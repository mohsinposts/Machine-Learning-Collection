{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjC8Ki2ivX2L7RQbFhUzD4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsinposts/Machine-Learning-Collection/blob/main/Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t0VSA-YoebSF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtEMrLkfGvY",
        "outputId": "c7d58755-617f-45b4-e0cc-ee3a33617658"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4\n",
        "hidden_size = 250\n",
        "num_classes = 3\n",
        "batch_size = 8\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "kRWC87BSfKEL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and test data from iris dataset\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# convert data to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# create dataloader for data\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "TFpewclzwNYb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "l-ZMK8PFewNL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "T-9vPhyPhpC0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    dataset_size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 1 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"Progress:[{current:>5d}/{dataset_size:>5d}] loss:{loss:>8f}\")\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "    average_loss = total_loss / num_batches\n",
        "    print(f\"Train Error: Avg loss: {average_loss:>8f}\")\n",
        "    return average_loss\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Get model pred\n",
        "            pred = model(X)\n",
        "\n",
        "            # Compute loss and\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= dataset_size\n",
        "\n",
        "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "IdkGUtCfhxtS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for t in range(num_epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW1YXfish0jT",
        "outputId": "6e8402c1-2127-4b96-e426-c11496011e77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.403076\n",
            "Progress:[   16/  120] loss:0.386993\n",
            "Progress:[   24/  120] loss:0.644820\n",
            "Progress:[   32/  120] loss:0.431340\n",
            "Progress:[   40/  120] loss:0.386526\n",
            "Progress:[   48/  120] loss:0.557435\n",
            "Progress:[   56/  120] loss:0.376109\n",
            "Progress:[   64/  120] loss:0.522510\n",
            "Progress:[   72/  120] loss:0.342413\n",
            "Progress:[   80/  120] loss:0.351286\n",
            "Progress:[   88/  120] loss:0.530744\n",
            "Progress:[   96/  120] loss:0.645071\n",
            "Progress:[  104/  120] loss:0.382959\n",
            "Progress:[  112/  120] loss:0.480389\n",
            "Progress:[  120/  120] loss:0.360475\n",
            "Train Error: Avg loss: 0.453476\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.351177\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.210201\n",
            "Progress:[   16/  120] loss:0.262795\n",
            "Progress:[   24/  120] loss:0.455431\n",
            "Progress:[   32/  120] loss:0.270510\n",
            "Progress:[   40/  120] loss:0.252936\n",
            "Progress:[   48/  120] loss:0.409638\n",
            "Progress:[   56/  120] loss:0.239496\n",
            "Progress:[   64/  120] loss:0.402202\n",
            "Progress:[   72/  120] loss:0.310829\n",
            "Progress:[   80/  120] loss:0.253298\n",
            "Progress:[   88/  120] loss:0.389249\n",
            "Progress:[   96/  120] loss:0.394428\n",
            "Progress:[  104/  120] loss:0.258520\n",
            "Progress:[  112/  120] loss:0.307645\n",
            "Progress:[  120/  120] loss:0.196044\n",
            "Train Error: Avg loss: 0.307548\n",
            "Test Error: Accuracy: 96.7%, Avg loss: 0.245131\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.137885\n",
            "Progress:[   16/  120] loss:0.198222\n",
            "Progress:[   24/  120] loss:0.329010\n",
            "Progress:[   32/  120] loss:0.175487\n",
            "Progress:[   40/  120] loss:0.164098\n",
            "Progress:[   48/  120] loss:0.310523\n",
            "Progress:[   56/  120] loss:0.151121\n",
            "Progress:[   64/  120] loss:0.334353\n",
            "Progress:[   72/  120] loss:0.311166\n",
            "Progress:[   80/  120] loss:0.187512\n",
            "Progress:[   88/  120] loss:0.353052\n",
            "Progress:[   96/  120] loss:0.250938\n",
            "Progress:[  104/  120] loss:0.170491\n",
            "Progress:[  112/  120] loss:0.194772\n",
            "Progress:[  120/  120] loss:0.101537\n",
            "Train Error: Avg loss: 0.224678\n",
            "Test Error: Accuracy: 86.7%, Avg loss: 0.197129\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.091713\n",
            "Progress:[   16/  120] loss:0.181284\n",
            "Progress:[   24/  120] loss:0.291404\n",
            "Progress:[   32/  120] loss:0.113606\n",
            "Progress:[   40/  120] loss:0.115063\n",
            "Progress:[   48/  120] loss:0.255670\n",
            "Progress:[   56/  120] loss:0.102199\n",
            "Progress:[   64/  120] loss:0.288741\n",
            "Progress:[   72/  120] loss:0.353873\n",
            "Progress:[   80/  120] loss:0.156926\n",
            "Progress:[   88/  120] loss:0.379809\n",
            "Progress:[   96/  120] loss:0.171018\n",
            "Progress:[  104/  120] loss:0.117298\n",
            "Progress:[  112/  120] loss:0.142148\n",
            "Progress:[  120/  120] loss:0.063262\n",
            "Train Error: Avg loss: 0.188268\n",
            "Test Error: Accuracy: 83.3%, Avg loss: 0.200020\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.075965\n",
            "Progress:[   16/  120] loss:0.200047\n",
            "Progress:[   24/  120] loss:0.314005\n",
            "Progress:[   32/  120] loss:0.082250\n",
            "Progress:[   40/  120] loss:0.097956\n",
            "Progress:[   48/  120] loss:0.230608\n",
            "Progress:[   56/  120] loss:0.075826\n",
            "Progress:[   64/  120] loss:0.259719\n",
            "Progress:[   72/  120] loss:0.390364\n",
            "Progress:[   80/  120] loss:0.151200\n",
            "Progress:[   88/  120] loss:0.462533\n",
            "Progress:[   96/  120] loss:0.106869\n",
            "Progress:[  104/  120] loss:0.103582\n",
            "Progress:[  112/  120] loss:0.103837\n",
            "Progress:[  120/  120] loss:0.045144\n",
            "Train Error: Avg loss: 0.179994\n",
            "Test Error: Accuracy: 83.3%, Avg loss: 0.216100\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.068121\n",
            "Progress:[   16/  120] loss:0.229442\n",
            "Progress:[   24/  120] loss:0.375808\n",
            "Progress:[   32/  120] loss:0.071741\n",
            "Progress:[   40/  120] loss:0.110009\n",
            "Progress:[   48/  120] loss:0.244048\n",
            "Progress:[   56/  120] loss:0.063405\n",
            "Progress:[   64/  120] loss:0.264511\n",
            "Progress:[   72/  120] loss:0.358484\n",
            "Progress:[   80/  120] loss:0.154973\n",
            "Progress:[   88/  120] loss:0.629660\n",
            "Progress:[   96/  120] loss:0.053910\n",
            "Progress:[  104/  120] loss:0.149452\n",
            "Progress:[  112/  120] loss:0.063436\n",
            "Progress:[  120/  120] loss:0.028867\n",
            "Train Error: Avg loss: 0.191058\n",
            "Test Error: Accuracy: 83.3%, Avg loss: 0.183963\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.045083\n",
            "Progress:[   16/  120] loss:0.205218\n",
            "Progress:[   24/  120] loss:0.410345\n",
            "Progress:[   32/  120] loss:0.075535\n",
            "Progress:[   40/  120] loss:0.154323\n",
            "Progress:[   48/  120] loss:0.328011\n",
            "Progress:[   56/  120] loss:0.088381\n",
            "Progress:[   64/  120] loss:0.377507\n",
            "Progress:[   72/  120] loss:0.200775\n",
            "Progress:[   80/  120] loss:0.127674\n",
            "Progress:[   88/  120] loss:0.748780\n",
            "Progress:[   96/  120] loss:0.029246\n",
            "Progress:[  104/  120] loss:0.306628\n",
            "Progress:[  112/  120] loss:0.073336\n",
            "Progress:[  120/  120] loss:0.028241\n",
            "Train Error: Avg loss: 0.213272\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.103440\n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.020281\n",
            "Progress:[   16/  120] loss:0.089763\n",
            "Progress:[   24/  120] loss:0.301386\n",
            "Progress:[   32/  120] loss:0.060198\n",
            "Progress:[   40/  120] loss:0.162364\n",
            "Progress:[   48/  120] loss:0.413182\n",
            "Progress:[   56/  120] loss:0.158168\n",
            "Progress:[   64/  120] loss:0.609007\n",
            "Progress:[   72/  120] loss:0.065178\n",
            "Progress:[   80/  120] loss:0.085852\n",
            "Progress:[   88/  120] loss:0.505158\n",
            "Progress:[   96/  120] loss:0.026545\n",
            "Progress:[  104/  120] loss:0.384967\n",
            "Progress:[  112/  120] loss:0.125868\n",
            "Progress:[  120/  120] loss:0.057554\n",
            "Train Error: Avg loss: 0.204365\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.104395\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.023264\n",
            "Progress:[   16/  120] loss:0.026735\n",
            "Progress:[   24/  120] loss:0.163840\n",
            "Progress:[   32/  120] loss:0.038266\n",
            "Progress:[   40/  120] loss:0.083374\n",
            "Progress:[   48/  120] loss:0.334851\n",
            "Progress:[   56/  120] loss:0.151787\n",
            "Progress:[   64/  120] loss:0.686749\n",
            "Progress:[   72/  120] loss:0.043517\n",
            "Progress:[   80/  120] loss:0.117289\n",
            "Progress:[   88/  120] loss:0.241842\n",
            "Progress:[   96/  120] loss:0.037228\n",
            "Progress:[  104/  120] loss:0.255591\n",
            "Progress:[  112/  120] loss:0.099016\n",
            "Progress:[  120/  120] loss:0.064981\n",
            "Train Error: Avg loss: 0.157889\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.135375\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.030170\n",
            "Progress:[   16/  120] loss:0.014709\n",
            "Progress:[   24/  120] loss:0.141454\n",
            "Progress:[   32/  120] loss:0.046613\n",
            "Progress:[   40/  120] loss:0.035515\n",
            "Progress:[   48/  120] loss:0.217633\n",
            "Progress:[   56/  120] loss:0.090577\n",
            "Progress:[   64/  120] loss:0.589450\n",
            "Progress:[   72/  120] loss:0.041056\n",
            "Progress:[   80/  120] loss:0.120349\n",
            "Progress:[   88/  120] loss:0.192434\n",
            "Progress:[   96/  120] loss:0.042594\n",
            "Progress:[  104/  120] loss:0.173821\n",
            "Progress:[  112/  120] loss:0.061201\n",
            "Progress:[  120/  120] loss:0.044039\n",
            "Train Error: Avg loss: 0.122774\n",
            "Test Error: Accuracy: 96.7%, Avg loss: 0.113499\n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.022133\n",
            "Progress:[   16/  120] loss:0.013009\n",
            "Progress:[   24/  120] loss:0.133417\n",
            "Progress:[   32/  120] loss:0.044487\n",
            "Progress:[   40/  120] loss:0.028289\n",
            "Progress:[   48/  120] loss:0.192553\n",
            "Progress:[   56/  120] loss:0.073022\n",
            "Progress:[   64/  120] loss:0.543171\n",
            "Progress:[   72/  120] loss:0.040348\n",
            "Progress:[   80/  120] loss:0.103870\n",
            "Progress:[   88/  120] loss:0.220902\n",
            "Progress:[   96/  120] loss:0.034822\n",
            "Progress:[  104/  120] loss:0.169740\n",
            "Progress:[  112/  120] loss:0.052412\n",
            "Progress:[  120/  120] loss:0.036449\n",
            "Train Error: Avg loss: 0.113908\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.100250\n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.017016\n",
            "Progress:[   16/  120] loss:0.012038\n",
            "Progress:[   24/  120] loss:0.122157\n",
            "Progress:[   32/  120] loss:0.035991\n",
            "Progress:[   40/  120] loss:0.028822\n",
            "Progress:[   48/  120] loss:0.198461\n",
            "Progress:[   56/  120] loss:0.077567\n",
            "Progress:[   64/  120] loss:0.560298\n",
            "Progress:[   72/  120] loss:0.036377\n",
            "Progress:[   80/  120] loss:0.098528\n",
            "Progress:[   88/  120] loss:0.243125\n",
            "Progress:[   96/  120] loss:0.027907\n",
            "Progress:[  104/  120] loss:0.182957\n",
            "Progress:[  112/  120] loss:0.052538\n",
            "Progress:[  120/  120] loss:0.036749\n",
            "Train Error: Avg loss: 0.115369\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.100590\n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.015535\n",
            "Progress:[   16/  120] loss:0.010158\n",
            "Progress:[   24/  120] loss:0.115550\n",
            "Progress:[   32/  120] loss:0.032535\n",
            "Progress:[   40/  120] loss:0.027289\n",
            "Progress:[   48/  120] loss:0.199548\n",
            "Progress:[   56/  120] loss:0.081731\n",
            "Progress:[   64/  120] loss:0.581993\n",
            "Progress:[   72/  120] loss:0.032035\n",
            "Progress:[   80/  120] loss:0.100404\n",
            "Progress:[   88/  120] loss:0.239469\n",
            "Progress:[   96/  120] loss:0.024530\n",
            "Progress:[  104/  120] loss:0.185747\n",
            "Progress:[  112/  120] loss:0.051631\n",
            "Progress:[  120/  120] loss:0.037633\n",
            "Train Error: Avg loss: 0.115719\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.103566\n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.014759\n",
            "Progress:[   16/  120] loss:0.008437\n",
            "Progress:[   24/  120] loss:0.110975\n",
            "Progress:[   32/  120] loss:0.031363\n",
            "Progress:[   40/  120] loss:0.024007\n",
            "Progress:[   48/  120] loss:0.190888\n",
            "Progress:[   56/  120] loss:0.080824\n",
            "Progress:[   64/  120] loss:0.590896\n",
            "Progress:[   72/  120] loss:0.028686\n",
            "Progress:[   80/  120] loss:0.104077\n",
            "Progress:[   88/  120] loss:0.229320\n",
            "Progress:[   96/  120] loss:0.022538\n",
            "Progress:[  104/  120] loss:0.177982\n",
            "Progress:[  112/  120] loss:0.048544\n",
            "Progress:[  120/  120] loss:0.037392\n",
            "Train Error: Avg loss: 0.113379\n",
            "Test Error: Accuracy: 96.7%, Avg loss: 0.105834\n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.013885\n",
            "Progress:[   16/  120] loss:0.007192\n",
            "Progress:[   24/  120] loss:0.107618\n",
            "Progress:[   32/  120] loss:0.030970\n",
            "Progress:[   40/  120] loss:0.020905\n",
            "Progress:[   48/  120] loss:0.180611\n",
            "Progress:[   56/  120] loss:0.077963\n",
            "Progress:[   64/  120] loss:0.592584\n",
            "Progress:[   72/  120] loss:0.026179\n",
            "Progress:[   80/  120] loss:0.107042\n",
            "Progress:[   88/  120] loss:0.220851\n",
            "Progress:[   96/  120] loss:0.020925\n",
            "Progress:[  104/  120] loss:0.170245\n",
            "Progress:[  112/  120] loss:0.045306\n",
            "Progress:[  120/  120] loss:0.036450\n",
            "Train Error: Avg loss: 0.110582\n",
            "Test Error: Accuracy: 96.7%, Avg loss: 0.106254\n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.012935\n",
            "Progress:[   16/  120] loss:0.006300\n",
            "Progress:[   24/  120] loss:0.104547\n",
            "Progress:[   32/  120] loss:0.030165\n",
            "Progress:[   40/  120] loss:0.018682\n",
            "Progress:[   48/  120] loss:0.172194\n",
            "Progress:[   56/  120] loss:0.076029\n",
            "Progress:[   64/  120] loss:0.593346\n",
            "Progress:[   72/  120] loss:0.024281\n",
            "Progress:[   80/  120] loss:0.108837\n",
            "Progress:[   88/  120] loss:0.214520\n",
            "Progress:[   96/  120] loss:0.019417\n",
            "Progress:[  104/  120] loss:0.165467\n",
            "Progress:[  112/  120] loss:0.043383\n",
            "Progress:[  120/  120] loss:0.036088\n",
            "Train Error: Avg loss: 0.108413\n",
            "Test Error: Accuracy: 96.7%, Avg loss: 0.107561\n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.012134\n",
            "Progress:[   16/  120] loss:0.005558\n",
            "Progress:[   24/  120] loss:0.102369\n",
            "Progress:[   32/  120] loss:0.029374\n",
            "Progress:[   40/  120] loss:0.016767\n",
            "Progress:[   48/  120] loss:0.164273\n",
            "Progress:[   56/  120] loss:0.074670\n",
            "Progress:[   64/  120] loss:0.596429\n",
            "Progress:[   72/  120] loss:0.022323\n",
            "Progress:[   80/  120] loss:0.111952\n",
            "Progress:[   88/  120] loss:0.207872\n",
            "Progress:[   96/  120] loss:0.018069\n",
            "Progress:[  104/  120] loss:0.160357\n",
            "Progress:[  112/  120] loss:0.041128\n",
            "Progress:[  120/  120] loss:0.035543\n",
            "Train Error: Avg loss: 0.106588\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.108417\n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.011483\n",
            "Progress:[   16/  120] loss:0.004950\n",
            "Progress:[   24/  120] loss:0.100385\n",
            "Progress:[   32/  120] loss:0.029132\n",
            "Progress:[   40/  120] loss:0.014874\n",
            "Progress:[   48/  120] loss:0.156970\n",
            "Progress:[   56/  120] loss:0.071750\n",
            "Progress:[   64/  120] loss:0.600274\n",
            "Progress:[   72/  120] loss:0.020686\n",
            "Progress:[   80/  120] loss:0.111901\n",
            "Progress:[   88/  120] loss:0.201460\n",
            "Progress:[   96/  120] loss:0.016691\n",
            "Progress:[  104/  120] loss:0.156180\n",
            "Progress:[  112/  120] loss:0.038487\n",
            "Progress:[  120/  120] loss:0.034538\n",
            "Train Error: Avg loss: 0.104651\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.108649\n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.010941\n",
            "Progress:[   16/  120] loss:0.004441\n",
            "Progress:[   24/  120] loss:0.099225\n",
            "Progress:[   32/  120] loss:0.028610\n",
            "Progress:[   40/  120] loss:0.013461\n",
            "Progress:[   48/  120] loss:0.150200\n",
            "Progress:[   56/  120] loss:0.070930\n",
            "Progress:[   64/  120] loss:0.600882\n",
            "Progress:[   72/  120] loss:0.019376\n",
            "Progress:[   80/  120] loss:0.116636\n",
            "Progress:[   88/  120] loss:0.194590\n",
            "Progress:[   96/  120] loss:0.015900\n",
            "Progress:[  104/  120] loss:0.151286\n",
            "Progress:[  112/  120] loss:0.037527\n",
            "Progress:[  120/  120] loss:0.034823\n",
            "Train Error: Avg loss: 0.103255\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.111140\n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.010386\n",
            "Progress:[   16/  120] loss:0.004022\n",
            "Progress:[   24/  120] loss:0.098852\n",
            "Progress:[   32/  120] loss:0.028381\n",
            "Progress:[   40/  120] loss:0.012163\n",
            "Progress:[   48/  120] loss:0.143581\n",
            "Progress:[   56/  120] loss:0.068741\n",
            "Progress:[   64/  120] loss:0.603074\n",
            "Progress:[   72/  120] loss:0.018091\n",
            "Progress:[   80/  120] loss:0.117499\n",
            "Progress:[   88/  120] loss:0.187918\n",
            "Progress:[   96/  120] loss:0.014913\n",
            "Progress:[  104/  120] loss:0.147222\n",
            "Progress:[  112/  120] loss:0.035230\n",
            "Progress:[  120/  120] loss:0.033761\n",
            "Train Error: Avg loss: 0.101589\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.111188\n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.009980\n",
            "Progress:[   16/  120] loss:0.003654\n",
            "Progress:[   24/  120] loss:0.098211\n",
            "Progress:[   32/  120] loss:0.028128\n",
            "Progress:[   40/  120] loss:0.011045\n",
            "Progress:[   48/  120] loss:0.138551\n",
            "Progress:[   56/  120] loss:0.067477\n",
            "Progress:[   64/  120] loss:0.602573\n",
            "Progress:[   72/  120] loss:0.017125\n",
            "Progress:[   80/  120] loss:0.120712\n",
            "Progress:[   88/  120] loss:0.182679\n",
            "Progress:[   96/  120] loss:0.014216\n",
            "Progress:[  104/  120] loss:0.142827\n",
            "Progress:[  112/  120] loss:0.034482\n",
            "Progress:[  120/  120] loss:0.034169\n",
            "Train Error: Avg loss: 0.100389\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.113729\n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.009473\n",
            "Progress:[   16/  120] loss:0.003391\n",
            "Progress:[   24/  120] loss:0.098134\n",
            "Progress:[   32/  120] loss:0.027582\n",
            "Progress:[   40/  120] loss:0.010105\n",
            "Progress:[   48/  120] loss:0.132268\n",
            "Progress:[   56/  120] loss:0.066184\n",
            "Progress:[   64/  120] loss:0.604883\n",
            "Progress:[   72/  120] loss:0.015995\n",
            "Progress:[   80/  120] loss:0.123097\n",
            "Progress:[   88/  120] loss:0.176864\n",
            "Progress:[   96/  120] loss:0.013525\n",
            "Progress:[  104/  120] loss:0.138992\n",
            "Progress:[  112/  120] loss:0.032398\n",
            "Progress:[  120/  120] loss:0.033482\n",
            "Train Error: Avg loss: 0.099092\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.114430\n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.009065\n",
            "Progress:[   16/  120] loss:0.003129\n",
            "Progress:[   24/  120] loss:0.098258\n",
            "Progress:[   32/  120] loss:0.027637\n",
            "Progress:[   40/  120] loss:0.009172\n",
            "Progress:[   48/  120] loss:0.127050\n",
            "Progress:[   56/  120] loss:0.064475\n",
            "Progress:[   64/  120] loss:0.607447\n",
            "Progress:[   72/  120] loss:0.015085\n",
            "Progress:[   80/  120] loss:0.125933\n",
            "Progress:[   88/  120] loss:0.169357\n",
            "Progress:[   96/  120] loss:0.012947\n",
            "Progress:[  104/  120] loss:0.134060\n",
            "Progress:[  112/  120] loss:0.031535\n",
            "Progress:[  120/  120] loss:0.033218\n",
            "Train Error: Avg loss: 0.097891\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.116100\n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.008913\n",
            "Progress:[   16/  120] loss:0.002927\n",
            "Progress:[   24/  120] loss:0.099917\n",
            "Progress:[   32/  120] loss:0.028292\n",
            "Progress:[   40/  120] loss:0.008283\n",
            "Progress:[   48/  120] loss:0.122216\n",
            "Progress:[   56/  120] loss:0.061735\n",
            "Progress:[   64/  120] loss:0.604834\n",
            "Progress:[   72/  120] loss:0.014316\n",
            "Progress:[   80/  120] loss:0.128376\n",
            "Progress:[   88/  120] loss:0.163577\n",
            "Progress:[   96/  120] loss:0.012436\n",
            "Progress:[  104/  120] loss:0.128420\n",
            "Progress:[  112/  120] loss:0.029969\n",
            "Progress:[  120/  120] loss:0.032311\n",
            "Train Error: Avg loss: 0.096435\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.115825\n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.008398\n",
            "Progress:[   16/  120] loss:0.002750\n",
            "Progress:[   24/  120] loss:0.099266\n",
            "Progress:[   32/  120] loss:0.027653\n",
            "Progress:[   40/  120] loss:0.007758\n",
            "Progress:[   48/  120] loss:0.118325\n",
            "Progress:[   56/  120] loss:0.061481\n",
            "Progress:[   64/  120] loss:0.602529\n",
            "Progress:[   72/  120] loss:0.013757\n",
            "Progress:[   80/  120] loss:0.130828\n",
            "Progress:[   88/  120] loss:0.160071\n",
            "Progress:[   96/  120] loss:0.012001\n",
            "Progress:[  104/  120] loss:0.126462\n",
            "Progress:[  112/  120] loss:0.029374\n",
            "Progress:[  120/  120] loss:0.032479\n",
            "Train Error: Avg loss: 0.095542\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.117587\n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.008119\n",
            "Progress:[   16/  120] loss:0.002596\n",
            "Progress:[   24/  120] loss:0.099400\n",
            "Progress:[   32/  120] loss:0.027559\n",
            "Progress:[   40/  120] loss:0.007148\n",
            "Progress:[   48/  120] loss:0.114754\n",
            "Progress:[   56/  120] loss:0.059659\n",
            "Progress:[   64/  120] loss:0.605617\n",
            "Progress:[   72/  120] loss:0.013008\n",
            "Progress:[   80/  120] loss:0.131345\n",
            "Progress:[   88/  120] loss:0.155743\n",
            "Progress:[   96/  120] loss:0.011217\n",
            "Progress:[  104/  120] loss:0.123461\n",
            "Progress:[  112/  120] loss:0.028135\n",
            "Progress:[  120/  120] loss:0.031964\n",
            "Train Error: Avg loss: 0.094648\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.116290\n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.007893\n",
            "Progress:[   16/  120] loss:0.002461\n",
            "Progress:[   24/  120] loss:0.099487\n",
            "Progress:[   32/  120] loss:0.027426\n",
            "Progress:[   40/  120] loss:0.006662\n",
            "Progress:[   48/  120] loss:0.110579\n",
            "Progress:[   56/  120] loss:0.058827\n",
            "Progress:[   64/  120] loss:0.604265\n",
            "Progress:[   72/  120] loss:0.012414\n",
            "Progress:[   80/  120] loss:0.134532\n",
            "Progress:[   88/  120] loss:0.151609\n",
            "Progress:[   96/  120] loss:0.010836\n",
            "Progress:[  104/  120] loss:0.120436\n",
            "Progress:[  112/  120] loss:0.027620\n",
            "Progress:[  120/  120] loss:0.032595\n",
            "Train Error: Avg loss: 0.093843\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.120071\n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.007469\n",
            "Progress:[   16/  120] loss:0.002331\n",
            "Progress:[   24/  120] loss:0.101500\n",
            "Progress:[   32/  120] loss:0.027145\n",
            "Progress:[   40/  120] loss:0.006098\n",
            "Progress:[   48/  120] loss:0.107204\n",
            "Progress:[   56/  120] loss:0.057474\n",
            "Progress:[   64/  120] loss:0.608185\n",
            "Progress:[   72/  120] loss:0.011618\n",
            "Progress:[   80/  120] loss:0.138142\n",
            "Progress:[   88/  120] loss:0.146426\n",
            "Progress:[   96/  120] loss:0.010151\n",
            "Progress:[  104/  120] loss:0.116737\n",
            "Progress:[  112/  120] loss:0.026214\n",
            "Progress:[  120/  120] loss:0.032049\n",
            "Train Error: Avg loss: 0.093249\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.119404\n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.007304\n",
            "Progress:[   16/  120] loss:0.002215\n",
            "Progress:[   24/  120] loss:0.101506\n",
            "Progress:[   32/  120] loss:0.027537\n",
            "Progress:[   40/  120] loss:0.005628\n",
            "Progress:[   48/  120] loss:0.104554\n",
            "Progress:[   56/  120] loss:0.056719\n",
            "Progress:[   64/  120] loss:0.605422\n",
            "Progress:[   72/  120] loss:0.011269\n",
            "Progress:[   80/  120] loss:0.141307\n",
            "Progress:[   88/  120] loss:0.141011\n",
            "Progress:[   96/  120] loss:0.009931\n",
            "Progress:[  104/  120] loss:0.112443\n",
            "Progress:[  112/  120] loss:0.026305\n",
            "Progress:[  120/  120] loss:0.032715\n",
            "Train Error: Avg loss: 0.092391\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.122953\n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.007137\n",
            "Progress:[   16/  120] loss:0.002157\n",
            "Progress:[   24/  120] loss:0.104250\n",
            "Progress:[   32/  120] loss:0.027588\n",
            "Progress:[   40/  120] loss:0.005228\n",
            "Progress:[   48/  120] loss:0.101530\n",
            "Progress:[   56/  120] loss:0.055337\n",
            "Progress:[   64/  120] loss:0.604658\n",
            "Progress:[   72/  120] loss:0.010751\n",
            "Progress:[   80/  120] loss:0.144181\n",
            "Progress:[   88/  120] loss:0.133546\n",
            "Progress:[   96/  120] loss:0.009801\n",
            "Progress:[  104/  120] loss:0.107460\n",
            "Progress:[  112/  120] loss:0.024915\n",
            "Progress:[  120/  120] loss:0.031951\n",
            "Train Error: Avg loss: 0.091366\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.122137\n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.007049\n",
            "Progress:[   16/  120] loss:0.002066\n",
            "Progress:[   24/  120] loss:0.105669\n",
            "Progress:[   32/  120] loss:0.028408\n",
            "Progress:[   40/  120] loss:0.004832\n",
            "Progress:[   48/  120] loss:0.098937\n",
            "Progress:[   56/  120] loss:0.053202\n",
            "Progress:[   64/  120] loss:0.601383\n",
            "Progress:[   72/  120] loss:0.010425\n",
            "Progress:[   80/  120] loss:0.143485\n",
            "Progress:[   88/  120] loss:0.130825\n",
            "Progress:[   96/  120] loss:0.009385\n",
            "Progress:[  104/  120] loss:0.106075\n",
            "Progress:[  112/  120] loss:0.023992\n",
            "Progress:[  120/  120] loss:0.031493\n",
            "Train Error: Avg loss: 0.090482\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.122835\n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.006723\n",
            "Progress:[   16/  120] loss:0.001958\n",
            "Progress:[   24/  120] loss:0.106126\n",
            "Progress:[   32/  120] loss:0.027590\n",
            "Progress:[   40/  120] loss:0.004515\n",
            "Progress:[   48/  120] loss:0.096942\n",
            "Progress:[   56/  120] loss:0.052595\n",
            "Progress:[   64/  120] loss:0.604592\n",
            "Progress:[   72/  120] loss:0.009883\n",
            "Progress:[   80/  120] loss:0.146744\n",
            "Progress:[   88/  120] loss:0.126507\n",
            "Progress:[   96/  120] loss:0.009064\n",
            "Progress:[  104/  120] loss:0.104162\n",
            "Progress:[  112/  120] loss:0.023395\n",
            "Progress:[  120/  120] loss:0.031638\n",
            "Train Error: Avg loss: 0.090162\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.123346\n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.006529\n",
            "Progress:[   16/  120] loss:0.001887\n",
            "Progress:[   24/  120] loss:0.107259\n",
            "Progress:[   32/  120] loss:0.027594\n",
            "Progress:[   40/  120] loss:0.004249\n",
            "Progress:[   48/  120] loss:0.095101\n",
            "Progress:[   56/  120] loss:0.051631\n",
            "Progress:[   64/  120] loss:0.603600\n",
            "Progress:[   72/  120] loss:0.009581\n",
            "Progress:[   80/  120] loss:0.147934\n",
            "Progress:[   88/  120] loss:0.121543\n",
            "Progress:[   96/  120] loss:0.008990\n",
            "Progress:[  104/  120] loss:0.099664\n",
            "Progress:[  112/  120] loss:0.022958\n",
            "Progress:[  120/  120] loss:0.031235\n",
            "Train Error: Avg loss: 0.089317\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.123144\n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.006552\n",
            "Progress:[   16/  120] loss:0.001877\n",
            "Progress:[   24/  120] loss:0.109073\n",
            "Progress:[   32/  120] loss:0.028805\n",
            "Progress:[   40/  120] loss:0.003988\n",
            "Progress:[   48/  120] loss:0.093558\n",
            "Progress:[   56/  120] loss:0.048980\n",
            "Progress:[   64/  120] loss:0.596219\n",
            "Progress:[   72/  120] loss:0.009257\n",
            "Progress:[   80/  120] loss:0.150066\n",
            "Progress:[   88/  120] loss:0.119928\n",
            "Progress:[   96/  120] loss:0.008626\n",
            "Progress:[  104/  120] loss:0.096016\n",
            "Progress:[  112/  120] loss:0.021472\n",
            "Progress:[  120/  120] loss:0.030058\n",
            "Train Error: Avg loss: 0.088298\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.121873\n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.006024\n",
            "Progress:[   16/  120] loss:0.001755\n",
            "Progress:[   24/  120] loss:0.107589\n",
            "Progress:[   32/  120] loss:0.027361\n",
            "Progress:[   40/  120] loss:0.003788\n",
            "Progress:[   48/  120] loss:0.091895\n",
            "Progress:[   56/  120] loss:0.048947\n",
            "Progress:[   64/  120] loss:0.600856\n",
            "Progress:[   72/  120] loss:0.008944\n",
            "Progress:[   80/  120] loss:0.148849\n",
            "Progress:[   88/  120] loss:0.117468\n",
            "Progress:[   96/  120] loss:0.008318\n",
            "Progress:[  104/  120] loss:0.094580\n",
            "Progress:[  112/  120] loss:0.021689\n",
            "Progress:[  120/  120] loss:0.030249\n",
            "Train Error: Avg loss: 0.087888\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.121479\n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.006291\n",
            "Progress:[   16/  120] loss:0.001768\n",
            "Progress:[   24/  120] loss:0.108031\n",
            "Progress:[   32/  120] loss:0.029040\n",
            "Progress:[   40/  120] loss:0.003605\n",
            "Progress:[   48/  120] loss:0.090707\n",
            "Progress:[   56/  120] loss:0.047409\n",
            "Progress:[   64/  120] loss:0.595155\n",
            "Progress:[   72/  120] loss:0.008794\n",
            "Progress:[   80/  120] loss:0.149132\n",
            "Progress:[   88/  120] loss:0.114432\n",
            "Progress:[   96/  120] loss:0.008275\n",
            "Progress:[  104/  120] loss:0.090810\n",
            "Progress:[  112/  120] loss:0.020873\n",
            "Progress:[  120/  120] loss:0.029818\n",
            "Train Error: Avg loss: 0.086943\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.121115\n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.006048\n",
            "Progress:[   16/  120] loss:0.001718\n",
            "Progress:[   24/  120] loss:0.107360\n",
            "Progress:[   32/  120] loss:0.028598\n",
            "Progress:[   40/  120] loss:0.003446\n",
            "Progress:[   48/  120] loss:0.089765\n",
            "Progress:[   56/  120] loss:0.047250\n",
            "Progress:[   64/  120] loss:0.594750\n",
            "Progress:[   72/  120] loss:0.008539\n",
            "Progress:[   80/  120] loss:0.150879\n",
            "Progress:[   88/  120] loss:0.112768\n",
            "Progress:[   96/  120] loss:0.008104\n",
            "Progress:[  104/  120] loss:0.089724\n",
            "Progress:[  112/  120] loss:0.020299\n",
            "Progress:[  120/  120] loss:0.029950\n",
            "Train Error: Avg loss: 0.086613\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.122210\n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005845\n",
            "Progress:[   16/  120] loss:0.001658\n",
            "Progress:[   24/  120] loss:0.108989\n",
            "Progress:[   32/  120] loss:0.028099\n",
            "Progress:[   40/  120] loss:0.003278\n",
            "Progress:[   48/  120] loss:0.088619\n",
            "Progress:[   56/  120] loss:0.046124\n",
            "Progress:[   64/  120] loss:0.595865\n",
            "Progress:[   72/  120] loss:0.008198\n",
            "Progress:[   80/  120] loss:0.151475\n",
            "Progress:[   88/  120] loss:0.109959\n",
            "Progress:[   96/  120] loss:0.007740\n",
            "Progress:[  104/  120] loss:0.089914\n",
            "Progress:[  112/  120] loss:0.019501\n",
            "Progress:[  120/  120] loss:0.029267\n",
            "Train Error: Avg loss: 0.086302\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.122930\n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005605\n",
            "Progress:[   16/  120] loss:0.001590\n",
            "Progress:[   24/  120] loss:0.109900\n",
            "Progress:[   32/  120] loss:0.027818\n",
            "Progress:[   40/  120] loss:0.003131\n",
            "Progress:[   48/  120] loss:0.087689\n",
            "Progress:[   56/  120] loss:0.046110\n",
            "Progress:[   64/  120] loss:0.597831\n",
            "Progress:[   72/  120] loss:0.007961\n",
            "Progress:[   80/  120] loss:0.154884\n",
            "Progress:[   88/  120] loss:0.105082\n",
            "Progress:[   96/  120] loss:0.007838\n",
            "Progress:[  104/  120] loss:0.085012\n",
            "Progress:[  112/  120] loss:0.019518\n",
            "Progress:[  120/  120] loss:0.029519\n",
            "Train Error: Avg loss: 0.085966\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.121738\n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005759\n",
            "Progress:[   16/  120] loss:0.001631\n",
            "Progress:[   24/  120] loss:0.110685\n",
            "Progress:[   32/  120] loss:0.029236\n",
            "Progress:[   40/  120] loss:0.003030\n",
            "Progress:[   48/  120] loss:0.087404\n",
            "Progress:[   56/  120] loss:0.044314\n",
            "Progress:[   64/  120] loss:0.587013\n",
            "Progress:[   72/  120] loss:0.008011\n",
            "Progress:[   80/  120] loss:0.150704\n",
            "Progress:[   88/  120] loss:0.105269\n",
            "Progress:[   96/  120] loss:0.007635\n",
            "Progress:[  104/  120] loss:0.085516\n",
            "Progress:[  112/  120] loss:0.018620\n",
            "Progress:[  120/  120] loss:0.028159\n",
            "Train Error: Avg loss: 0.084866\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.118259\n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005374\n",
            "Progress:[   16/  120] loss:0.001525\n",
            "Progress:[   24/  120] loss:0.107771\n",
            "Progress:[   32/  120] loss:0.027899\n",
            "Progress:[   40/  120] loss:0.002906\n",
            "Progress:[   48/  120] loss:0.085812\n",
            "Progress:[   56/  120] loss:0.044639\n",
            "Progress:[   64/  120] loss:0.593688\n",
            "Progress:[   72/  120] loss:0.007640\n",
            "Progress:[   80/  120] loss:0.152261\n",
            "Progress:[   88/  120] loss:0.105284\n",
            "Progress:[   96/  120] loss:0.007141\n",
            "Progress:[  104/  120] loss:0.087777\n",
            "Progress:[  112/  120] loss:0.019056\n",
            "Progress:[  120/  120] loss:0.029082\n",
            "Train Error: Avg loss: 0.085190\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.120091\n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005302\n",
            "Progress:[   16/  120] loss:0.001492\n",
            "Progress:[   24/  120] loss:0.108636\n",
            "Progress:[   32/  120] loss:0.027344\n",
            "Progress:[   40/  120] loss:0.002850\n",
            "Progress:[   48/  120] loss:0.084618\n",
            "Progress:[   56/  120] loss:0.046443\n",
            "Progress:[   64/  120] loss:0.597303\n",
            "Progress:[   72/  120] loss:0.007592\n",
            "Progress:[   80/  120] loss:0.151445\n",
            "Progress:[   88/  120] loss:0.101329\n",
            "Progress:[   96/  120] loss:0.007162\n",
            "Progress:[  104/  120] loss:0.087234\n",
            "Progress:[  112/  120] loss:0.019223\n",
            "Progress:[  120/  120] loss:0.029809\n",
            "Train Error: Avg loss: 0.085185\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.123405\n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005616\n",
            "Progress:[   16/  120] loss:0.001538\n",
            "Progress:[   24/  120] loss:0.112990\n",
            "Progress:[   32/  120] loss:0.028973\n",
            "Progress:[   40/  120] loss:0.002714\n",
            "Progress:[   48/  120] loss:0.085169\n",
            "Progress:[   56/  120] loss:0.043799\n",
            "Progress:[   64/  120] loss:0.592494\n",
            "Progress:[   72/  120] loss:0.007351\n",
            "Progress:[   80/  120] loss:0.155707\n",
            "Progress:[   88/  120] loss:0.095093\n",
            "Progress:[   96/  120] loss:0.007441\n",
            "Progress:[  104/  120] loss:0.079552\n",
            "Progress:[  112/  120] loss:0.017637\n",
            "Progress:[  120/  120] loss:0.028322\n",
            "Train Error: Avg loss: 0.084293\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.119764\n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005331\n",
            "Progress:[   16/  120] loss:0.001482\n",
            "Progress:[   24/  120] loss:0.111377\n",
            "Progress:[   32/  120] loss:0.028644\n",
            "Progress:[   40/  120] loss:0.002647\n",
            "Progress:[   48/  120] loss:0.084475\n",
            "Progress:[   56/  120] loss:0.042893\n",
            "Progress:[   64/  120] loss:0.584560\n",
            "Progress:[   72/  120] loss:0.007457\n",
            "Progress:[   80/  120] loss:0.150934\n",
            "Progress:[   88/  120] loss:0.094617\n",
            "Progress:[   96/  120] loss:0.007343\n",
            "Progress:[  104/  120] loss:0.082166\n",
            "Progress:[  112/  120] loss:0.017973\n",
            "Progress:[  120/  120] loss:0.027805\n",
            "Train Error: Avg loss: 0.083314\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.117434\n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005219\n",
            "Progress:[   16/  120] loss:0.001457\n",
            "Progress:[   24/  120] loss:0.109996\n",
            "Progress:[   32/  120] loss:0.028242\n",
            "Progress:[   40/  120] loss:0.002549\n",
            "Progress:[   48/  120] loss:0.084373\n",
            "Progress:[   56/  120] loss:0.041042\n",
            "Progress:[   64/  120] loss:0.583566\n",
            "Progress:[   72/  120] loss:0.007083\n",
            "Progress:[   80/  120] loss:0.150951\n",
            "Progress:[   88/  120] loss:0.097710\n",
            "Progress:[   96/  120] loss:0.006571\n",
            "Progress:[  104/  120] loss:0.084532\n",
            "Progress:[  112/  120] loss:0.016048\n",
            "Progress:[  120/  120] loss:0.026347\n",
            "Train Error: Avg loss: 0.083046\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.116897\n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004654\n",
            "Progress:[   16/  120] loss:0.001323\n",
            "Progress:[   24/  120] loss:0.106508\n",
            "Progress:[   32/  120] loss:0.025426\n",
            "Progress:[   40/  120] loss:0.002436\n",
            "Progress:[   48/  120] loss:0.082091\n",
            "Progress:[   56/  120] loss:0.043868\n",
            "Progress:[   64/  120] loss:0.596722\n",
            "Progress:[   72/  120] loss:0.006835\n",
            "Progress:[   80/  120] loss:0.153505\n",
            "Progress:[   88/  120] loss:0.093550\n",
            "Progress:[   96/  120] loss:0.006644\n",
            "Progress:[  104/  120] loss:0.081176\n",
            "Progress:[  112/  120] loss:0.017341\n",
            "Progress:[  120/  120] loss:0.028332\n",
            "Train Error: Avg loss: 0.083361\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.119205\n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005246\n",
            "Progress:[   16/  120] loss:0.001440\n",
            "Progress:[   24/  120] loss:0.111833\n",
            "Progress:[   32/  120] loss:0.028564\n",
            "Progress:[   40/  120] loss:0.002442\n",
            "Progress:[   48/  120] loss:0.083308\n",
            "Progress:[   56/  120] loss:0.041652\n",
            "Progress:[   64/  120] loss:0.580592\n",
            "Progress:[   72/  120] loss:0.007067\n",
            "Progress:[   80/  120] loss:0.149832\n",
            "Progress:[   88/  120] loss:0.092149\n",
            "Progress:[   96/  120] loss:0.006670\n",
            "Progress:[  104/  120] loss:0.079904\n",
            "Progress:[  112/  120] loss:0.016463\n",
            "Progress:[  120/  120] loss:0.026905\n",
            "Train Error: Avg loss: 0.082271\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.118797\n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004937\n",
            "Progress:[   16/  120] loss:0.001362\n",
            "Progress:[   24/  120] loss:0.109925\n",
            "Progress:[   32/  120] loss:0.027075\n",
            "Progress:[   40/  120] loss:0.002288\n",
            "Progress:[   48/  120] loss:0.082849\n",
            "Progress:[   56/  120] loss:0.041316\n",
            "Progress:[   64/  120] loss:0.587928\n",
            "Progress:[   72/  120] loss:0.006685\n",
            "Progress:[   80/  120] loss:0.153499\n",
            "Progress:[   88/  120] loss:0.087342\n",
            "Progress:[   96/  120] loss:0.006710\n",
            "Progress:[  104/  120] loss:0.076957\n",
            "Progress:[  112/  120] loss:0.015919\n",
            "Progress:[  120/  120] loss:0.026169\n",
            "Train Error: Avg loss: 0.082064\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.116366\n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004995\n",
            "Progress:[   16/  120] loss:0.001359\n",
            "Progress:[   24/  120] loss:0.110736\n",
            "Progress:[   32/  120] loss:0.028136\n",
            "Progress:[   40/  120] loss:0.002267\n",
            "Progress:[   48/  120] loss:0.082033\n",
            "Progress:[   56/  120] loss:0.039938\n",
            "Progress:[   64/  120] loss:0.579511\n",
            "Progress:[   72/  120] loss:0.006873\n",
            "Progress:[   80/  120] loss:0.145351\n",
            "Progress:[   88/  120] loss:0.088791\n",
            "Progress:[   96/  120] loss:0.006530\n",
            "Progress:[  104/  120] loss:0.081301\n",
            "Progress:[  112/  120] loss:0.015844\n",
            "Progress:[  120/  120] loss:0.025440\n",
            "Train Error: Avg loss: 0.081274\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.111056\n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004854\n",
            "Progress:[   16/  120] loss:0.001302\n",
            "Progress:[   24/  120] loss:0.107416\n",
            "Progress:[   32/  120] loss:0.026994\n",
            "Progress:[   40/  120] loss:0.002179\n",
            "Progress:[   48/  120] loss:0.081443\n",
            "Progress:[   56/  120] loss:0.039309\n",
            "Progress:[   64/  120] loss:0.582330\n",
            "Progress:[   72/  120] loss:0.006467\n",
            "Progress:[   80/  120] loss:0.150402\n",
            "Progress:[   88/  120] loss:0.087228\n",
            "Progress:[   96/  120] loss:0.006255\n",
            "Progress:[  104/  120] loss:0.075020\n",
            "Progress:[  112/  120] loss:0.015102\n",
            "Progress:[  120/  120] loss:0.025334\n",
            "Train Error: Avg loss: 0.080776\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.113382\n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004759\n",
            "Progress:[   16/  120] loss:0.001299\n",
            "Progress:[   24/  120] loss:0.107200\n",
            "Progress:[   32/  120] loss:0.026929\n",
            "Progress:[   40/  120] loss:0.002189\n",
            "Progress:[   48/  120] loss:0.080855\n",
            "Progress:[   56/  120] loss:0.040866\n",
            "Progress:[   64/  120] loss:0.577254\n",
            "Progress:[   72/  120] loss:0.006783\n",
            "Progress:[   80/  120] loss:0.144686\n",
            "Progress:[   88/  120] loss:0.089167\n",
            "Progress:[   96/  120] loss:0.006280\n",
            "Progress:[  104/  120] loss:0.081658\n",
            "Progress:[  112/  120] loss:0.015961\n",
            "Progress:[  120/  120] loss:0.026536\n",
            "Train Error: Avg loss: 0.080828\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.112255\n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004812\n",
            "Progress:[   16/  120] loss:0.001289\n",
            "Progress:[   24/  120] loss:0.106904\n",
            "Progress:[   32/  120] loss:0.026420\n",
            "Progress:[   40/  120] loss:0.002107\n",
            "Progress:[   48/  120] loss:0.080539\n",
            "Progress:[   56/  120] loss:0.040517\n",
            "Progress:[   64/  120] loss:0.582899\n",
            "Progress:[   72/  120] loss:0.006352\n",
            "Progress:[   80/  120] loss:0.149487\n",
            "Progress:[   88/  120] loss:0.085387\n",
            "Progress:[   96/  120] loss:0.005938\n",
            "Progress:[  104/  120] loss:0.079737\n",
            "Progress:[  112/  120] loss:0.014649\n",
            "Progress:[  120/  120] loss:0.025756\n",
            "Train Error: Avg loss: 0.080853\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.114594\n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004589\n",
            "Progress:[   16/  120] loss:0.001244\n",
            "Progress:[   24/  120] loss:0.108361\n",
            "Progress:[   32/  120] loss:0.026022\n",
            "Progress:[   40/  120] loss:0.002043\n",
            "Progress:[   48/  120] loss:0.079658\n",
            "Progress:[   56/  120] loss:0.041617\n",
            "Progress:[   64/  120] loss:0.584399\n",
            "Progress:[   72/  120] loss:0.006375\n",
            "Progress:[   80/  120] loss:0.149092\n",
            "Progress:[   88/  120] loss:0.080281\n",
            "Progress:[   96/  120] loss:0.006232\n",
            "Progress:[  104/  120] loss:0.076248\n",
            "Progress:[  112/  120] loss:0.015533\n",
            "Progress:[  120/  120] loss:0.027018\n",
            "Train Error: Avg loss: 0.080581\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.110895\n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005000\n",
            "Progress:[   16/  120] loss:0.001337\n",
            "Progress:[   24/  120] loss:0.110356\n",
            "Progress:[   32/  120] loss:0.028476\n",
            "Progress:[   40/  120] loss:0.002081\n",
            "Progress:[   48/  120] loss:0.081228\n",
            "Progress:[   56/  120] loss:0.038957\n",
            "Progress:[   64/  120] loss:0.567540\n",
            "Progress:[   72/  120] loss:0.006441\n",
            "Progress:[   80/  120] loss:0.150864\n",
            "Progress:[   88/  120] loss:0.080292\n",
            "Progress:[   96/  120] loss:0.006169\n",
            "Progress:[  104/  120] loss:0.073797\n",
            "Progress:[  112/  120] loss:0.014761\n",
            "Progress:[  120/  120] loss:0.025016\n",
            "Train Error: Avg loss: 0.079488\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.111180\n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004674\n",
            "Progress:[   16/  120] loss:0.001225\n",
            "Progress:[   24/  120] loss:0.105898\n",
            "Progress:[   32/  120] loss:0.025804\n",
            "Progress:[   40/  120] loss:0.001917\n",
            "Progress:[   48/  120] loss:0.078494\n",
            "Progress:[   56/  120] loss:0.040811\n",
            "Progress:[   64/  120] loss:0.596192\n",
            "Progress:[   72/  120] loss:0.005836\n",
            "Progress:[   80/  120] loss:0.146030\n",
            "Progress:[   88/  120] loss:0.090632\n",
            "Progress:[   96/  120] loss:0.005065\n",
            "Progress:[  104/  120] loss:0.082545\n",
            "Progress:[  112/  120] loss:0.015122\n",
            "Progress:[  120/  120] loss:0.026283\n",
            "Train Error: Avg loss: 0.081769\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.115228\n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004661\n",
            "Progress:[   16/  120] loss:0.001177\n",
            "Progress:[   24/  120] loss:0.106088\n",
            "Progress:[   32/  120] loss:0.025757\n",
            "Progress:[   40/  120] loss:0.001908\n",
            "Progress:[   48/  120] loss:0.075813\n",
            "Progress:[   56/  120] loss:0.043651\n",
            "Progress:[   64/  120] loss:0.592518\n",
            "Progress:[   72/  120] loss:0.006155\n",
            "Progress:[   80/  120] loss:0.144366\n",
            "Progress:[   88/  120] loss:0.082002\n",
            "Progress:[   96/  120] loss:0.005682\n",
            "Progress:[  104/  120] loss:0.080593\n",
            "Progress:[  112/  120] loss:0.015978\n",
            "Progress:[  120/  120] loss:0.026660\n",
            "Train Error: Avg loss: 0.080867\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.111721\n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.005060\n",
            "Progress:[   16/  120] loss:0.001289\n",
            "Progress:[   24/  120] loss:0.111240\n",
            "Progress:[   32/  120] loss:0.028162\n",
            "Progress:[   40/  120] loss:0.001940\n",
            "Progress:[   48/  120] loss:0.078623\n",
            "Progress:[   56/  120] loss:0.040219\n",
            "Progress:[   64/  120] loss:0.572763\n",
            "Progress:[   72/  120] loss:0.006273\n",
            "Progress:[   80/  120] loss:0.145417\n",
            "Progress:[   88/  120] loss:0.078746\n",
            "Progress:[   96/  120] loss:0.005905\n",
            "Progress:[  104/  120] loss:0.072898\n",
            "Progress:[  112/  120] loss:0.014643\n",
            "Progress:[  120/  120] loss:0.025703\n",
            "Train Error: Avg loss: 0.079259\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.109893\n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004665\n",
            "Progress:[   16/  120] loss:0.001233\n",
            "Progress:[   24/  120] loss:0.108756\n",
            "Progress:[   32/  120] loss:0.027080\n",
            "Progress:[   40/  120] loss:0.001822\n",
            "Progress:[   48/  120] loss:0.080863\n",
            "Progress:[   56/  120] loss:0.037275\n",
            "Progress:[   64/  120] loss:0.569451\n",
            "Progress:[   72/  120] loss:0.005972\n",
            "Progress:[   80/  120] loss:0.149514\n",
            "Progress:[   88/  120] loss:0.075771\n",
            "Progress:[   96/  120] loss:0.005768\n",
            "Progress:[  104/  120] loss:0.068062\n",
            "Progress:[  112/  120] loss:0.013550\n",
            "Progress:[  120/  120] loss:0.024038\n",
            "Train Error: Avg loss: 0.078255\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.110218\n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004498\n",
            "Progress:[   16/  120] loss:0.001197\n",
            "Progress:[   24/  120] loss:0.109703\n",
            "Progress:[   32/  120] loss:0.026761\n",
            "Progress:[   40/  120] loss:0.001780\n",
            "Progress:[   48/  120] loss:0.080907\n",
            "Progress:[   56/  120] loss:0.038451\n",
            "Progress:[   64/  120] loss:0.566315\n",
            "Progress:[   72/  120] loss:0.006076\n",
            "Progress:[   80/  120] loss:0.150939\n",
            "Progress:[   88/  120] loss:0.071712\n",
            "Progress:[   96/  120] loss:0.006082\n",
            "Progress:[  104/  120] loss:0.070253\n",
            "Progress:[  112/  120] loss:0.014349\n",
            "Progress:[  120/  120] loss:0.024986\n",
            "Train Error: Avg loss: 0.078267\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.110628\n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004489\n",
            "Progress:[   16/  120] loss:0.001240\n",
            "Progress:[   24/  120] loss:0.112148\n",
            "Progress:[   32/  120] loss:0.027257\n",
            "Progress:[   40/  120] loss:0.001816\n",
            "Progress:[   48/  120] loss:0.080651\n",
            "Progress:[   56/  120] loss:0.037867\n",
            "Progress:[   64/  120] loss:0.561996\n",
            "Progress:[   72/  120] loss:0.006208\n",
            "Progress:[   80/  120] loss:0.145368\n",
            "Progress:[   88/  120] loss:0.073752\n",
            "Progress:[   96/  120] loss:0.006050\n",
            "Progress:[  104/  120] loss:0.069446\n",
            "Progress:[  112/  120] loss:0.013877\n",
            "Progress:[  120/  120] loss:0.023893\n",
            "Train Error: Avg loss: 0.077737\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.103324\n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004525\n",
            "Progress:[   16/  120] loss:0.001206\n",
            "Progress:[   24/  120] loss:0.106295\n",
            "Progress:[   32/  120] loss:0.027447\n",
            "Progress:[   40/  120] loss:0.001740\n",
            "Progress:[   48/  120] loss:0.081239\n",
            "Progress:[   56/  120] loss:0.034955\n",
            "Progress:[   64/  120] loss:0.557807\n",
            "Progress:[   72/  120] loss:0.005955\n",
            "Progress:[   80/  120] loss:0.145060\n",
            "Progress:[   88/  120] loss:0.073424\n",
            "Progress:[   96/  120] loss:0.005545\n",
            "Progress:[  104/  120] loss:0.066476\n",
            "Progress:[  112/  120] loss:0.012820\n",
            "Progress:[  120/  120] loss:0.022314\n",
            "Train Error: Avg loss: 0.076454\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.103541\n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004290\n",
            "Progress:[   16/  120] loss:0.001147\n",
            "Progress:[   24/  120] loss:0.103949\n",
            "Progress:[   32/  120] loss:0.026050\n",
            "Progress:[   40/  120] loss:0.001718\n",
            "Progress:[   48/  120] loss:0.078599\n",
            "Progress:[   56/  120] loss:0.038972\n",
            "Progress:[   64/  120] loss:0.561008\n",
            "Progress:[   72/  120] loss:0.006160\n",
            "Progress:[   80/  120] loss:0.144812\n",
            "Progress:[   88/  120] loss:0.072567\n",
            "Progress:[   96/  120] loss:0.005969\n",
            "Progress:[  104/  120] loss:0.071624\n",
            "Progress:[  112/  120] loss:0.014538\n",
            "Progress:[  120/  120] loss:0.025579\n",
            "Train Error: Avg loss: 0.077132\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.106755\n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004519\n",
            "Progress:[   16/  120] loss:0.001230\n",
            "Progress:[   24/  120] loss:0.111455\n",
            "Progress:[   32/  120] loss:0.027246\n",
            "Progress:[   40/  120] loss:0.001728\n",
            "Progress:[   48/  120] loss:0.080622\n",
            "Progress:[   56/  120] loss:0.036313\n",
            "Progress:[   64/  120] loss:0.557250\n",
            "Progress:[   72/  120] loss:0.005940\n",
            "Progress:[   80/  120] loss:0.145978\n",
            "Progress:[   88/  120] loss:0.069666\n",
            "Progress:[   96/  120] loss:0.005648\n",
            "Progress:[  104/  120] loss:0.065198\n",
            "Progress:[  112/  120] loss:0.012916\n",
            "Progress:[  120/  120] loss:0.022655\n",
            "Train Error: Avg loss: 0.076558\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.107959\n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004350\n",
            "Progress:[   16/  120] loss:0.001155\n",
            "Progress:[   24/  120] loss:0.108070\n",
            "Progress:[   32/  120] loss:0.026718\n",
            "Progress:[   40/  120] loss:0.001601\n",
            "Progress:[   48/  120] loss:0.082913\n",
            "Progress:[   56/  120] loss:0.035318\n",
            "Progress:[   64/  120] loss:0.557037\n",
            "Progress:[   72/  120] loss:0.005782\n",
            "Progress:[   80/  120] loss:0.152398\n",
            "Progress:[   88/  120] loss:0.064766\n",
            "Progress:[   96/  120] loss:0.005949\n",
            "Progress:[  104/  120] loss:0.062899\n",
            "Progress:[  112/  120] loss:0.012983\n",
            "Progress:[  120/  120] loss:0.023948\n",
            "Train Error: Avg loss: 0.076393\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.108250\n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004234\n",
            "Progress:[   16/  120] loss:0.001178\n",
            "Progress:[   24/  120] loss:0.110630\n",
            "Progress:[   32/  120] loss:0.027068\n",
            "Progress:[   40/  120] loss:0.001634\n",
            "Progress:[   48/  120] loss:0.082294\n",
            "Progress:[   56/  120] loss:0.034692\n",
            "Progress:[   64/  120] loss:0.550846\n",
            "Progress:[   72/  120] loss:0.006034\n",
            "Progress:[   80/  120] loss:0.141941\n",
            "Progress:[   88/  120] loss:0.068471\n",
            "Progress:[   96/  120] loss:0.005853\n",
            "Progress:[  104/  120] loss:0.065939\n",
            "Progress:[  112/  120] loss:0.012749\n",
            "Progress:[  120/  120] loss:0.022266\n",
            "Train Error: Avg loss: 0.075722\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.098849\n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004302\n",
            "Progress:[   16/  120] loss:0.001137\n",
            "Progress:[   24/  120] loss:0.104352\n",
            "Progress:[   32/  120] loss:0.026519\n",
            "Progress:[   40/  120] loss:0.001581\n",
            "Progress:[   48/  120] loss:0.081018\n",
            "Progress:[   56/  120] loss:0.034414\n",
            "Progress:[   64/  120] loss:0.550897\n",
            "Progress:[   72/  120] loss:0.005813\n",
            "Progress:[   80/  120] loss:0.146983\n",
            "Progress:[   88/  120] loss:0.069100\n",
            "Progress:[   96/  120] loss:0.005462\n",
            "Progress:[  104/  120] loss:0.063511\n",
            "Progress:[  112/  120] loss:0.012533\n",
            "Progress:[  120/  120] loss:0.022958\n",
            "Train Error: Avg loss: 0.075372\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.105201\n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004058\n",
            "Progress:[   16/  120] loss:0.001115\n",
            "Progress:[   24/  120] loss:0.106794\n",
            "Progress:[   32/  120] loss:0.025949\n",
            "Progress:[   40/  120] loss:0.001544\n",
            "Progress:[   48/  120] loss:0.079142\n",
            "Progress:[   56/  120] loss:0.035518\n",
            "Progress:[   64/  120] loss:0.555800\n",
            "Progress:[   72/  120] loss:0.005845\n",
            "Progress:[   80/  120] loss:0.140919\n",
            "Progress:[   88/  120] loss:0.069194\n",
            "Progress:[   96/  120] loss:0.005366\n",
            "Progress:[  104/  120] loss:0.068039\n",
            "Progress:[  112/  120] loss:0.012544\n",
            "Progress:[  120/  120] loss:0.022445\n",
            "Train Error: Avg loss: 0.075618\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.098216\n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004276\n",
            "Progress:[   16/  120] loss:0.001107\n",
            "Progress:[   24/  120] loss:0.105933\n",
            "Progress:[   32/  120] loss:0.026490\n",
            "Progress:[   40/  120] loss:0.001534\n",
            "Progress:[   48/  120] loss:0.077855\n",
            "Progress:[   56/  120] loss:0.035819\n",
            "Progress:[   64/  120] loss:0.552921\n",
            "Progress:[   72/  120] loss:0.005827\n",
            "Progress:[   80/  120] loss:0.144298\n",
            "Progress:[   88/  120] loss:0.066774\n",
            "Progress:[   96/  120] loss:0.005410\n",
            "Progress:[  104/  120] loss:0.063897\n",
            "Progress:[  112/  120] loss:0.013168\n",
            "Progress:[  120/  120] loss:0.023877\n",
            "Train Error: Avg loss: 0.075279\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.108350\n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004341\n",
            "Progress:[   16/  120] loss:0.001160\n",
            "Progress:[   24/  120] loss:0.111572\n",
            "Progress:[   32/  120] loss:0.027163\n",
            "Progress:[   40/  120] loss:0.001527\n",
            "Progress:[   48/  120] loss:0.080718\n",
            "Progress:[   56/  120] loss:0.033993\n",
            "Progress:[   64/  120] loss:0.551873\n",
            "Progress:[   72/  120] loss:0.005812\n",
            "Progress:[   80/  120] loss:0.143324\n",
            "Progress:[   88/  120] loss:0.064671\n",
            "Progress:[   96/  120] loss:0.005729\n",
            "Progress:[  104/  120] loss:0.062210\n",
            "Progress:[  112/  120] loss:0.012115\n",
            "Progress:[  120/  120] loss:0.021300\n",
            "Train Error: Avg loss: 0.075167\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.095228\n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004254\n",
            "Progress:[   16/  120] loss:0.001107\n",
            "Progress:[   24/  120] loss:0.104263\n",
            "Progress:[   32/  120] loss:0.026907\n",
            "Progress:[   40/  120] loss:0.001472\n",
            "Progress:[   48/  120] loss:0.082853\n",
            "Progress:[   56/  120] loss:0.031248\n",
            "Progress:[   64/  120] loss:0.540758\n",
            "Progress:[   72/  120] loss:0.005712\n",
            "Progress:[   80/  120] loss:0.143912\n",
            "Progress:[   88/  120] loss:0.064575\n",
            "Progress:[   96/  120] loss:0.005344\n",
            "Progress:[  104/  120] loss:0.058682\n",
            "Progress:[  112/  120] loss:0.011659\n",
            "Progress:[  120/  120] loss:0.020638\n",
            "Train Error: Avg loss: 0.073559\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.097082\n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003838\n",
            "Progress:[   16/  120] loss:0.001075\n",
            "Progress:[   24/  120] loss:0.104233\n",
            "Progress:[   32/  120] loss:0.024755\n",
            "Progress:[   40/  120] loss:0.001493\n",
            "Progress:[   48/  120] loss:0.077967\n",
            "Progress:[   56/  120] loss:0.035115\n",
            "Progress:[   64/  120] loss:0.542985\n",
            "Progress:[   72/  120] loss:0.006036\n",
            "Progress:[   80/  120] loss:0.136758\n",
            "Progress:[   88/  120] loss:0.066547\n",
            "Progress:[   96/  120] loss:0.005220\n",
            "Progress:[  104/  120] loss:0.066310\n",
            "Progress:[  112/  120] loss:0.013046\n",
            "Progress:[  120/  120] loss:0.022441\n",
            "Train Error: Avg loss: 0.073855\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.099122\n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004357\n",
            "Progress:[   16/  120] loss:0.001119\n",
            "Progress:[   24/  120] loss:0.106863\n",
            "Progress:[   32/  120] loss:0.026698\n",
            "Progress:[   40/  120] loss:0.001463\n",
            "Progress:[   48/  120] loss:0.078956\n",
            "Progress:[   56/  120] loss:0.033112\n",
            "Progress:[   64/  120] loss:0.544846\n",
            "Progress:[   72/  120] loss:0.005810\n",
            "Progress:[   80/  120] loss:0.139946\n",
            "Progress:[   88/  120] loss:0.065292\n",
            "Progress:[   96/  120] loss:0.005132\n",
            "Progress:[  104/  120] loss:0.062072\n",
            "Progress:[  112/  120] loss:0.012024\n",
            "Progress:[  120/  120] loss:0.021136\n",
            "Train Error: Avg loss: 0.073922\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.099143\n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004117\n",
            "Progress:[   16/  120] loss:0.001079\n",
            "Progress:[   24/  120] loss:0.107334\n",
            "Progress:[   32/  120] loss:0.025864\n",
            "Progress:[   40/  120] loss:0.001395\n",
            "Progress:[   48/  120] loss:0.079176\n",
            "Progress:[   56/  120] loss:0.033226\n",
            "Progress:[   64/  120] loss:0.547513\n",
            "Progress:[   72/  120] loss:0.005661\n",
            "Progress:[   80/  120] loss:0.141265\n",
            "Progress:[   88/  120] loss:0.061152\n",
            "Progress:[   96/  120] loss:0.005253\n",
            "Progress:[  104/  120] loss:0.060806\n",
            "Progress:[  112/  120] loss:0.011874\n",
            "Progress:[  120/  120] loss:0.021142\n",
            "Train Error: Avg loss: 0.073791\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.096884\n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004103\n",
            "Progress:[   16/  120] loss:0.001087\n",
            "Progress:[   24/  120] loss:0.105341\n",
            "Progress:[   32/  120] loss:0.025862\n",
            "Progress:[   40/  120] loss:0.001405\n",
            "Progress:[   48/  120] loss:0.081682\n",
            "Progress:[   56/  120] loss:0.032080\n",
            "Progress:[   64/  120] loss:0.536174\n",
            "Progress:[   72/  120] loss:0.005764\n",
            "Progress:[   80/  120] loss:0.141709\n",
            "Progress:[   88/  120] loss:0.060949\n",
            "Progress:[   96/  120] loss:0.005264\n",
            "Progress:[  104/  120] loss:0.058866\n",
            "Progress:[  112/  120] loss:0.011813\n",
            "Progress:[  120/  120] loss:0.020365\n",
            "Train Error: Avg loss: 0.072831\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.094949\n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003941\n",
            "Progress:[   16/  120] loss:0.001088\n",
            "Progress:[   24/  120] loss:0.105654\n",
            "Progress:[   32/  120] loss:0.025446\n",
            "Progress:[   40/  120] loss:0.001417\n",
            "Progress:[   48/  120] loss:0.077466\n",
            "Progress:[   56/  120] loss:0.034019\n",
            "Progress:[   64/  120] loss:0.536605\n",
            "Progress:[   72/  120] loss:0.006045\n",
            "Progress:[   80/  120] loss:0.133333\n",
            "Progress:[   88/  120] loss:0.062246\n",
            "Progress:[   96/  120] loss:0.005086\n",
            "Progress:[  104/  120] loss:0.065372\n",
            "Progress:[  112/  120] loss:0.012502\n",
            "Progress:[  120/  120] loss:0.020789\n",
            "Train Error: Avg loss: 0.072734\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.093485\n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004256\n",
            "Progress:[   16/  120] loss:0.001094\n",
            "Progress:[   24/  120] loss:0.102943\n",
            "Progress:[   32/  120] loss:0.026135\n",
            "Progress:[   40/  120] loss:0.001393\n",
            "Progress:[   48/  120] loss:0.077686\n",
            "Progress:[   56/  120] loss:0.032614\n",
            "Progress:[   64/  120] loss:0.537281\n",
            "Progress:[   72/  120] loss:0.005856\n",
            "Progress:[   80/  120] loss:0.137934\n",
            "Progress:[   88/  120] loss:0.060552\n",
            "Progress:[   96/  120] loss:0.004975\n",
            "Progress:[  104/  120] loss:0.061759\n",
            "Progress:[  112/  120] loss:0.012016\n",
            "Progress:[  120/  120] loss:0.021520\n",
            "Train Error: Avg loss: 0.072534\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.097373\n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004103\n",
            "Progress:[   16/  120] loss:0.001078\n",
            "Progress:[   24/  120] loss:0.105695\n",
            "Progress:[   32/  120] loss:0.025649\n",
            "Progress:[   40/  120] loss:0.001338\n",
            "Progress:[   48/  120] loss:0.079017\n",
            "Progress:[   56/  120] loss:0.032355\n",
            "Progress:[   64/  120] loss:0.538095\n",
            "Progress:[   72/  120] loss:0.005796\n",
            "Progress:[   80/  120] loss:0.139461\n",
            "Progress:[   88/  120] loss:0.058435\n",
            "Progress:[   96/  120] loss:0.005224\n",
            "Progress:[  104/  120] loss:0.060453\n",
            "Progress:[  112/  120] loss:0.011838\n",
            "Progress:[  120/  120] loss:0.020386\n",
            "Train Error: Avg loss: 0.072595\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.093145\n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004157\n",
            "Progress:[   16/  120] loss:0.001089\n",
            "Progress:[   24/  120] loss:0.105580\n",
            "Progress:[   32/  120] loss:0.026542\n",
            "Progress:[   40/  120] loss:0.001360\n",
            "Progress:[   48/  120] loss:0.079377\n",
            "Progress:[   56/  120] loss:0.031006\n",
            "Progress:[   64/  120] loss:0.533891\n",
            "Progress:[   72/  120] loss:0.005968\n",
            "Progress:[   80/  120] loss:0.136516\n",
            "Progress:[   88/  120] loss:0.056948\n",
            "Progress:[   96/  120] loss:0.005259\n",
            "Progress:[  104/  120] loss:0.060932\n",
            "Progress:[  112/  120] loss:0.011662\n",
            "Progress:[  120/  120] loss:0.020022\n",
            "Train Error: Avg loss: 0.072021\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.093499\n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004099\n",
            "Progress:[   16/  120] loss:0.001067\n",
            "Progress:[   24/  120] loss:0.103676\n",
            "Progress:[   32/  120] loss:0.026195\n",
            "Progress:[   40/  120] loss:0.001318\n",
            "Progress:[   48/  120] loss:0.078899\n",
            "Progress:[   56/  120] loss:0.029049\n",
            "Progress:[   64/  120] loss:0.537324\n",
            "Progress:[   72/  120] loss:0.005940\n",
            "Progress:[   80/  120] loss:0.133294\n",
            "Progress:[   88/  120] loss:0.057839\n",
            "Progress:[   96/  120] loss:0.005045\n",
            "Progress:[  104/  120] loss:0.060824\n",
            "Progress:[  112/  120] loss:0.011157\n",
            "Progress:[  120/  120] loss:0.018704\n",
            "Train Error: Avg loss: 0.071629\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.088333\n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004149\n",
            "Progress:[   16/  120] loss:0.001037\n",
            "Progress:[   24/  120] loss:0.099262\n",
            "Progress:[   32/  120] loss:0.026095\n",
            "Progress:[   40/  120] loss:0.001292\n",
            "Progress:[   48/  120] loss:0.076648\n",
            "Progress:[   56/  120] loss:0.030980\n",
            "Progress:[   64/  120] loss:0.532493\n",
            "Progress:[   72/  120] loss:0.006081\n",
            "Progress:[   80/  120] loss:0.134727\n",
            "Progress:[   88/  120] loss:0.057217\n",
            "Progress:[   96/  120] loss:0.005133\n",
            "Progress:[  104/  120] loss:0.062381\n",
            "Progress:[  112/  120] loss:0.011968\n",
            "Progress:[  120/  120] loss:0.020617\n",
            "Train Error: Avg loss: 0.071339\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.091002\n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004158\n",
            "Progress:[   16/  120] loss:0.001077\n",
            "Progress:[   24/  120] loss:0.102875\n",
            "Progress:[   32/  120] loss:0.026397\n",
            "Progress:[   40/  120] loss:0.001307\n",
            "Progress:[   48/  120] loss:0.078578\n",
            "Progress:[   56/  120] loss:0.029398\n",
            "Progress:[   64/  120] loss:0.527663\n",
            "Progress:[   72/  120] loss:0.006085\n",
            "Progress:[   80/  120] loss:0.130967\n",
            "Progress:[   88/  120] loss:0.056436\n",
            "Progress:[   96/  120] loss:0.004966\n",
            "Progress:[  104/  120] loss:0.060379\n",
            "Progress:[  112/  120] loss:0.011152\n",
            "Progress:[  120/  120] loss:0.018703\n",
            "Train Error: Avg loss: 0.070676\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.083265\n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004068\n",
            "Progress:[   16/  120] loss:0.001039\n",
            "Progress:[   24/  120] loss:0.094527\n",
            "Progress:[   32/  120] loss:0.025744\n",
            "Progress:[   40/  120] loss:0.001301\n",
            "Progress:[   48/  120] loss:0.073018\n",
            "Progress:[   56/  120] loss:0.031646\n",
            "Progress:[   64/  120] loss:0.529743\n",
            "Progress:[   72/  120] loss:0.006304\n",
            "Progress:[   80/  120] loss:0.127796\n",
            "Progress:[   88/  120] loss:0.060520\n",
            "Progress:[   96/  120] loss:0.004822\n",
            "Progress:[  104/  120] loss:0.064220\n",
            "Progress:[  112/  120] loss:0.012261\n",
            "Progress:[  120/  120] loss:0.020397\n",
            "Train Error: Avg loss: 0.070494\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.087866\n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004288\n",
            "Progress:[   16/  120] loss:0.001075\n",
            "Progress:[   24/  120] loss:0.099533\n",
            "Progress:[   32/  120] loss:0.026053\n",
            "Progress:[   40/  120] loss:0.001271\n",
            "Progress:[   48/  120] loss:0.075935\n",
            "Progress:[   56/  120] loss:0.031052\n",
            "Progress:[   64/  120] loss:0.529630\n",
            "Progress:[   72/  120] loss:0.006014\n",
            "Progress:[   80/  120] loss:0.134343\n",
            "Progress:[   88/  120] loss:0.053916\n",
            "Progress:[   96/  120] loss:0.004832\n",
            "Progress:[  104/  120] loss:0.059869\n",
            "Progress:[  112/  120] loss:0.011347\n",
            "Progress:[  120/  120] loss:0.019244\n",
            "Train Error: Avg loss: 0.070560\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.087787\n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004062\n",
            "Progress:[   16/  120] loss:0.001049\n",
            "Progress:[   24/  120] loss:0.100054\n",
            "Progress:[   32/  120] loss:0.025916\n",
            "Progress:[   40/  120] loss:0.001251\n",
            "Progress:[   48/  120] loss:0.074147\n",
            "Progress:[   56/  120] loss:0.029614\n",
            "Progress:[   64/  120] loss:0.505969\n",
            "Progress:[   72/  120] loss:0.007539\n",
            "Progress:[   80/  120] loss:0.104140\n",
            "Progress:[   88/  120] loss:0.077790\n",
            "Progress:[   96/  120] loss:0.003753\n",
            "Progress:[  104/  120] loss:0.084774\n",
            "Progress:[  112/  120] loss:0.014033\n",
            "Progress:[  120/  120] loss:0.020083\n",
            "Train Error: Avg loss: 0.070278\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.070567\n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003846\n",
            "Progress:[   16/  120] loss:0.001135\n",
            "Progress:[   24/  120] loss:0.077682\n",
            "Progress:[   32/  120] loss:0.018177\n",
            "Progress:[   40/  120] loss:0.001216\n",
            "Progress:[   48/  120] loss:0.058716\n",
            "Progress:[   56/  120] loss:0.044648\n",
            "Progress:[   64/  120] loss:0.580439\n",
            "Progress:[   72/  120] loss:0.005067\n",
            "Progress:[   80/  120] loss:0.134651\n",
            "Progress:[   88/  120] loss:0.073081\n",
            "Progress:[   96/  120] loss:0.002629\n",
            "Progress:[  104/  120] loss:0.074971\n",
            "Progress:[  112/  120] loss:0.013308\n",
            "Progress:[  120/  120] loss:0.025605\n",
            "Train Error: Avg loss: 0.074345\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.121331\n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004344\n",
            "Progress:[   16/  120] loss:0.001173\n",
            "Progress:[   24/  120] loss:0.110395\n",
            "Progress:[   32/  120] loss:0.023882\n",
            "Progress:[   40/  120] loss:0.001117\n",
            "Progress:[   48/  120] loss:0.066148\n",
            "Progress:[   56/  120] loss:0.042584\n",
            "Progress:[   64/  120] loss:0.570984\n",
            "Progress:[   72/  120] loss:0.005718\n",
            "Progress:[   80/  120] loss:0.138104\n",
            "Progress:[   88/  120] loss:0.052618\n",
            "Progress:[   96/  120] loss:0.004766\n",
            "Progress:[  104/  120] loss:0.070730\n",
            "Progress:[  112/  120] loss:0.013835\n",
            "Progress:[  120/  120] loss:0.023391\n",
            "Train Error: Avg loss: 0.075319\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.095658\n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004824\n",
            "Progress:[   16/  120] loss:0.001127\n",
            "Progress:[   24/  120] loss:0.098605\n",
            "Progress:[   32/  120] loss:0.025011\n",
            "Progress:[   40/  120] loss:0.001084\n",
            "Progress:[   48/  120] loss:0.071586\n",
            "Progress:[   56/  120] loss:0.035195\n",
            "Progress:[   64/  120] loss:0.580269\n",
            "Progress:[   72/  120] loss:0.004658\n",
            "Progress:[   80/  120] loss:0.143660\n",
            "Progress:[   88/  120] loss:0.064842\n",
            "Progress:[   96/  120] loss:0.003093\n",
            "Progress:[  104/  120] loss:0.070437\n",
            "Progress:[  112/  120] loss:0.012449\n",
            "Progress:[  120/  120] loss:0.024746\n",
            "Train Error: Avg loss: 0.076106\n",
            "Test Error: Accuracy: 90.0%, Avg loss: 0.116570\n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004327\n",
            "Progress:[   16/  120] loss:0.001001\n",
            "Progress:[   24/  120] loss:0.105713\n",
            "Progress:[   32/  120] loss:0.024485\n",
            "Progress:[   40/  120] loss:0.001046\n",
            "Progress:[   48/  120] loss:0.071914\n",
            "Progress:[   56/  120] loss:0.038943\n",
            "Progress:[   64/  120] loss:0.566795\n",
            "Progress:[   72/  120] loss:0.005236\n",
            "Progress:[   80/  120] loss:0.145826\n",
            "Progress:[   88/  120] loss:0.050568\n",
            "Progress:[   96/  120] loss:0.004808\n",
            "Progress:[  104/  120] loss:0.064685\n",
            "Progress:[  112/  120] loss:0.012791\n",
            "Progress:[  120/  120] loss:0.023669\n",
            "Train Error: Avg loss: 0.074787\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.095822\n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004701\n",
            "Progress:[   16/  120] loss:0.001137\n",
            "Progress:[   24/  120] loss:0.111650\n",
            "Progress:[   32/  120] loss:0.028784\n",
            "Progress:[   40/  120] loss:0.001192\n",
            "Progress:[   48/  120] loss:0.082021\n",
            "Progress:[   56/  120] loss:0.029195\n",
            "Progress:[   64/  120] loss:0.525584\n",
            "Progress:[   72/  120] loss:0.005733\n",
            "Progress:[   80/  120] loss:0.134886\n",
            "Progress:[   88/  120] loss:0.049392\n",
            "Progress:[   96/  120] loss:0.004744\n",
            "Progress:[  104/  120] loss:0.057101\n",
            "Progress:[  112/  120] loss:0.010380\n",
            "Progress:[  120/  120] loss:0.018106\n",
            "Train Error: Avg loss: 0.070974\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.083925\n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003927\n",
            "Progress:[   16/  120] loss:0.000980\n",
            "Progress:[   24/  120] loss:0.094735\n",
            "Progress:[   32/  120] loss:0.024410\n",
            "Progress:[   40/  120] loss:0.001071\n",
            "Progress:[   48/  120] loss:0.073521\n",
            "Progress:[   56/  120] loss:0.030801\n",
            "Progress:[   64/  120] loss:0.528254\n",
            "Progress:[   72/  120] loss:0.005761\n",
            "Progress:[   80/  120] loss:0.130288\n",
            "Progress:[   88/  120] loss:0.053045\n",
            "Progress:[   96/  120] loss:0.003968\n",
            "Progress:[  104/  120] loss:0.061836\n",
            "Progress:[  112/  120] loss:0.011485\n",
            "Progress:[  120/  120] loss:0.020380\n",
            "Train Error: Avg loss: 0.069631\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.093617\n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004259\n",
            "Progress:[   16/  120] loss:0.001028\n",
            "Progress:[   24/  120] loss:0.103585\n",
            "Progress:[   32/  120] loss:0.025919\n",
            "Progress:[   40/  120] loss:0.001029\n",
            "Progress:[   48/  120] loss:0.077933\n",
            "Progress:[   56/  120] loss:0.028961\n",
            "Progress:[   64/  120] loss:0.535236\n",
            "Progress:[   72/  120] loss:0.005459\n",
            "Progress:[   80/  120] loss:0.138987\n",
            "Progress:[   88/  120] loss:0.045109\n",
            "Progress:[   96/  120] loss:0.004646\n",
            "Progress:[  104/  120] loss:0.055562\n",
            "Progress:[  112/  120] loss:0.010448\n",
            "Progress:[  120/  120] loss:0.018157\n",
            "Train Error: Avg loss: 0.070421\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.082671\n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004134\n",
            "Progress:[   16/  120] loss:0.001028\n",
            "Progress:[   24/  120] loss:0.097212\n",
            "Progress:[   32/  120] loss:0.026581\n",
            "Progress:[   40/  120] loss:0.001094\n",
            "Progress:[   48/  120] loss:0.076503\n",
            "Progress:[   56/  120] loss:0.027717\n",
            "Progress:[   64/  120] loss:0.513487\n",
            "Progress:[   72/  120] loss:0.006332\n",
            "Progress:[   80/  120] loss:0.123363\n",
            "Progress:[   88/  120] loss:0.052877\n",
            "Progress:[   96/  120] loss:0.004550\n",
            "Progress:[  104/  120] loss:0.061570\n",
            "Progress:[  112/  120] loss:0.011124\n",
            "Progress:[  120/  120] loss:0.018110\n",
            "Train Error: Avg loss: 0.068379\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.075940\n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004040\n",
            "Progress:[   16/  120] loss:0.001014\n",
            "Progress:[   24/  120] loss:0.093826\n",
            "Progress:[   32/  120] loss:0.024317\n",
            "Progress:[   40/  120] loss:0.001074\n",
            "Progress:[   48/  120] loss:0.068904\n",
            "Progress:[   56/  120] loss:0.031217\n",
            "Progress:[   64/  120] loss:0.521278\n",
            "Progress:[   72/  120] loss:0.006118\n",
            "Progress:[   80/  120] loss:0.124727\n",
            "Progress:[   88/  120] loss:0.051859\n",
            "Progress:[   96/  120] loss:0.003853\n",
            "Progress:[  104/  120] loss:0.062539\n",
            "Progress:[  112/  120] loss:0.011610\n",
            "Progress:[  120/  120] loss:0.019331\n",
            "Train Error: Avg loss: 0.068381\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.093034\n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004303\n",
            "Progress:[   16/  120] loss:0.001041\n",
            "Progress:[   24/  120] loss:0.102255\n",
            "Progress:[   32/  120] loss:0.025408\n",
            "Progress:[   40/  120] loss:0.001015\n",
            "Progress:[   48/  120] loss:0.077619\n",
            "Progress:[   56/  120] loss:0.028917\n",
            "Progress:[   64/  120] loss:0.525095\n",
            "Progress:[   72/  120] loss:0.005697\n",
            "Progress:[   80/  120] loss:0.136230\n",
            "Progress:[   88/  120] loss:0.044191\n",
            "Progress:[   96/  120] loss:0.004699\n",
            "Progress:[  104/  120] loss:0.055707\n",
            "Progress:[  112/  120] loss:0.010581\n",
            "Progress:[  120/  120] loss:0.017966\n",
            "Train Error: Avg loss: 0.069382\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.082738\n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004086\n",
            "Progress:[   16/  120] loss:0.001041\n",
            "Progress:[   24/  120] loss:0.099038\n",
            "Progress:[   32/  120] loss:0.026062\n",
            "Progress:[   40/  120] loss:0.001052\n",
            "Progress:[   48/  120] loss:0.080367\n",
            "Progress:[   56/  120] loss:0.026097\n",
            "Progress:[   64/  120] loss:0.507437\n",
            "Progress:[   72/  120] loss:0.006101\n",
            "Progress:[   80/  120] loss:0.127531\n",
            "Progress:[   88/  120] loss:0.047352\n",
            "Progress:[   96/  120] loss:0.004583\n",
            "Progress:[  104/  120] loss:0.055438\n",
            "Progress:[  112/  120] loss:0.010236\n",
            "Progress:[  120/  120] loss:0.016729\n",
            "Train Error: Avg loss: 0.067543\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.070807\n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003822\n",
            "Progress:[   16/  120] loss:0.001005\n",
            "Progress:[   24/  120] loss:0.089048\n",
            "Progress:[   32/  120] loss:0.023838\n",
            "Progress:[   40/  120] loss:0.001047\n",
            "Progress:[   48/  120] loss:0.072711\n",
            "Progress:[   56/  120] loss:0.028696\n",
            "Progress:[   64/  120] loss:0.504973\n",
            "Progress:[   72/  120] loss:0.006299\n",
            "Progress:[   80/  120] loss:0.124064\n",
            "Progress:[   88/  120] loss:0.050743\n",
            "Progress:[   96/  120] loss:0.003906\n",
            "Progress:[  104/  120] loss:0.058783\n",
            "Progress:[  112/  120] loss:0.011276\n",
            "Progress:[  120/  120] loss:0.018643\n",
            "Train Error: Avg loss: 0.066590\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.083695\n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004060\n",
            "Progress:[   16/  120] loss:0.001038\n",
            "Progress:[   24/  120] loss:0.094064\n",
            "Progress:[   32/  120] loss:0.024599\n",
            "Progress:[   40/  120] loss:0.001015\n",
            "Progress:[   48/  120] loss:0.078248\n",
            "Progress:[   56/  120] loss:0.026318\n",
            "Progress:[   64/  120] loss:0.508660\n",
            "Progress:[   72/  120] loss:0.005984\n",
            "Progress:[   80/  120] loss:0.128166\n",
            "Progress:[   88/  120] loss:0.045876\n",
            "Progress:[   96/  120] loss:0.004236\n",
            "Progress:[  104/  120] loss:0.053963\n",
            "Progress:[  112/  120] loss:0.010172\n",
            "Progress:[  120/  120] loss:0.017160\n",
            "Train Error: Avg loss: 0.066904\n",
            "Test Error: Accuracy: 93.3%, Avg loss: 0.077093\n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003955\n",
            "Progress:[   16/  120] loss:0.001008\n",
            "Progress:[   24/  120] loss:0.089231\n",
            "Progress:[   32/  120] loss:0.024710\n",
            "Progress:[   40/  120] loss:0.001004\n",
            "Progress:[   48/  120] loss:0.075452\n",
            "Progress:[   56/  120] loss:0.025337\n",
            "Progress:[   64/  120] loss:0.503576\n",
            "Progress:[   72/  120] loss:0.006176\n",
            "Progress:[   80/  120] loss:0.125127\n",
            "Progress:[   88/  120] loss:0.049896\n",
            "Progress:[   96/  120] loss:0.004139\n",
            "Progress:[  104/  120] loss:0.053507\n",
            "Progress:[  112/  120] loss:0.010361\n",
            "Progress:[  120/  120] loss:0.017209\n",
            "Train Error: Avg loss: 0.066046\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.073271\n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.003831\n",
            "Progress:[   16/  120] loss:0.001006\n",
            "Progress:[   24/  120] loss:0.088570\n",
            "Progress:[   32/  120] loss:0.023471\n",
            "Progress:[   40/  120] loss:0.001015\n",
            "Progress:[   48/  120] loss:0.073890\n",
            "Progress:[   56/  120] loss:0.028271\n",
            "Progress:[   64/  120] loss:0.503827\n",
            "Progress:[   72/  120] loss:0.006334\n",
            "Progress:[   80/  120] loss:0.122768\n",
            "Progress:[   88/  120] loss:0.049184\n",
            "Progress:[   96/  120] loss:0.004203\n",
            "Progress:[  104/  120] loss:0.057281\n",
            "Progress:[  112/  120] loss:0.010627\n",
            "Progress:[  120/  120] loss:0.017916\n",
            "Train Error: Avg loss: 0.066146\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.070561\n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Progress:[    8/  120] loss:0.004003\n",
            "Progress:[   16/  120] loss:0.001009\n",
            "Progress:[   24/  120] loss:0.090571\n",
            "Progress:[   32/  120] loss:0.024203\n",
            "Progress:[   40/  120] loss:0.000983\n",
            "Progress:[   48/  120] loss:0.072413\n",
            "Progress:[   56/  120] loss:0.026994\n",
            "Progress:[   64/  120] loss:0.503749\n",
            "Progress:[   72/  120] loss:0.006397\n",
            "Progress:[   80/  120] loss:0.120452\n",
            "Progress:[   88/  120] loss:0.048765\n",
            "Progress:[   96/  120] loss:0.003732\n",
            "Progress:[  104/  120] loss:0.058158\n",
            "Progress:[  112/  120] loss:0.010400\n",
            "Progress:[  120/  120] loss:0.017309\n",
            "Train Error: Avg loss: 0.065943\n",
            "Test Error: Accuracy: 100.0%, Avg loss: 0.074489\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training and test loss\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs'), plt.ylabel('Loss'), plt.title('Training and Test Loss Over Epochs')\n",
        "plt.legend(), plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "zL0y7Y1IB0CS",
        "outputId": "688a83f6-a2b6-4346-949a-a806d02d0b4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.legend.Legend at 0x7a0369447250>, None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}