{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9Cfp3KbCQFMBDZAUQ36b8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsinposts/Machine-Learning-Collection/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0DRWjPvcBUVT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import pandas as pd\n",
        "import re\n",
        "import gensim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXZFLPO6BV6-",
        "outputId": "1386494d-d9ef-4fe6-d693-3ef683511b85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "replace twitter_training.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace twitter_validation.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9rIL_s3Wk6f",
        "outputId": "657a781f-aba1-4c3b-a4b9-c3929ce5c2e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "input_size = 100\n",
        "hidden_size = 250\n",
        "num_classes = 2\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "qCeIoYYmVU9P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/twitter_training.csv')\n",
        "test_df = pd.read_csv('/content/twitter_validation.csv')\n",
        "\n",
        "# only keep relevent columns\n",
        "train_df = train_df.iloc[:, [2, -1]]\n",
        "test_df = test_df.iloc[:, [2, -1]]\n",
        "\n",
        "# rename columns\n",
        "train_df.columns = ['sentiment', 'tweet']\n",
        "test_df.columns = ['sentiment', 'tweet']\n",
        "\n",
        "# replace positive and negative with 1 and 0 respectively\n",
        "train_df = train_df[train_df['sentiment'].isin(['Positive', 'Negative'])].replace({'Positive': 1, 'Negative': 0})\n",
        "test_df = test_df[test_df['sentiment'].isin(['Positive', 'Negative'])].replace({'Positive': 1, 'Negative': 0})\n",
        "\n",
        "# only keep rows with strings in the tweet\n",
        "train_df = train_df[train_df['tweet'].apply(lambda x: isinstance(x, str))]\n",
        "test_df = test_df[test_df['tweet'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jSDTXV1GB6be",
        "outputId": "952f925e-2751-4dfd-e242-252c2de8247a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sentiment                                              tweet\n",
              "0              1  I am coming to the borders and I will kill you...\n",
              "1              1  im getting on borderlands and i will kill you ...\n",
              "2              1  im coming on borderlands and i will murder you...\n",
              "3              1  im getting on borderlands 2 and i will murder ...\n",
              "4              1  im getting into borderlands and i can murder y...\n",
              "...          ...                                                ...\n",
              "74676          1  Just realized that the Windows partition of my...\n",
              "74677          1  Just realized that my Mac window partition is ...\n",
              "74678          1  Just realized the windows partition of my Mac ...\n",
              "74679          1  Just realized between the windows partition of...\n",
              "74680          1  Just like the windows partition of my Mac is l...\n",
              "\n",
              "[43012 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dc37105-25cb-4519-8cd0-c9b9b0ad5f56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74676</th>\n",
              "      <td>1</td>\n",
              "      <td>Just realized that the Windows partition of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74677</th>\n",
              "      <td>1</td>\n",
              "      <td>Just realized that my Mac window partition is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74678</th>\n",
              "      <td>1</td>\n",
              "      <td>Just realized the windows partition of my Mac ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74679</th>\n",
              "      <td>1</td>\n",
              "      <td>Just realized between the windows partition of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74680</th>\n",
              "      <td>1</td>\n",
              "      <td>Just like the windows partition of my Mac is l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43012 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dc37105-25cb-4519-8cd0-c9b9b0ad5f56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dc37105-25cb-4519-8cd0-c9b9b0ad5f56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dc37105-25cb-4519-8cd0-c9b9b0ad5f56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea39bfea-adf9-4d16-9c8f-6d0e708fcebe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea39bfea-adf9-4d16-9c8f-6d0e708fcebe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea39bfea-adf9-4d16-9c8f-6d0e708fcebe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d1a6908e-2378-4b09-a4ae-22c473e1bc1c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d1a6908e-2378-4b09-a4ae-22c473e1bc1c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if data is balanced\n",
        "train_df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3A0BGMYGufu",
        "outputId": "c613b9a6-12ed-41a7-c93f-b0ba5cc1a863"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    22358\n",
              "1    20654\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tweet):\n",
        "    tweet = re.sub('@[^\\s]+','',tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'http://\\S+|https://\\S+', \" \", tweet)\n",
        "    tweet = re.sub(r' +', \" \", tweet)\n",
        "    return tweet.strip().lower()\n",
        "\n",
        "# preprocess tweets\n",
        "train_df['tweet'] = train_df['tweet'].apply(preprocess).dropna()\n",
        "test_df['tweet'] = test_df['tweet'].apply(preprocess).dropna()\n",
        "\n",
        "# Remove rows where the 'tweet' column is an empty string\n",
        "train_df = train_df[train_df['tweet'].str.strip().astype(bool)]\n",
        "test_df = test_df[test_df['tweet'].str.strip().astype(bool)]\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gq3OTlQ9GQ1t",
        "outputId": "9b8e3579-b3cb-4f61-84b6-7bae8790be34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sentiment                                              tweet\n",
              "0              1  i am coming to the borders and i will kill you...\n",
              "1              1  im getting on borderlands and i will kill you ...\n",
              "2              1  im coming on borderlands and i will murder you...\n",
              "3              1  im getting on borderlands 2 and i will murder ...\n",
              "4              1  im getting into borderlands and i can murder y...\n",
              "...          ...                                                ...\n",
              "74676          1  just realized that the windows partition of my...\n",
              "74677          1  just realized that my mac window partition is ...\n",
              "74678          1  just realized the windows partition of my mac ...\n",
              "74679          1  just realized between the windows partition of...\n",
              "74680          1  just like the windows partition of my mac is l...\n",
              "\n",
              "[42907 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1997207-ab3f-47f2-bd7b-b3f5beb4b59d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>i am coming to the borders and i will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74676</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized that the windows partition of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74677</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized that my mac window partition is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74678</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized the windows partition of my mac ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74679</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized between the windows partition of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74680</th>\n",
              "      <td>1</td>\n",
              "      <td>just like the windows partition of my mac is l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42907 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1997207-ab3f-47f2-bd7b-b3f5beb4b59d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1997207-ab3f-47f2-bd7b-b3f5beb4b59d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1997207-ab3f-47f2-bd7b-b3f5beb4b59d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36ca1d4f-3557-484d-a521-ba875748faab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36ca1d4f-3557-484d-a521-ba875748faab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36ca1d4f-3557-484d-a521-ba875748faab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_26bc2188-3fcf-4c2a-8113-c14c31ecbb36\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_26bc2188-3fcf-4c2a-8113-c14c31ecbb36 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the tweets\n",
        "train_tokenized = train_df['tweet'].apply(lambda x: x.split())\n",
        "\n",
        "# Train a Word2Vec model\n",
        "W2V_model = gensim.models.Word2Vec(sentences=train_tokenized, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "1jO78aUtCP2F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(word):\n",
        "    if word in W2V_model.wv:\n",
        "        return torch.tensor(W2V_model.wv[word], dtype=torch.float32)\n",
        "    else:\n",
        "        return torch.zeros(100, dtype=torch.float32)  # Return a zero vector if the word is not in the vocabulary\n",
        "\n",
        "def create_tweet_embeddings(df):\n",
        "    tweet_embeddings = []\n",
        "\n",
        "    for tweet in df['tweet']:\n",
        "        # Split the tweet into words and get embeddings\n",
        "        embeddings = [get_embedding(word) for word in tweet.split()]\n",
        "        if embeddings:\n",
        "            # Stack the embeddings into one tensor and compute the mean\n",
        "            tweet_embedding = torch.stack(embeddings).mean(dim=0)\n",
        "        else:\n",
        "            # If no words in the tweet are in the vocabulary, use a zero vector\n",
        "            tweet_embedding = torch.zeros(100, dtype=torch.float32)\n",
        "\n",
        "        tweet_embeddings.append(tweet_embedding)\n",
        "\n",
        "    # Convert the list of tensors to a single tensor\n",
        "    tweet_embeddings_tensor = torch.stack(tweet_embeddings) if tweet_embeddings else torch.empty(0, 100)\n",
        "\n",
        "    # Convert the tensor to a list of lists (each embedding as a list) for DataFrame compatibility\n",
        "    embeddings_list = tweet_embeddings_tensor.tolist()\n",
        "\n",
        "    return embeddings_list\n",
        "\n",
        "train_df['embeddings'] = create_tweet_embeddings(train_df)\n",
        "test_df['embeddings'] = create_tweet_embeddings(test_df)\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "6XuPLejJP7ee",
        "outputId": "7efe38dd-638d-4897-d884-6bd942ca8ad2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2ea84075313c>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['embeddings'] = create_tweet_embeddings(train_df)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sentiment                                              tweet  \\\n",
              "0              1  i am coming to the borders and i will kill you...   \n",
              "1              1  im getting on borderlands and i will kill you ...   \n",
              "2              1  im coming on borderlands and i will murder you...   \n",
              "3              1  im getting on borderlands 2 and i will murder ...   \n",
              "4              1  im getting into borderlands and i can murder y...   \n",
              "...          ...                                                ...   \n",
              "74676          1  just realized that the windows partition of my...   \n",
              "74677          1  just realized that my mac window partition is ...   \n",
              "74678          1  just realized the windows partition of my mac ...   \n",
              "74679          1  just realized between the windows partition of...   \n",
              "74680          1  just like the windows partition of my mac is l...   \n",
              "\n",
              "                                              embeddings  \n",
              "0      [-1.455673336982727, 0.48071131110191345, 0.17...  \n",
              "1      [-1.1921939849853516, 0.24493196606636047, 0.4...  \n",
              "2      [-1.0292232036590576, 0.2167886197566986, 0.30...  \n",
              "3      [-1.040396809577942, 0.14605596661567688, 0.54...  \n",
              "4      [-1.1236872673034668, 0.3335123360157013, 0.44...  \n",
              "...                                                  ...  \n",
              "74676  [-0.4612485468387604, -0.007398550398647785, 0...  \n",
              "74677  [-0.5238672494888306, 0.020812761038541794, 0....  \n",
              "74678  [-0.36158743500709534, -0.10157100856304169, 0...  \n",
              "74679  [-0.34585878252983093, -0.12464603781700134, 0...  \n",
              "74680  [-0.37145668268203735, -0.10219672322273254, 0...  \n",
              "\n",
              "[42907 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd5c2283-f4fb-4dca-b593-5b80acbd0f1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>i am coming to the borders and i will kill you...</td>\n",
              "      <td>[-1.455673336982727, 0.48071131110191345, 0.17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "      <td>[-1.1921939849853516, 0.24493196606636047, 0.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "      <td>[-1.0292232036590576, 0.2167886197566986, 0.30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "      <td>[-1.040396809577942, 0.14605596661567688, 0.54...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "      <td>[-1.1236872673034668, 0.3335123360157013, 0.44...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74676</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized that the windows partition of my...</td>\n",
              "      <td>[-0.4612485468387604, -0.007398550398647785, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74677</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized that my mac window partition is ...</td>\n",
              "      <td>[-0.5238672494888306, 0.020812761038541794, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74678</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized the windows partition of my mac ...</td>\n",
              "      <td>[-0.36158743500709534, -0.10157100856304169, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74679</th>\n",
              "      <td>1</td>\n",
              "      <td>just realized between the windows partition of...</td>\n",
              "      <td>[-0.34585878252983093, -0.12464603781700134, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74680</th>\n",
              "      <td>1</td>\n",
              "      <td>just like the windows partition of my mac is l...</td>\n",
              "      <td>[-0.37145668268203735, -0.10219672322273254, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42907 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd5c2283-f4fb-4dca-b593-5b80acbd0f1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd5c2283-f4fb-4dca-b593-5b80acbd0f1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd5c2283-f4fb-4dca-b593-5b80acbd0f1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6673ec32-5bf0-4f5b-994c-5c9290c052a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6673ec32-5bf0-4f5b-994c-5c9290c052a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6673ec32-5bf0-4f5b-994c-5c9290c052a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ac4eea4a-723a-4087-8b95-b12606fa04bc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ac4eea4a-723a-4087-8b95-b12606fa04bc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'tweet_embeddings' and 'sentiment' columns to tensors\n",
        "train_embeddings = torch.tensor(list(train_df['embeddings'])).float()\n",
        "train_labels = torch.tensor(train_df['sentiment'].values).long()\n",
        "\n",
        "test_embeddings = torch.tensor(list(test_df['embeddings'])).float()\n",
        "test_labels = torch.tensor(test_df['sentiment'].values).long()\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_embeddings, train_labels)\n",
        "test_dataset = TensorDataset(test_embeddings, test_labels)\n",
        "\n",
        "# Create Pytorch DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "4ALEWUnAUXxu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "YV6Q2G7SVk33"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Zk5j2ObgWOS5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    dataset_size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        batch_loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            batch_loss, current = batch_loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"Progress:[{current:>5d}/{dataset_size:>5d}]  batch loss:{batch_loss:>8f}\")\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    average_loss = total_loss / num_batches\n",
        "    print(f\"Train Error: Avg loss: {average_loss:>8f}\")\n",
        "    return average_loss\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # Get model pred\n",
        "            pred = model(X)\n",
        "\n",
        "            # Compute loss and\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= dataset_size\n",
        "\n",
        "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "y-NS03qbWsbh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for t in range(num_epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
        "    train_losses.append(train_loss.detach().cpu())\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2hVOD3WWtLL",
        "outputId": "e0448eb8-59cd-4df5-eb39-ce6e330ecb68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.331384\n",
            "Progress:[ 3232/42907]  batch loss:0.323478\n",
            "Progress:[ 6432/42907]  batch loss:0.352547\n",
            "Progress:[ 9632/42907]  batch loss:0.301139\n",
            "Progress:[12832/42907]  batch loss:0.420820\n",
            "Progress:[16032/42907]  batch loss:0.460334\n",
            "Progress:[19232/42907]  batch loss:0.335815\n",
            "Progress:[22432/42907]  batch loss:0.349174\n",
            "Progress:[25632/42907]  batch loss:0.447778\n",
            "Progress:[28832/42907]  batch loss:0.281886\n",
            "Progress:[32032/42907]  batch loss:0.362734\n",
            "Progress:[35232/42907]  batch loss:0.306995\n",
            "Progress:[38432/42907]  batch loss:0.451600\n",
            "Progress:[41632/42907]  batch loss:0.270719\n",
            "Train Error: Avg loss: 0.336707\n",
            "Test Error: Accuracy: 88.8%, Avg loss: 0.271268\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.322622\n",
            "Progress:[ 3232/42907]  batch loss:0.610432\n",
            "Progress:[ 6432/42907]  batch loss:0.322292\n",
            "Progress:[ 9632/42907]  batch loss:0.288887\n",
            "Progress:[12832/42907]  batch loss:0.397988\n",
            "Progress:[16032/42907]  batch loss:0.355195\n",
            "Progress:[19232/42907]  batch loss:0.278728\n",
            "Progress:[22432/42907]  batch loss:0.348843\n",
            "Progress:[25632/42907]  batch loss:0.365390\n",
            "Progress:[28832/42907]  batch loss:0.163821\n",
            "Progress:[32032/42907]  batch loss:0.336202\n",
            "Progress:[35232/42907]  batch loss:0.259651\n",
            "Progress:[38432/42907]  batch loss:0.314191\n",
            "Progress:[41632/42907]  batch loss:0.413814\n",
            "Train Error: Avg loss: 0.326636\n",
            "Test Error: Accuracy: 88.8%, Avg loss: 0.264309\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.215387\n",
            "Progress:[ 3232/42907]  batch loss:0.206856\n",
            "Progress:[ 6432/42907]  batch loss:0.480313\n",
            "Progress:[ 9632/42907]  batch loss:0.162974\n",
            "Progress:[12832/42907]  batch loss:0.317064\n",
            "Progress:[16032/42907]  batch loss:0.388812\n",
            "Progress:[19232/42907]  batch loss:0.326026\n",
            "Progress:[22432/42907]  batch loss:0.298234\n",
            "Progress:[25632/42907]  batch loss:0.371626\n",
            "Progress:[28832/42907]  batch loss:0.241204\n",
            "Progress:[32032/42907]  batch loss:0.254723\n",
            "Progress:[35232/42907]  batch loss:0.220808\n",
            "Progress:[38432/42907]  batch loss:0.165072\n",
            "Progress:[41632/42907]  batch loss:0.301010\n",
            "Train Error: Avg loss: 0.315864\n",
            "Test Error: Accuracy: 89.0%, Avg loss: 0.265937\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.236810\n",
            "Progress:[ 3232/42907]  batch loss:0.219433\n",
            "Progress:[ 6432/42907]  batch loss:0.261058\n",
            "Progress:[ 9632/42907]  batch loss:0.380342\n",
            "Progress:[12832/42907]  batch loss:0.403330\n",
            "Progress:[16032/42907]  batch loss:0.292571\n",
            "Progress:[19232/42907]  batch loss:0.492036\n",
            "Progress:[22432/42907]  batch loss:0.364793\n",
            "Progress:[25632/42907]  batch loss:0.364159\n",
            "Progress:[28832/42907]  batch loss:0.295889\n",
            "Progress:[32032/42907]  batch loss:0.307054\n",
            "Progress:[35232/42907]  batch loss:0.340472\n",
            "Progress:[38432/42907]  batch loss:0.247927\n",
            "Progress:[41632/42907]  batch loss:0.316691\n",
            "Train Error: Avg loss: 0.305313\n",
            "Test Error: Accuracy: 90.1%, Avg loss: 0.262598\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.270199\n",
            "Progress:[ 3232/42907]  batch loss:0.347163\n",
            "Progress:[ 6432/42907]  batch loss:0.174491\n",
            "Progress:[ 9632/42907]  batch loss:0.336549\n",
            "Progress:[12832/42907]  batch loss:0.450384\n",
            "Progress:[16032/42907]  batch loss:0.237805\n",
            "Progress:[19232/42907]  batch loss:0.311622\n",
            "Progress:[22432/42907]  batch loss:0.376119\n",
            "Progress:[25632/42907]  batch loss:0.264388\n",
            "Progress:[28832/42907]  batch loss:0.210582\n",
            "Progress:[32032/42907]  batch loss:0.206382\n",
            "Progress:[35232/42907]  batch loss:0.219568\n",
            "Progress:[38432/42907]  batch loss:0.238843\n",
            "Progress:[41632/42907]  batch loss:0.301487\n",
            "Train Error: Avg loss: 0.299189\n",
            "Test Error: Accuracy: 89.7%, Avg loss: 0.250688\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.214219\n",
            "Progress:[ 3232/42907]  batch loss:0.295473\n",
            "Progress:[ 6432/42907]  batch loss:0.285847\n",
            "Progress:[ 9632/42907]  batch loss:0.240720\n",
            "Progress:[12832/42907]  batch loss:0.124608\n",
            "Progress:[16032/42907]  batch loss:0.233638\n",
            "Progress:[19232/42907]  batch loss:0.212955\n",
            "Progress:[22432/42907]  batch loss:0.334002\n",
            "Progress:[25632/42907]  batch loss:0.194889\n",
            "Progress:[28832/42907]  batch loss:0.248093\n",
            "Progress:[32032/42907]  batch loss:0.136971\n",
            "Progress:[35232/42907]  batch loss:0.385701\n",
            "Progress:[38432/42907]  batch loss:0.323059\n",
            "Progress:[41632/42907]  batch loss:0.186646\n",
            "Train Error: Avg loss: 0.289908\n",
            "Test Error: Accuracy: 88.6%, Avg loss: 0.263708\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.247088\n",
            "Progress:[ 3232/42907]  batch loss:0.277170\n",
            "Progress:[ 6432/42907]  batch loss:0.475405\n",
            "Progress:[ 9632/42907]  batch loss:0.212292\n",
            "Progress:[12832/42907]  batch loss:0.342094\n",
            "Progress:[16032/42907]  batch loss:0.266948\n",
            "Progress:[19232/42907]  batch loss:0.167606\n",
            "Progress:[22432/42907]  batch loss:0.328604\n",
            "Progress:[25632/42907]  batch loss:0.235996\n",
            "Progress:[28832/42907]  batch loss:0.279241\n",
            "Progress:[32032/42907]  batch loss:0.217201\n",
            "Progress:[35232/42907]  batch loss:0.443078\n",
            "Progress:[38432/42907]  batch loss:0.187040\n",
            "Progress:[41632/42907]  batch loss:0.240513\n",
            "Train Error: Avg loss: 0.280858\n",
            "Test Error: Accuracy: 87.7%, Avg loss: 0.262266\n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.455112\n",
            "Progress:[ 3232/42907]  batch loss:0.469657\n",
            "Progress:[ 6432/42907]  batch loss:0.252849\n",
            "Progress:[ 9632/42907]  batch loss:0.114862\n",
            "Progress:[12832/42907]  batch loss:0.364260\n",
            "Progress:[16032/42907]  batch loss:0.260282\n",
            "Progress:[19232/42907]  batch loss:0.296445\n",
            "Progress:[22432/42907]  batch loss:0.255231\n",
            "Progress:[25632/42907]  batch loss:0.281195\n",
            "Progress:[28832/42907]  batch loss:0.243756\n",
            "Progress:[32032/42907]  batch loss:0.585374\n",
            "Progress:[35232/42907]  batch loss:0.229985\n",
            "Progress:[38432/42907]  batch loss:0.373060\n",
            "Progress:[41632/42907]  batch loss:0.404391\n",
            "Train Error: Avg loss: 0.271815\n",
            "Test Error: Accuracy: 89.9%, Avg loss: 0.249984\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.343066\n",
            "Progress:[ 3232/42907]  batch loss:0.222318\n",
            "Progress:[ 6432/42907]  batch loss:0.105332\n",
            "Progress:[ 9632/42907]  batch loss:0.301646\n",
            "Progress:[12832/42907]  batch loss:0.196977\n",
            "Progress:[16032/42907]  batch loss:0.269992\n",
            "Progress:[19232/42907]  batch loss:0.277420\n",
            "Progress:[22432/42907]  batch loss:0.222627\n",
            "Progress:[25632/42907]  batch loss:0.106528\n",
            "Progress:[28832/42907]  batch loss:0.240549\n",
            "Progress:[32032/42907]  batch loss:0.271231\n",
            "Progress:[35232/42907]  batch loss:0.148845\n",
            "Progress:[38432/42907]  batch loss:0.266931\n",
            "Progress:[41632/42907]  batch loss:0.316028\n",
            "Train Error: Avg loss: 0.264537\n",
            "Test Error: Accuracy: 89.1%, Avg loss: 0.256005\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.302674\n",
            "Progress:[ 3232/42907]  batch loss:0.166085\n",
            "Progress:[ 6432/42907]  batch loss:0.362898\n",
            "Progress:[ 9632/42907]  batch loss:0.270633\n",
            "Progress:[12832/42907]  batch loss:0.347031\n",
            "Progress:[16032/42907]  batch loss:0.301430\n",
            "Progress:[19232/42907]  batch loss:0.257519\n",
            "Progress:[22432/42907]  batch loss:0.243844\n",
            "Progress:[25632/42907]  batch loss:0.242381\n",
            "Progress:[28832/42907]  batch loss:0.175583\n",
            "Progress:[32032/42907]  batch loss:0.357769\n",
            "Progress:[35232/42907]  batch loss:0.274896\n",
            "Progress:[38432/42907]  batch loss:0.227401\n",
            "Progress:[41632/42907]  batch loss:0.379820\n",
            "Train Error: Avg loss: 0.257074\n",
            "Test Error: Accuracy: 90.1%, Avg loss: 0.255166\n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.258186\n",
            "Progress:[ 3232/42907]  batch loss:0.248303\n",
            "Progress:[ 6432/42907]  batch loss:0.130371\n",
            "Progress:[ 9632/42907]  batch loss:0.296936\n",
            "Progress:[12832/42907]  batch loss:0.129132\n",
            "Progress:[16032/42907]  batch loss:0.329335\n",
            "Progress:[19232/42907]  batch loss:0.207339\n",
            "Progress:[22432/42907]  batch loss:0.298215\n",
            "Progress:[25632/42907]  batch loss:0.370764\n",
            "Progress:[28832/42907]  batch loss:0.222202\n",
            "Progress:[32032/42907]  batch loss:0.120305\n",
            "Progress:[35232/42907]  batch loss:0.265320\n",
            "Progress:[38432/42907]  batch loss:0.228481\n",
            "Progress:[41632/42907]  batch loss:0.214489\n",
            "Train Error: Avg loss: 0.249143\n",
            "Test Error: Accuracy: 91.9%, Avg loss: 0.213187\n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.176901\n",
            "Progress:[ 3232/42907]  batch loss:0.126947\n",
            "Progress:[ 6432/42907]  batch loss:0.197542\n",
            "Progress:[ 9632/42907]  batch loss:0.097692\n",
            "Progress:[12832/42907]  batch loss:0.336843\n",
            "Progress:[16032/42907]  batch loss:0.390424\n",
            "Progress:[19232/42907]  batch loss:0.098621\n",
            "Progress:[22432/42907]  batch loss:0.178518\n",
            "Progress:[25632/42907]  batch loss:0.209932\n",
            "Progress:[28832/42907]  batch loss:0.182356\n",
            "Progress:[32032/42907]  batch loss:0.452367\n",
            "Progress:[35232/42907]  batch loss:0.146251\n",
            "Progress:[38432/42907]  batch loss:0.158079\n",
            "Progress:[41632/42907]  batch loss:0.309717\n",
            "Train Error: Avg loss: 0.244449\n",
            "Test Error: Accuracy: 92.6%, Avg loss: 0.213257\n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.099213\n",
            "Progress:[ 3232/42907]  batch loss:0.158299\n",
            "Progress:[ 6432/42907]  batch loss:0.279145\n",
            "Progress:[ 9632/42907]  batch loss:0.213210\n",
            "Progress:[12832/42907]  batch loss:0.207133\n",
            "Progress:[16032/42907]  batch loss:0.220443\n",
            "Progress:[19232/42907]  batch loss:0.284344\n",
            "Progress:[22432/42907]  batch loss:0.127553\n",
            "Progress:[25632/42907]  batch loss:0.186696\n",
            "Progress:[28832/42907]  batch loss:0.228778\n",
            "Progress:[32032/42907]  batch loss:0.132817\n",
            "Progress:[35232/42907]  batch loss:0.250948\n",
            "Progress:[38432/42907]  batch loss:0.266992\n",
            "Progress:[41632/42907]  batch loss:0.193649\n",
            "Train Error: Avg loss: 0.234803\n",
            "Test Error: Accuracy: 91.7%, Avg loss: 0.212364\n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.235694\n",
            "Progress:[ 3232/42907]  batch loss:0.166451\n",
            "Progress:[ 6432/42907]  batch loss:0.379047\n",
            "Progress:[ 9632/42907]  batch loss:0.163866\n",
            "Progress:[12832/42907]  batch loss:0.279265\n",
            "Progress:[16032/42907]  batch loss:0.278386\n",
            "Progress:[19232/42907]  batch loss:0.190041\n",
            "Progress:[22432/42907]  batch loss:0.144388\n",
            "Progress:[25632/42907]  batch loss:0.227341\n",
            "Progress:[28832/42907]  batch loss:0.240821\n",
            "Progress:[32032/42907]  batch loss:0.120306\n",
            "Progress:[35232/42907]  batch loss:0.123188\n",
            "Progress:[38432/42907]  batch loss:0.351260\n",
            "Progress:[41632/42907]  batch loss:0.189809\n",
            "Train Error: Avg loss: 0.227481\n",
            "Test Error: Accuracy: 92.3%, Avg loss: 0.202074\n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.311809\n",
            "Progress:[ 3232/42907]  batch loss:0.220102\n",
            "Progress:[ 6432/42907]  batch loss:0.323595\n",
            "Progress:[ 9632/42907]  batch loss:0.361272\n",
            "Progress:[12832/42907]  batch loss:0.217906\n",
            "Progress:[16032/42907]  batch loss:0.186941\n",
            "Progress:[19232/42907]  batch loss:0.185731\n",
            "Progress:[22432/42907]  batch loss:0.421025\n",
            "Progress:[25632/42907]  batch loss:0.157857\n",
            "Progress:[28832/42907]  batch loss:0.490381\n",
            "Progress:[32032/42907]  batch loss:0.156046\n",
            "Progress:[35232/42907]  batch loss:0.306221\n",
            "Progress:[38432/42907]  batch loss:0.210651\n",
            "Progress:[41632/42907]  batch loss:0.154442\n",
            "Train Error: Avg loss: 0.222169\n",
            "Test Error: Accuracy: 91.2%, Avg loss: 0.224415\n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.322530\n",
            "Progress:[ 3232/42907]  batch loss:0.176640\n",
            "Progress:[ 6432/42907]  batch loss:0.140920\n",
            "Progress:[ 9632/42907]  batch loss:0.231927\n",
            "Progress:[12832/42907]  batch loss:0.126268\n",
            "Progress:[16032/42907]  batch loss:0.336414\n",
            "Progress:[19232/42907]  batch loss:0.098309\n",
            "Progress:[22432/42907]  batch loss:0.144042\n",
            "Progress:[25632/42907]  batch loss:0.228233\n",
            "Progress:[28832/42907]  batch loss:0.193624\n",
            "Progress:[32032/42907]  batch loss:0.285354\n",
            "Progress:[35232/42907]  batch loss:0.326412\n",
            "Progress:[38432/42907]  batch loss:0.190889\n",
            "Progress:[41632/42907]  batch loss:0.361921\n",
            "Train Error: Avg loss: 0.216677\n",
            "Test Error: Accuracy: 91.3%, Avg loss: 0.224323\n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.143745\n",
            "Progress:[ 3232/42907]  batch loss:0.044575\n",
            "Progress:[ 6432/42907]  batch loss:0.144094\n",
            "Progress:[ 9632/42907]  batch loss:0.113379\n",
            "Progress:[12832/42907]  batch loss:0.173593\n",
            "Progress:[16032/42907]  batch loss:0.151378\n",
            "Progress:[19232/42907]  batch loss:0.107674\n",
            "Progress:[22432/42907]  batch loss:0.099249\n",
            "Progress:[25632/42907]  batch loss:0.173121\n",
            "Progress:[28832/42907]  batch loss:0.308966\n",
            "Progress:[32032/42907]  batch loss:0.247120\n",
            "Progress:[35232/42907]  batch loss:0.096250\n",
            "Progress:[38432/42907]  batch loss:0.320226\n",
            "Progress:[41632/42907]  batch loss:0.262205\n",
            "Train Error: Avg loss: 0.210245\n",
            "Test Error: Accuracy: 92.8%, Avg loss: 0.214131\n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.118378\n",
            "Progress:[ 3232/42907]  batch loss:0.172169\n",
            "Progress:[ 6432/42907]  batch loss:0.120181\n",
            "Progress:[ 9632/42907]  batch loss:0.208140\n",
            "Progress:[12832/42907]  batch loss:0.338769\n",
            "Progress:[16032/42907]  batch loss:0.173971\n",
            "Progress:[19232/42907]  batch loss:0.181934\n",
            "Progress:[22432/42907]  batch loss:0.466868\n",
            "Progress:[25632/42907]  batch loss:0.106963\n",
            "Progress:[28832/42907]  batch loss:0.076964\n",
            "Progress:[32032/42907]  batch loss:0.210287\n",
            "Progress:[35232/42907]  batch loss:0.153010\n",
            "Progress:[38432/42907]  batch loss:0.153847\n",
            "Progress:[41632/42907]  batch loss:0.252930\n",
            "Train Error: Avg loss: 0.204562\n",
            "Test Error: Accuracy: 94.1%, Avg loss: 0.179751\n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.094074\n",
            "Progress:[ 3232/42907]  batch loss:0.292566\n",
            "Progress:[ 6432/42907]  batch loss:0.180698\n",
            "Progress:[ 9632/42907]  batch loss:0.138016\n",
            "Progress:[12832/42907]  batch loss:0.104200\n",
            "Progress:[16032/42907]  batch loss:0.049135\n",
            "Progress:[19232/42907]  batch loss:0.130290\n",
            "Progress:[22432/42907]  batch loss:0.182281\n",
            "Progress:[25632/42907]  batch loss:0.273355\n",
            "Progress:[28832/42907]  batch loss:0.198137\n",
            "Progress:[32032/42907]  batch loss:0.166484\n",
            "Progress:[35232/42907]  batch loss:0.175751\n",
            "Progress:[38432/42907]  batch loss:0.137481\n",
            "Progress:[41632/42907]  batch loss:0.360077\n",
            "Train Error: Avg loss: 0.197502\n",
            "Test Error: Accuracy: 92.4%, Avg loss: 0.209085\n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.240623\n",
            "Progress:[ 3232/42907]  batch loss:0.071074\n",
            "Progress:[ 6432/42907]  batch loss:0.195468\n",
            "Progress:[ 9632/42907]  batch loss:0.102319\n",
            "Progress:[12832/42907]  batch loss:0.180096\n",
            "Progress:[16032/42907]  batch loss:0.255228\n",
            "Progress:[19232/42907]  batch loss:0.144952\n",
            "Progress:[22432/42907]  batch loss:0.261066\n",
            "Progress:[25632/42907]  batch loss:0.242766\n",
            "Progress:[28832/42907]  batch loss:0.259070\n",
            "Progress:[32032/42907]  batch loss:0.119519\n",
            "Progress:[35232/42907]  batch loss:0.236786\n",
            "Progress:[38432/42907]  batch loss:0.304434\n",
            "Progress:[41632/42907]  batch loss:0.136652\n",
            "Train Error: Avg loss: 0.194037\n",
            "Test Error: Accuracy: 92.8%, Avg loss: 0.196663\n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.143989\n",
            "Progress:[ 3232/42907]  batch loss:0.222027\n",
            "Progress:[ 6432/42907]  batch loss:0.140664\n",
            "Progress:[ 9632/42907]  batch loss:0.140987\n",
            "Progress:[12832/42907]  batch loss:0.263620\n",
            "Progress:[16032/42907]  batch loss:0.159325\n",
            "Progress:[19232/42907]  batch loss:0.191705\n",
            "Progress:[22432/42907]  batch loss:0.254093\n",
            "Progress:[25632/42907]  batch loss:0.116833\n",
            "Progress:[28832/42907]  batch loss:0.182050\n",
            "Progress:[32032/42907]  batch loss:0.030446\n",
            "Progress:[35232/42907]  batch loss:0.213810\n",
            "Progress:[38432/42907]  batch loss:0.117177\n",
            "Progress:[41632/42907]  batch loss:0.185239\n",
            "Train Error: Avg loss: 0.189614\n",
            "Test Error: Accuracy: 93.7%, Avg loss: 0.190848\n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.094883\n",
            "Progress:[ 3232/42907]  batch loss:0.368526\n",
            "Progress:[ 6432/42907]  batch loss:0.155152\n",
            "Progress:[ 9632/42907]  batch loss:0.167880\n",
            "Progress:[12832/42907]  batch loss:0.210068\n",
            "Progress:[16032/42907]  batch loss:0.505899\n",
            "Progress:[19232/42907]  batch loss:0.099436\n",
            "Progress:[22432/42907]  batch loss:0.233704\n",
            "Progress:[25632/42907]  batch loss:0.171079\n",
            "Progress:[28832/42907]  batch loss:0.121209\n",
            "Progress:[32032/42907]  batch loss:0.169586\n",
            "Progress:[35232/42907]  batch loss:0.066712\n",
            "Progress:[38432/42907]  batch loss:0.349593\n",
            "Progress:[41632/42907]  batch loss:0.105861\n",
            "Train Error: Avg loss: 0.180912\n",
            "Test Error: Accuracy: 92.6%, Avg loss: 0.199749\n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.061454\n",
            "Progress:[ 3232/42907]  batch loss:0.038822\n",
            "Progress:[ 6432/42907]  batch loss:0.246013\n",
            "Progress:[ 9632/42907]  batch loss:0.190186\n",
            "Progress:[12832/42907]  batch loss:0.083421\n",
            "Progress:[16032/42907]  batch loss:0.182677\n",
            "Progress:[19232/42907]  batch loss:0.151211\n",
            "Progress:[22432/42907]  batch loss:0.314169\n",
            "Progress:[25632/42907]  batch loss:0.122523\n",
            "Progress:[28832/42907]  batch loss:0.155980\n",
            "Progress:[32032/42907]  batch loss:0.190018\n",
            "Progress:[35232/42907]  batch loss:0.167229\n",
            "Progress:[38432/42907]  batch loss:0.139871\n",
            "Progress:[41632/42907]  batch loss:0.178253\n",
            "Train Error: Avg loss: 0.179657\n",
            "Test Error: Accuracy: 92.8%, Avg loss: 0.217670\n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.099414\n",
            "Progress:[ 3232/42907]  batch loss:0.154391\n",
            "Progress:[ 6432/42907]  batch loss:0.394240\n",
            "Progress:[ 9632/42907]  batch loss:0.142255\n",
            "Progress:[12832/42907]  batch loss:0.377873\n",
            "Progress:[16032/42907]  batch loss:0.139527\n",
            "Progress:[19232/42907]  batch loss:0.155623\n",
            "Progress:[22432/42907]  batch loss:0.317052\n",
            "Progress:[25632/42907]  batch loss:0.209311\n",
            "Progress:[28832/42907]  batch loss:0.225053\n",
            "Progress:[32032/42907]  batch loss:0.141632\n",
            "Progress:[35232/42907]  batch loss:0.121969\n",
            "Progress:[38432/42907]  batch loss:0.235505\n",
            "Progress:[41632/42907]  batch loss:0.227149\n",
            "Train Error: Avg loss: 0.172557\n",
            "Test Error: Accuracy: 92.8%, Avg loss: 0.206559\n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.349606\n",
            "Progress:[ 3232/42907]  batch loss:0.243184\n",
            "Progress:[ 6432/42907]  batch loss:0.245879\n",
            "Progress:[ 9632/42907]  batch loss:0.089154\n",
            "Progress:[12832/42907]  batch loss:0.143959\n",
            "Progress:[16032/42907]  batch loss:0.316982\n",
            "Progress:[19232/42907]  batch loss:0.077975\n",
            "Progress:[22432/42907]  batch loss:0.446666\n",
            "Progress:[25632/42907]  batch loss:0.158616\n",
            "Progress:[28832/42907]  batch loss:0.068532\n",
            "Progress:[32032/42907]  batch loss:0.105940\n",
            "Progress:[35232/42907]  batch loss:0.252246\n",
            "Progress:[38432/42907]  batch loss:0.200362\n",
            "Progress:[41632/42907]  batch loss:0.305230\n",
            "Train Error: Avg loss: 0.172508\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.202481\n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.104217\n",
            "Progress:[ 3232/42907]  batch loss:0.134438\n",
            "Progress:[ 6432/42907]  batch loss:0.067781\n",
            "Progress:[ 9632/42907]  batch loss:0.194167\n",
            "Progress:[12832/42907]  batch loss:0.085168\n",
            "Progress:[16032/42907]  batch loss:0.087400\n",
            "Progress:[19232/42907]  batch loss:0.154773\n",
            "Progress:[22432/42907]  batch loss:0.153285\n",
            "Progress:[25632/42907]  batch loss:0.279652\n",
            "Progress:[28832/42907]  batch loss:0.295522\n",
            "Progress:[32032/42907]  batch loss:0.131299\n",
            "Progress:[35232/42907]  batch loss:0.129739\n",
            "Progress:[38432/42907]  batch loss:0.052368\n",
            "Progress:[41632/42907]  batch loss:0.246553\n",
            "Train Error: Avg loss: 0.168064\n",
            "Test Error: Accuracy: 93.4%, Avg loss: 0.190271\n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.055514\n",
            "Progress:[ 3232/42907]  batch loss:0.087813\n",
            "Progress:[ 6432/42907]  batch loss:0.040266\n",
            "Progress:[ 9632/42907]  batch loss:0.166614\n",
            "Progress:[12832/42907]  batch loss:0.214957\n",
            "Progress:[16032/42907]  batch loss:0.059417\n",
            "Progress:[19232/42907]  batch loss:0.184628\n",
            "Progress:[22432/42907]  batch loss:0.203635\n",
            "Progress:[25632/42907]  batch loss:0.266737\n",
            "Progress:[28832/42907]  batch loss:0.170453\n",
            "Progress:[32032/42907]  batch loss:0.191897\n",
            "Progress:[35232/42907]  batch loss:0.140643\n",
            "Progress:[38432/42907]  batch loss:0.097157\n",
            "Progress:[41632/42907]  batch loss:0.089873\n",
            "Train Error: Avg loss: 0.160068\n",
            "Test Error: Accuracy: 93.2%, Avg loss: 0.202766\n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.104629\n",
            "Progress:[ 3232/42907]  batch loss:0.134625\n",
            "Progress:[ 6432/42907]  batch loss:0.138396\n",
            "Progress:[ 9632/42907]  batch loss:0.110746\n",
            "Progress:[12832/42907]  batch loss:0.274265\n",
            "Progress:[16032/42907]  batch loss:0.257105\n",
            "Progress:[19232/42907]  batch loss:0.136594\n",
            "Progress:[22432/42907]  batch loss:0.082117\n",
            "Progress:[25632/42907]  batch loss:0.116558\n",
            "Progress:[28832/42907]  batch loss:0.112472\n",
            "Progress:[32032/42907]  batch loss:0.052681\n",
            "Progress:[35232/42907]  batch loss:0.257758\n",
            "Progress:[38432/42907]  batch loss:0.085081\n",
            "Progress:[41632/42907]  batch loss:0.323505\n",
            "Train Error: Avg loss: 0.160768\n",
            "Test Error: Accuracy: 93.6%, Avg loss: 0.190141\n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.116505\n",
            "Progress:[ 3232/42907]  batch loss:0.097703\n",
            "Progress:[ 6432/42907]  batch loss:0.117942\n",
            "Progress:[ 9632/42907]  batch loss:0.182671\n",
            "Progress:[12832/42907]  batch loss:0.278416\n",
            "Progress:[16032/42907]  batch loss:0.201157\n",
            "Progress:[19232/42907]  batch loss:0.152889\n",
            "Progress:[22432/42907]  batch loss:0.040273\n",
            "Progress:[25632/42907]  batch loss:0.178985\n",
            "Progress:[28832/42907]  batch loss:0.331339\n",
            "Progress:[32032/42907]  batch loss:0.264517\n",
            "Progress:[35232/42907]  batch loss:0.136982\n",
            "Progress:[38432/42907]  batch loss:0.065920\n",
            "Progress:[41632/42907]  batch loss:0.154520\n",
            "Train Error: Avg loss: 0.157814\n",
            "Test Error: Accuracy: 93.2%, Avg loss: 0.213828\n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.316478\n",
            "Progress:[ 3232/42907]  batch loss:0.087219\n",
            "Progress:[ 6432/42907]  batch loss:0.096034\n",
            "Progress:[ 9632/42907]  batch loss:0.143749\n",
            "Progress:[12832/42907]  batch loss:0.232158\n",
            "Progress:[16032/42907]  batch loss:0.161404\n",
            "Progress:[19232/42907]  batch loss:0.096436\n",
            "Progress:[22432/42907]  batch loss:0.174734\n",
            "Progress:[25632/42907]  batch loss:0.162873\n",
            "Progress:[28832/42907]  batch loss:0.218455\n",
            "Progress:[32032/42907]  batch loss:0.061652\n",
            "Progress:[35232/42907]  batch loss:0.271484\n",
            "Progress:[38432/42907]  batch loss:0.135805\n",
            "Progress:[41632/42907]  batch loss:0.085647\n",
            "Train Error: Avg loss: 0.152608\n",
            "Test Error: Accuracy: 93.9%, Avg loss: 0.186818\n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.136797\n",
            "Progress:[ 3232/42907]  batch loss:0.023112\n",
            "Progress:[ 6432/42907]  batch loss:0.139539\n",
            "Progress:[ 9632/42907]  batch loss:0.077381\n",
            "Progress:[12832/42907]  batch loss:0.068298\n",
            "Progress:[16032/42907]  batch loss:0.105414\n",
            "Progress:[19232/42907]  batch loss:0.213324\n",
            "Progress:[22432/42907]  batch loss:0.130995\n",
            "Progress:[25632/42907]  batch loss:0.097188\n",
            "Progress:[28832/42907]  batch loss:0.205500\n",
            "Progress:[32032/42907]  batch loss:0.120002\n",
            "Progress:[35232/42907]  batch loss:0.071710\n",
            "Progress:[38432/42907]  batch loss:0.112304\n",
            "Progress:[41632/42907]  batch loss:0.095103\n",
            "Train Error: Avg loss: 0.147040\n",
            "Test Error: Accuracy: 93.6%, Avg loss: 0.208240\n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.265624\n",
            "Progress:[ 3232/42907]  batch loss:0.070395\n",
            "Progress:[ 6432/42907]  batch loss:0.036065\n",
            "Progress:[ 9632/42907]  batch loss:0.159828\n",
            "Progress:[12832/42907]  batch loss:0.125459\n",
            "Progress:[16032/42907]  batch loss:0.022218\n",
            "Progress:[19232/42907]  batch loss:0.187243\n",
            "Progress:[22432/42907]  batch loss:0.088223\n",
            "Progress:[25632/42907]  batch loss:0.222530\n",
            "Progress:[28832/42907]  batch loss:0.318507\n",
            "Progress:[32032/42907]  batch loss:0.265480\n",
            "Progress:[35232/42907]  batch loss:0.165745\n",
            "Progress:[38432/42907]  batch loss:0.043398\n",
            "Progress:[41632/42907]  batch loss:0.173964\n",
            "Train Error: Avg loss: 0.147564\n",
            "Test Error: Accuracy: 93.2%, Avg loss: 0.184429\n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.083029\n",
            "Progress:[ 3232/42907]  batch loss:0.159002\n",
            "Progress:[ 6432/42907]  batch loss:0.143699\n",
            "Progress:[ 9632/42907]  batch loss:0.221354\n",
            "Progress:[12832/42907]  batch loss:0.096918\n",
            "Progress:[16032/42907]  batch loss:0.016831\n",
            "Progress:[19232/42907]  batch loss:0.184083\n",
            "Progress:[22432/42907]  batch loss:0.023609\n",
            "Progress:[25632/42907]  batch loss:0.230182\n",
            "Progress:[28832/42907]  batch loss:0.155827\n",
            "Progress:[32032/42907]  batch loss:0.151482\n",
            "Progress:[35232/42907]  batch loss:0.065367\n",
            "Progress:[38432/42907]  batch loss:0.177424\n",
            "Progress:[41632/42907]  batch loss:0.150116\n",
            "Train Error: Avg loss: 0.139798\n",
            "Test Error: Accuracy: 93.0%, Avg loss: 0.199998\n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.085724\n",
            "Progress:[ 3232/42907]  batch loss:0.068999\n",
            "Progress:[ 6432/42907]  batch loss:0.043714\n",
            "Progress:[ 9632/42907]  batch loss:0.077900\n",
            "Progress:[12832/42907]  batch loss:0.191620\n",
            "Progress:[16032/42907]  batch loss:0.191654\n",
            "Progress:[19232/42907]  batch loss:0.223327\n",
            "Progress:[22432/42907]  batch loss:0.129240\n",
            "Progress:[25632/42907]  batch loss:0.096153\n",
            "Progress:[28832/42907]  batch loss:0.095568\n",
            "Progress:[32032/42907]  batch loss:0.181603\n",
            "Progress:[35232/42907]  batch loss:0.033092\n",
            "Progress:[38432/42907]  batch loss:0.162945\n",
            "Progress:[41632/42907]  batch loss:0.053260\n",
            "Train Error: Avg loss: 0.140870\n",
            "Test Error: Accuracy: 93.4%, Avg loss: 0.229708\n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.043771\n",
            "Progress:[ 3232/42907]  batch loss:0.074687\n",
            "Progress:[ 6432/42907]  batch loss:0.089187\n",
            "Progress:[ 9632/42907]  batch loss:0.074309\n",
            "Progress:[12832/42907]  batch loss:0.092395\n",
            "Progress:[16032/42907]  batch loss:0.108332\n",
            "Progress:[19232/42907]  batch loss:0.113110\n",
            "Progress:[22432/42907]  batch loss:0.134727\n",
            "Progress:[25632/42907]  batch loss:0.205866\n",
            "Progress:[28832/42907]  batch loss:0.099509\n",
            "Progress:[32032/42907]  batch loss:0.147580\n",
            "Progress:[35232/42907]  batch loss:0.131408\n",
            "Progress:[38432/42907]  batch loss:0.168363\n",
            "Progress:[41632/42907]  batch loss:0.245776\n",
            "Train Error: Avg loss: 0.136288\n",
            "Test Error: Accuracy: 94.1%, Avg loss: 0.205446\n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.116967\n",
            "Progress:[ 3232/42907]  batch loss:0.129368\n",
            "Progress:[ 6432/42907]  batch loss:0.086016\n",
            "Progress:[ 9632/42907]  batch loss:0.280938\n",
            "Progress:[12832/42907]  batch loss:0.072675\n",
            "Progress:[16032/42907]  batch loss:0.083339\n",
            "Progress:[19232/42907]  batch loss:0.068610\n",
            "Progress:[22432/42907]  batch loss:0.131960\n",
            "Progress:[25632/42907]  batch loss:0.079761\n",
            "Progress:[28832/42907]  batch loss:0.193225\n",
            "Progress:[32032/42907]  batch loss:0.183149\n",
            "Progress:[35232/42907]  batch loss:0.035407\n",
            "Progress:[38432/42907]  batch loss:0.140116\n",
            "Progress:[41632/42907]  batch loss:0.114801\n",
            "Train Error: Avg loss: 0.135448\n",
            "Test Error: Accuracy: 93.9%, Avg loss: 0.222469\n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.157330\n",
            "Progress:[ 3232/42907]  batch loss:0.269631\n",
            "Progress:[ 6432/42907]  batch loss:0.110826\n",
            "Progress:[ 9632/42907]  batch loss:0.215305\n",
            "Progress:[12832/42907]  batch loss:0.184118\n",
            "Progress:[16032/42907]  batch loss:0.080493\n",
            "Progress:[19232/42907]  batch loss:0.125884\n",
            "Progress:[22432/42907]  batch loss:0.043092\n",
            "Progress:[25632/42907]  batch loss:0.151327\n",
            "Progress:[28832/42907]  batch loss:0.090605\n",
            "Progress:[32032/42907]  batch loss:0.029966\n",
            "Progress:[35232/42907]  batch loss:0.108701\n",
            "Progress:[38432/42907]  batch loss:0.095662\n",
            "Progress:[41632/42907]  batch loss:0.070241\n",
            "Train Error: Avg loss: 0.135100\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.195659\n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.224903\n",
            "Progress:[ 3232/42907]  batch loss:0.063672\n",
            "Progress:[ 6432/42907]  batch loss:0.094749\n",
            "Progress:[ 9632/42907]  batch loss:0.237053\n",
            "Progress:[12832/42907]  batch loss:0.033575\n",
            "Progress:[16032/42907]  batch loss:0.181472\n",
            "Progress:[19232/42907]  batch loss:0.268409\n",
            "Progress:[22432/42907]  batch loss:0.029963\n",
            "Progress:[25632/42907]  batch loss:0.081144\n",
            "Progress:[28832/42907]  batch loss:0.090649\n",
            "Progress:[32032/42907]  batch loss:0.172095\n",
            "Progress:[35232/42907]  batch loss:0.055328\n",
            "Progress:[38432/42907]  batch loss:0.075361\n",
            "Progress:[41632/42907]  batch loss:0.044068\n",
            "Train Error: Avg loss: 0.128652\n",
            "Test Error: Accuracy: 93.2%, Avg loss: 0.218148\n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.054458\n",
            "Progress:[ 3232/42907]  batch loss:0.125431\n",
            "Progress:[ 6432/42907]  batch loss:0.142464\n",
            "Progress:[ 9632/42907]  batch loss:0.120195\n",
            "Progress:[12832/42907]  batch loss:0.036706\n",
            "Progress:[16032/42907]  batch loss:0.228691\n",
            "Progress:[19232/42907]  batch loss:0.088080\n",
            "Progress:[22432/42907]  batch loss:0.064045\n",
            "Progress:[25632/42907]  batch loss:0.246419\n",
            "Progress:[28832/42907]  batch loss:0.309429\n",
            "Progress:[32032/42907]  batch loss:0.159002\n",
            "Progress:[35232/42907]  batch loss:0.115283\n",
            "Progress:[38432/42907]  batch loss:0.187629\n",
            "Progress:[41632/42907]  batch loss:0.085740\n",
            "Train Error: Avg loss: 0.124868\n",
            "Test Error: Accuracy: 93.0%, Avg loss: 0.223344\n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.191048\n",
            "Progress:[ 3232/42907]  batch loss:0.022898\n",
            "Progress:[ 6432/42907]  batch loss:0.063476\n",
            "Progress:[ 9632/42907]  batch loss:0.316034\n",
            "Progress:[12832/42907]  batch loss:0.105665\n",
            "Progress:[16032/42907]  batch loss:0.155658\n",
            "Progress:[19232/42907]  batch loss:0.195909\n",
            "Progress:[22432/42907]  batch loss:0.179436\n",
            "Progress:[25632/42907]  batch loss:0.099436\n",
            "Progress:[28832/42907]  batch loss:0.091620\n",
            "Progress:[32032/42907]  batch loss:0.263299\n",
            "Progress:[35232/42907]  batch loss:0.159476\n",
            "Progress:[38432/42907]  batch loss:0.064573\n",
            "Progress:[41632/42907]  batch loss:0.127541\n",
            "Train Error: Avg loss: 0.129680\n",
            "Test Error: Accuracy: 92.8%, Avg loss: 0.217397\n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.113876\n",
            "Progress:[ 3232/42907]  batch loss:0.188385\n",
            "Progress:[ 6432/42907]  batch loss:0.081302\n",
            "Progress:[ 9632/42907]  batch loss:0.172291\n",
            "Progress:[12832/42907]  batch loss:0.150371\n",
            "Progress:[16032/42907]  batch loss:0.116519\n",
            "Progress:[19232/42907]  batch loss:0.122310\n",
            "Progress:[22432/42907]  batch loss:0.073815\n",
            "Progress:[25632/42907]  batch loss:0.075614\n",
            "Progress:[28832/42907]  batch loss:0.063287\n",
            "Progress:[32032/42907]  batch loss:0.148955\n",
            "Progress:[35232/42907]  batch loss:0.067786\n",
            "Progress:[38432/42907]  batch loss:0.043824\n",
            "Progress:[41632/42907]  batch loss:0.196819\n",
            "Train Error: Avg loss: 0.125458\n",
            "Test Error: Accuracy: 95.4%, Avg loss: 0.191925\n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.427703\n",
            "Progress:[ 3232/42907]  batch loss:0.176506\n",
            "Progress:[ 6432/42907]  batch loss:0.139119\n",
            "Progress:[ 9632/42907]  batch loss:0.093057\n",
            "Progress:[12832/42907]  batch loss:0.127422\n",
            "Progress:[16032/42907]  batch loss:0.118215\n",
            "Progress:[19232/42907]  batch loss:0.093243\n",
            "Progress:[22432/42907]  batch loss:0.125457\n",
            "Progress:[25632/42907]  batch loss:0.074906\n",
            "Progress:[28832/42907]  batch loss:0.129835\n",
            "Progress:[32032/42907]  batch loss:0.249744\n",
            "Progress:[35232/42907]  batch loss:0.118204\n",
            "Progress:[38432/42907]  batch loss:0.024634\n",
            "Progress:[41632/42907]  batch loss:0.168800\n",
            "Train Error: Avg loss: 0.121181\n",
            "Test Error: Accuracy: 93.7%, Avg loss: 0.200197\n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.087543\n",
            "Progress:[ 3232/42907]  batch loss:0.017586\n",
            "Progress:[ 6432/42907]  batch loss:0.128202\n",
            "Progress:[ 9632/42907]  batch loss:0.043327\n",
            "Progress:[12832/42907]  batch loss:0.067016\n",
            "Progress:[16032/42907]  batch loss:0.128338\n",
            "Progress:[19232/42907]  batch loss:0.283733\n",
            "Progress:[22432/42907]  batch loss:0.054931\n",
            "Progress:[25632/42907]  batch loss:0.090634\n",
            "Progress:[28832/42907]  batch loss:0.154234\n",
            "Progress:[32032/42907]  batch loss:0.067073\n",
            "Progress:[35232/42907]  batch loss:0.117653\n",
            "Progress:[38432/42907]  batch loss:0.138638\n",
            "Progress:[41632/42907]  batch loss:0.088880\n",
            "Train Error: Avg loss: 0.117637\n",
            "Test Error: Accuracy: 93.2%, Avg loss: 0.209934\n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.026277\n",
            "Progress:[ 3232/42907]  batch loss:0.082314\n",
            "Progress:[ 6432/42907]  batch loss:0.169790\n",
            "Progress:[ 9632/42907]  batch loss:0.026873\n",
            "Progress:[12832/42907]  batch loss:0.169154\n",
            "Progress:[16032/42907]  batch loss:0.167000\n",
            "Progress:[19232/42907]  batch loss:0.204902\n",
            "Progress:[22432/42907]  batch loss:0.111845\n",
            "Progress:[25632/42907]  batch loss:0.062996\n",
            "Progress:[28832/42907]  batch loss:0.141228\n",
            "Progress:[32032/42907]  batch loss:0.130365\n",
            "Progress:[35232/42907]  batch loss:0.094504\n",
            "Progress:[38432/42907]  batch loss:0.044997\n",
            "Progress:[41632/42907]  batch loss:0.109763\n",
            "Train Error: Avg loss: 0.115497\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.208780\n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.105559\n",
            "Progress:[ 3232/42907]  batch loss:0.069312\n",
            "Progress:[ 6432/42907]  batch loss:0.021547\n",
            "Progress:[ 9632/42907]  batch loss:0.032946\n",
            "Progress:[12832/42907]  batch loss:0.082084\n",
            "Progress:[16032/42907]  batch loss:0.125645\n",
            "Progress:[19232/42907]  batch loss:0.198124\n",
            "Progress:[22432/42907]  batch loss:0.139620\n",
            "Progress:[25632/42907]  batch loss:0.131162\n",
            "Progress:[28832/42907]  batch loss:0.135620\n",
            "Progress:[32032/42907]  batch loss:0.223226\n",
            "Progress:[35232/42907]  batch loss:0.056597\n",
            "Progress:[38432/42907]  batch loss:0.104554\n",
            "Progress:[41632/42907]  batch loss:0.106999\n",
            "Train Error: Avg loss: 0.119233\n",
            "Test Error: Accuracy: 92.8%, Avg loss: 0.234640\n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.186956\n",
            "Progress:[ 3232/42907]  batch loss:0.059322\n",
            "Progress:[ 6432/42907]  batch loss:0.149449\n",
            "Progress:[ 9632/42907]  batch loss:0.124157\n",
            "Progress:[12832/42907]  batch loss:0.078569\n",
            "Progress:[16032/42907]  batch loss:0.165063\n",
            "Progress:[19232/42907]  batch loss:0.091430\n",
            "Progress:[22432/42907]  batch loss:0.070660\n",
            "Progress:[25632/42907]  batch loss:0.160609\n",
            "Progress:[28832/42907]  batch loss:0.278556\n",
            "Progress:[32032/42907]  batch loss:0.036838\n",
            "Progress:[35232/42907]  batch loss:0.098576\n",
            "Progress:[38432/42907]  batch loss:0.190084\n",
            "Progress:[41632/42907]  batch loss:0.070917\n",
            "Train Error: Avg loss: 0.114652\n",
            "Test Error: Accuracy: 95.6%, Avg loss: 0.209582\n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.012996\n",
            "Progress:[ 3232/42907]  batch loss:0.046325\n",
            "Progress:[ 6432/42907]  batch loss:0.104903\n",
            "Progress:[ 9632/42907]  batch loss:0.088765\n",
            "Progress:[12832/42907]  batch loss:0.100667\n",
            "Progress:[16032/42907]  batch loss:0.173134\n",
            "Progress:[19232/42907]  batch loss:0.091623\n",
            "Progress:[22432/42907]  batch loss:0.098720\n",
            "Progress:[25632/42907]  batch loss:0.194153\n",
            "Progress:[28832/42907]  batch loss:0.036543\n",
            "Progress:[32032/42907]  batch loss:0.071458\n",
            "Progress:[35232/42907]  batch loss:0.223406\n",
            "Progress:[38432/42907]  batch loss:0.126381\n",
            "Progress:[41632/42907]  batch loss:0.138527\n",
            "Train Error: Avg loss: 0.116696\n",
            "Test Error: Accuracy: 95.2%, Avg loss: 0.204512\n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.191737\n",
            "Progress:[ 3232/42907]  batch loss:0.060372\n",
            "Progress:[ 6432/42907]  batch loss:0.110931\n",
            "Progress:[ 9632/42907]  batch loss:0.046606\n",
            "Progress:[12832/42907]  batch loss:0.178604\n",
            "Progress:[16032/42907]  batch loss:0.057787\n",
            "Progress:[19232/42907]  batch loss:0.142926\n",
            "Progress:[22432/42907]  batch loss:0.074869\n",
            "Progress:[25632/42907]  batch loss:0.204662\n",
            "Progress:[28832/42907]  batch loss:0.143960\n",
            "Progress:[32032/42907]  batch loss:0.129139\n",
            "Progress:[35232/42907]  batch loss:0.029715\n",
            "Progress:[38432/42907]  batch loss:0.045689\n",
            "Progress:[41632/42907]  batch loss:0.053394\n",
            "Train Error: Avg loss: 0.112915\n",
            "Test Error: Accuracy: 93.9%, Avg loss: 0.214052\n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.122222\n",
            "Progress:[ 3232/42907]  batch loss:0.025325\n",
            "Progress:[ 6432/42907]  batch loss:0.079871\n",
            "Progress:[ 9632/42907]  batch loss:0.045472\n",
            "Progress:[12832/42907]  batch loss:0.105067\n",
            "Progress:[16032/42907]  batch loss:0.055851\n",
            "Progress:[19232/42907]  batch loss:0.046750\n",
            "Progress:[22432/42907]  batch loss:0.198684\n",
            "Progress:[25632/42907]  batch loss:0.039520\n",
            "Progress:[28832/42907]  batch loss:0.191528\n",
            "Progress:[32032/42907]  batch loss:0.066950\n",
            "Progress:[35232/42907]  batch loss:0.102208\n",
            "Progress:[38432/42907]  batch loss:0.094961\n",
            "Progress:[41632/42907]  batch loss:0.150068\n",
            "Train Error: Avg loss: 0.107069\n",
            "Test Error: Accuracy: 95.2%, Avg loss: 0.203345\n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.094240\n",
            "Progress:[ 3232/42907]  batch loss:0.229117\n",
            "Progress:[ 6432/42907]  batch loss:0.089629\n",
            "Progress:[ 9632/42907]  batch loss:0.153131\n",
            "Progress:[12832/42907]  batch loss:0.084097\n",
            "Progress:[16032/42907]  batch loss:0.157911\n",
            "Progress:[19232/42907]  batch loss:0.036707\n",
            "Progress:[22432/42907]  batch loss:0.109817\n",
            "Progress:[25632/42907]  batch loss:0.127364\n",
            "Progress:[28832/42907]  batch loss:0.208427\n",
            "Progress:[32032/42907]  batch loss:0.149837\n",
            "Progress:[35232/42907]  batch loss:0.054045\n",
            "Progress:[38432/42907]  batch loss:0.030493\n",
            "Progress:[41632/42907]  batch loss:0.142753\n",
            "Train Error: Avg loss: 0.109191\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.195842\n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.094098\n",
            "Progress:[ 3232/42907]  batch loss:0.368975\n",
            "Progress:[ 6432/42907]  batch loss:0.172791\n",
            "Progress:[ 9632/42907]  batch loss:0.063687\n",
            "Progress:[12832/42907]  batch loss:0.221905\n",
            "Progress:[16032/42907]  batch loss:0.172983\n",
            "Progress:[19232/42907]  batch loss:0.092710\n",
            "Progress:[22432/42907]  batch loss:0.118546\n",
            "Progress:[25632/42907]  batch loss:0.078967\n",
            "Progress:[28832/42907]  batch loss:0.095062\n",
            "Progress:[32032/42907]  batch loss:0.088720\n",
            "Progress:[35232/42907]  batch loss:0.116843\n",
            "Progress:[38432/42907]  batch loss:0.041559\n",
            "Progress:[41632/42907]  batch loss:0.025006\n",
            "Train Error: Avg loss: 0.109135\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.204862\n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.092690\n",
            "Progress:[ 3232/42907]  batch loss:0.218891\n",
            "Progress:[ 6432/42907]  batch loss:0.041942\n",
            "Progress:[ 9632/42907]  batch loss:0.115476\n",
            "Progress:[12832/42907]  batch loss:0.060221\n",
            "Progress:[16032/42907]  batch loss:0.049770\n",
            "Progress:[19232/42907]  batch loss:0.118334\n",
            "Progress:[22432/42907]  batch loss:0.069780\n",
            "Progress:[25632/42907]  batch loss:0.114017\n",
            "Progress:[28832/42907]  batch loss:0.089629\n",
            "Progress:[32032/42907]  batch loss:0.055828\n",
            "Progress:[35232/42907]  batch loss:0.149815\n",
            "Progress:[38432/42907]  batch loss:0.047306\n",
            "Progress:[41632/42907]  batch loss:0.076683\n",
            "Train Error: Avg loss: 0.104534\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.209314\n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.073528\n",
            "Progress:[ 3232/42907]  batch loss:0.104988\n",
            "Progress:[ 6432/42907]  batch loss:0.039986\n",
            "Progress:[ 9632/42907]  batch loss:0.114271\n",
            "Progress:[12832/42907]  batch loss:0.097458\n",
            "Progress:[16032/42907]  batch loss:0.144022\n",
            "Progress:[19232/42907]  batch loss:0.098888\n",
            "Progress:[22432/42907]  batch loss:0.069641\n",
            "Progress:[25632/42907]  batch loss:0.105035\n",
            "Progress:[28832/42907]  batch loss:0.067161\n",
            "Progress:[32032/42907]  batch loss:0.228381\n",
            "Progress:[35232/42907]  batch loss:0.050915\n",
            "Progress:[38432/42907]  batch loss:0.062196\n",
            "Progress:[41632/42907]  batch loss:0.113181\n",
            "Train Error: Avg loss: 0.105102\n",
            "Test Error: Accuracy: 95.4%, Avg loss: 0.188583\n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.100362\n",
            "Progress:[ 3232/42907]  batch loss:0.046650\n",
            "Progress:[ 6432/42907]  batch loss:0.069841\n",
            "Progress:[ 9632/42907]  batch loss:0.086424\n",
            "Progress:[12832/42907]  batch loss:0.023753\n",
            "Progress:[16032/42907]  batch loss:0.060508\n",
            "Progress:[19232/42907]  batch loss:0.234962\n",
            "Progress:[22432/42907]  batch loss:0.028440\n",
            "Progress:[25632/42907]  batch loss:0.171280\n",
            "Progress:[28832/42907]  batch loss:0.108491\n",
            "Progress:[32032/42907]  batch loss:0.276514\n",
            "Progress:[35232/42907]  batch loss:0.081367\n",
            "Progress:[38432/42907]  batch loss:0.056793\n",
            "Progress:[41632/42907]  batch loss:0.036981\n",
            "Train Error: Avg loss: 0.104097\n",
            "Test Error: Accuracy: 95.0%, Avg loss: 0.233805\n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.043442\n",
            "Progress:[ 3232/42907]  batch loss:0.130689\n",
            "Progress:[ 6432/42907]  batch loss:0.090353\n",
            "Progress:[ 9632/42907]  batch loss:0.080913\n",
            "Progress:[12832/42907]  batch loss:0.073493\n",
            "Progress:[16032/42907]  batch loss:0.103169\n",
            "Progress:[19232/42907]  batch loss:0.050228\n",
            "Progress:[22432/42907]  batch loss:0.129591\n",
            "Progress:[25632/42907]  batch loss:0.078332\n",
            "Progress:[28832/42907]  batch loss:0.094795\n",
            "Progress:[32032/42907]  batch loss:0.082617\n",
            "Progress:[35232/42907]  batch loss:0.045444\n",
            "Progress:[38432/42907]  batch loss:0.062947\n",
            "Progress:[41632/42907]  batch loss:0.028769\n",
            "Train Error: Avg loss: 0.102885\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.234529\n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.038174\n",
            "Progress:[ 3232/42907]  batch loss:0.099451\n",
            "Progress:[ 6432/42907]  batch loss:0.062792\n",
            "Progress:[ 9632/42907]  batch loss:0.102569\n",
            "Progress:[12832/42907]  batch loss:0.033434\n",
            "Progress:[16032/42907]  batch loss:0.080944\n",
            "Progress:[19232/42907]  batch loss:0.009025\n",
            "Progress:[22432/42907]  batch loss:0.073320\n",
            "Progress:[25632/42907]  batch loss:0.011659\n",
            "Progress:[28832/42907]  batch loss:0.118716\n",
            "Progress:[32032/42907]  batch loss:0.138979\n",
            "Progress:[35232/42907]  batch loss:0.105891\n",
            "Progress:[38432/42907]  batch loss:0.070595\n",
            "Progress:[41632/42907]  batch loss:0.083270\n",
            "Train Error: Avg loss: 0.098530\n",
            "Test Error: Accuracy: 93.9%, Avg loss: 0.240690\n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.105646\n",
            "Progress:[ 3232/42907]  batch loss:0.033140\n",
            "Progress:[ 6432/42907]  batch loss:0.073191\n",
            "Progress:[ 9632/42907]  batch loss:0.109158\n",
            "Progress:[12832/42907]  batch loss:0.153474\n",
            "Progress:[16032/42907]  batch loss:0.006488\n",
            "Progress:[19232/42907]  batch loss:0.090777\n",
            "Progress:[22432/42907]  batch loss:0.063093\n",
            "Progress:[25632/42907]  batch loss:0.018694\n",
            "Progress:[28832/42907]  batch loss:0.245056\n",
            "Progress:[32032/42907]  batch loss:0.030939\n",
            "Progress:[35232/42907]  batch loss:0.188326\n",
            "Progress:[38432/42907]  batch loss:0.161246\n",
            "Progress:[41632/42907]  batch loss:0.082918\n",
            "Train Error: Avg loss: 0.100643\n",
            "Test Error: Accuracy: 93.6%, Avg loss: 0.256293\n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.046979\n",
            "Progress:[ 3232/42907]  batch loss:0.098050\n",
            "Progress:[ 6432/42907]  batch loss:0.030584\n",
            "Progress:[ 9632/42907]  batch loss:0.049653\n",
            "Progress:[12832/42907]  batch loss:0.157923\n",
            "Progress:[16032/42907]  batch loss:0.347455\n",
            "Progress:[19232/42907]  batch loss:0.096681\n",
            "Progress:[22432/42907]  batch loss:0.094289\n",
            "Progress:[25632/42907]  batch loss:0.135912\n",
            "Progress:[28832/42907]  batch loss:0.099486\n",
            "Progress:[32032/42907]  batch loss:0.108284\n",
            "Progress:[35232/42907]  batch loss:0.052965\n",
            "Progress:[38432/42907]  batch loss:0.043164\n",
            "Progress:[41632/42907]  batch loss:0.110063\n",
            "Train Error: Avg loss: 0.095874\n",
            "Test Error: Accuracy: 93.9%, Avg loss: 0.219114\n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.034753\n",
            "Progress:[ 3232/42907]  batch loss:0.131211\n",
            "Progress:[ 6432/42907]  batch loss:0.166051\n",
            "Progress:[ 9632/42907]  batch loss:0.060646\n",
            "Progress:[12832/42907]  batch loss:0.226926\n",
            "Progress:[16032/42907]  batch loss:0.054768\n",
            "Progress:[19232/42907]  batch loss:0.068894\n",
            "Progress:[22432/42907]  batch loss:0.036315\n",
            "Progress:[25632/42907]  batch loss:0.292114\n",
            "Progress:[28832/42907]  batch loss:0.047586\n",
            "Progress:[32032/42907]  batch loss:0.083057\n",
            "Progress:[35232/42907]  batch loss:0.119616\n",
            "Progress:[38432/42907]  batch loss:0.216342\n",
            "Progress:[41632/42907]  batch loss:0.085210\n",
            "Train Error: Avg loss: 0.102642\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.228009\n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.089873\n",
            "Progress:[ 3232/42907]  batch loss:0.086398\n",
            "Progress:[ 6432/42907]  batch loss:0.081805\n",
            "Progress:[ 9632/42907]  batch loss:0.104641\n",
            "Progress:[12832/42907]  batch loss:0.246420\n",
            "Progress:[16032/42907]  batch loss:0.045032\n",
            "Progress:[19232/42907]  batch loss:0.076444\n",
            "Progress:[22432/42907]  batch loss:0.037960\n",
            "Progress:[25632/42907]  batch loss:0.251003\n",
            "Progress:[28832/42907]  batch loss:0.169565\n",
            "Progress:[32032/42907]  batch loss:0.166034\n",
            "Progress:[35232/42907]  batch loss:0.030015\n",
            "Progress:[38432/42907]  batch loss:0.032009\n",
            "Progress:[41632/42907]  batch loss:0.032085\n",
            "Train Error: Avg loss: 0.093067\n",
            "Test Error: Accuracy: 95.4%, Avg loss: 0.214614\n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.239318\n",
            "Progress:[ 3232/42907]  batch loss:0.006201\n",
            "Progress:[ 6432/42907]  batch loss:0.051033\n",
            "Progress:[ 9632/42907]  batch loss:0.061180\n",
            "Progress:[12832/42907]  batch loss:0.032202\n",
            "Progress:[16032/42907]  batch loss:0.226584\n",
            "Progress:[19232/42907]  batch loss:0.138617\n",
            "Progress:[22432/42907]  batch loss:0.125684\n",
            "Progress:[25632/42907]  batch loss:0.092288\n",
            "Progress:[28832/42907]  batch loss:0.110770\n",
            "Progress:[32032/42907]  batch loss:0.121982\n",
            "Progress:[35232/42907]  batch loss:0.057285\n",
            "Progress:[38432/42907]  batch loss:0.049658\n",
            "Progress:[41632/42907]  batch loss:0.102298\n",
            "Train Error: Avg loss: 0.092638\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.211346\n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.046958\n",
            "Progress:[ 3232/42907]  batch loss:0.110815\n",
            "Progress:[ 6432/42907]  batch loss:0.332176\n",
            "Progress:[ 9632/42907]  batch loss:0.099595\n",
            "Progress:[12832/42907]  batch loss:0.011797\n",
            "Progress:[16032/42907]  batch loss:0.065746\n",
            "Progress:[19232/42907]  batch loss:0.204964\n",
            "Progress:[22432/42907]  batch loss:0.200785\n",
            "Progress:[25632/42907]  batch loss:0.074251\n",
            "Progress:[28832/42907]  batch loss:0.039266\n",
            "Progress:[32032/42907]  batch loss:0.158992\n",
            "Progress:[35232/42907]  batch loss:0.059976\n",
            "Progress:[38432/42907]  batch loss:0.106980\n",
            "Progress:[41632/42907]  batch loss:0.203610\n",
            "Train Error: Avg loss: 0.095838\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.212563\n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.087630\n",
            "Progress:[ 3232/42907]  batch loss:0.085843\n",
            "Progress:[ 6432/42907]  batch loss:0.082755\n",
            "Progress:[ 9632/42907]  batch loss:0.142619\n",
            "Progress:[12832/42907]  batch loss:0.078432\n",
            "Progress:[16032/42907]  batch loss:0.055638\n",
            "Progress:[19232/42907]  batch loss:0.134225\n",
            "Progress:[22432/42907]  batch loss:0.094455\n",
            "Progress:[25632/42907]  batch loss:0.200718\n",
            "Progress:[28832/42907]  batch loss:0.285805\n",
            "Progress:[32032/42907]  batch loss:0.083384\n",
            "Progress:[35232/42907]  batch loss:0.344819\n",
            "Progress:[38432/42907]  batch loss:0.094549\n",
            "Progress:[41632/42907]  batch loss:0.076335\n",
            "Train Error: Avg loss: 0.094128\n",
            "Test Error: Accuracy: 94.5%, Avg loss: 0.251254\n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.143830\n",
            "Progress:[ 3232/42907]  batch loss:0.052702\n",
            "Progress:[ 6432/42907]  batch loss:0.030351\n",
            "Progress:[ 9632/42907]  batch loss:0.008039\n",
            "Progress:[12832/42907]  batch loss:0.073638\n",
            "Progress:[16032/42907]  batch loss:0.028189\n",
            "Progress:[19232/42907]  batch loss:0.107283\n",
            "Progress:[22432/42907]  batch loss:0.279263\n",
            "Progress:[25632/42907]  batch loss:0.039742\n",
            "Progress:[28832/42907]  batch loss:0.010171\n",
            "Progress:[32032/42907]  batch loss:0.050427\n",
            "Progress:[35232/42907]  batch loss:0.028246\n",
            "Progress:[38432/42907]  batch loss:0.277339\n",
            "Progress:[41632/42907]  batch loss:0.060689\n",
            "Train Error: Avg loss: 0.091256\n",
            "Test Error: Accuracy: 94.5%, Avg loss: 0.228909\n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.013900\n",
            "Progress:[ 3232/42907]  batch loss:0.016650\n",
            "Progress:[ 6432/42907]  batch loss:0.089330\n",
            "Progress:[ 9632/42907]  batch loss:0.017268\n",
            "Progress:[12832/42907]  batch loss:0.013160\n",
            "Progress:[16032/42907]  batch loss:0.062732\n",
            "Progress:[19232/42907]  batch loss:0.139992\n",
            "Progress:[22432/42907]  batch loss:0.015126\n",
            "Progress:[25632/42907]  batch loss:0.073755\n",
            "Progress:[28832/42907]  batch loss:0.041463\n",
            "Progress:[32032/42907]  batch loss:0.175868\n",
            "Progress:[35232/42907]  batch loss:0.423825\n",
            "Progress:[38432/42907]  batch loss:0.100008\n",
            "Progress:[41632/42907]  batch loss:0.094095\n",
            "Train Error: Avg loss: 0.093271\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.216272\n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.137410\n",
            "Progress:[ 3232/42907]  batch loss:0.241365\n",
            "Progress:[ 6432/42907]  batch loss:0.036470\n",
            "Progress:[ 9632/42907]  batch loss:0.036506\n",
            "Progress:[12832/42907]  batch loss:0.120055\n",
            "Progress:[16032/42907]  batch loss:0.055561\n",
            "Progress:[19232/42907]  batch loss:0.161499\n",
            "Progress:[22432/42907]  batch loss:0.062992\n",
            "Progress:[25632/42907]  batch loss:0.039683\n",
            "Progress:[28832/42907]  batch loss:0.102053\n",
            "Progress:[32032/42907]  batch loss:0.052665\n",
            "Progress:[35232/42907]  batch loss:0.066507\n",
            "Progress:[38432/42907]  batch loss:0.104780\n",
            "Progress:[41632/42907]  batch loss:0.026984\n",
            "Train Error: Avg loss: 0.090933\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.240657\n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.038255\n",
            "Progress:[ 3232/42907]  batch loss:0.074170\n",
            "Progress:[ 6432/42907]  batch loss:0.026207\n",
            "Progress:[ 9632/42907]  batch loss:0.015026\n",
            "Progress:[12832/42907]  batch loss:0.041337\n",
            "Progress:[16032/42907]  batch loss:0.124124\n",
            "Progress:[19232/42907]  batch loss:0.085985\n",
            "Progress:[22432/42907]  batch loss:0.040187\n",
            "Progress:[25632/42907]  batch loss:0.061141\n",
            "Progress:[28832/42907]  batch loss:0.018166\n",
            "Progress:[32032/42907]  batch loss:0.047717\n",
            "Progress:[35232/42907]  batch loss:0.112422\n",
            "Progress:[38432/42907]  batch loss:0.053044\n",
            "Progress:[41632/42907]  batch loss:0.010844\n",
            "Train Error: Avg loss: 0.091962\n",
            "Test Error: Accuracy: 94.3%, Avg loss: 0.231705\n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.029949\n",
            "Progress:[ 3232/42907]  batch loss:0.039063\n",
            "Progress:[ 6432/42907]  batch loss:0.081685\n",
            "Progress:[ 9632/42907]  batch loss:0.067207\n",
            "Progress:[12832/42907]  batch loss:0.063446\n",
            "Progress:[16032/42907]  batch loss:0.063051\n",
            "Progress:[19232/42907]  batch loss:0.065951\n",
            "Progress:[22432/42907]  batch loss:0.280003\n",
            "Progress:[25632/42907]  batch loss:0.125937\n",
            "Progress:[28832/42907]  batch loss:0.009302\n",
            "Progress:[32032/42907]  batch loss:0.011115\n",
            "Progress:[35232/42907]  batch loss:0.071617\n",
            "Progress:[38432/42907]  batch loss:0.147562\n",
            "Progress:[41632/42907]  batch loss:0.013103\n",
            "Train Error: Avg loss: 0.086099\n",
            "Test Error: Accuracy: 94.1%, Avg loss: 0.235274\n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.190339\n",
            "Progress:[ 3232/42907]  batch loss:0.071557\n",
            "Progress:[ 6432/42907]  batch loss:0.045563\n",
            "Progress:[ 9632/42907]  batch loss:0.078092\n",
            "Progress:[12832/42907]  batch loss:0.092268\n",
            "Progress:[16032/42907]  batch loss:0.145289\n",
            "Progress:[19232/42907]  batch loss:0.035440\n",
            "Progress:[22432/42907]  batch loss:0.038060\n",
            "Progress:[25632/42907]  batch loss:0.064170\n",
            "Progress:[28832/42907]  batch loss:0.094962\n",
            "Progress:[32032/42907]  batch loss:0.037734\n",
            "Progress:[35232/42907]  batch loss:0.036621\n",
            "Progress:[38432/42907]  batch loss:0.040056\n",
            "Progress:[41632/42907]  batch loss:0.053567\n",
            "Train Error: Avg loss: 0.085988\n",
            "Test Error: Accuracy: 93.7%, Avg loss: 0.265991\n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.112314\n",
            "Progress:[ 3232/42907]  batch loss:0.023140\n",
            "Progress:[ 6432/42907]  batch loss:0.125699\n",
            "Progress:[ 9632/42907]  batch loss:0.665417\n",
            "Progress:[12832/42907]  batch loss:0.134865\n",
            "Progress:[16032/42907]  batch loss:0.098372\n",
            "Progress:[19232/42907]  batch loss:0.096810\n",
            "Progress:[22432/42907]  batch loss:0.083086\n",
            "Progress:[25632/42907]  batch loss:0.022195\n",
            "Progress:[28832/42907]  batch loss:0.054977\n",
            "Progress:[32032/42907]  batch loss:0.056832\n",
            "Progress:[35232/42907]  batch loss:0.133624\n",
            "Progress:[38432/42907]  batch loss:0.084757\n",
            "Progress:[41632/42907]  batch loss:0.062753\n",
            "Train Error: Avg loss: 0.090465\n",
            "Test Error: Accuracy: 93.4%, Avg loss: 0.238661\n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.097995\n",
            "Progress:[ 3232/42907]  batch loss:0.127907\n",
            "Progress:[ 6432/42907]  batch loss:0.067609\n",
            "Progress:[ 9632/42907]  batch loss:0.075943\n",
            "Progress:[12832/42907]  batch loss:0.093972\n",
            "Progress:[16032/42907]  batch loss:0.022973\n",
            "Progress:[19232/42907]  batch loss:0.044502\n",
            "Progress:[22432/42907]  batch loss:0.026389\n",
            "Progress:[25632/42907]  batch loss:0.036873\n",
            "Progress:[28832/42907]  batch loss:0.003484\n",
            "Progress:[32032/42907]  batch loss:0.068901\n",
            "Progress:[35232/42907]  batch loss:0.043678\n",
            "Progress:[38432/42907]  batch loss:0.091882\n",
            "Progress:[41632/42907]  batch loss:0.040217\n",
            "Train Error: Avg loss: 0.088624\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.224212\n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.018154\n",
            "Progress:[ 3232/42907]  batch loss:0.115660\n",
            "Progress:[ 6432/42907]  batch loss:0.020853\n",
            "Progress:[ 9632/42907]  batch loss:0.060743\n",
            "Progress:[12832/42907]  batch loss:0.033742\n",
            "Progress:[16032/42907]  batch loss:0.026480\n",
            "Progress:[19232/42907]  batch loss:0.053252\n",
            "Progress:[22432/42907]  batch loss:0.206632\n",
            "Progress:[25632/42907]  batch loss:0.005574\n",
            "Progress:[28832/42907]  batch loss:0.106548\n",
            "Progress:[32032/42907]  batch loss:0.117081\n",
            "Progress:[35232/42907]  batch loss:0.070911\n",
            "Progress:[38432/42907]  batch loss:0.057832\n",
            "Progress:[41632/42907]  batch loss:0.025909\n",
            "Train Error: Avg loss: 0.080756\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.227941\n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.024948\n",
            "Progress:[ 3232/42907]  batch loss:0.042344\n",
            "Progress:[ 6432/42907]  batch loss:0.010246\n",
            "Progress:[ 9632/42907]  batch loss:0.168081\n",
            "Progress:[12832/42907]  batch loss:0.040905\n",
            "Progress:[16032/42907]  batch loss:0.044088\n",
            "Progress:[19232/42907]  batch loss:0.042268\n",
            "Progress:[22432/42907]  batch loss:0.120168\n",
            "Progress:[25632/42907]  batch loss:0.069273\n",
            "Progress:[28832/42907]  batch loss:0.081616\n",
            "Progress:[32032/42907]  batch loss:0.084620\n",
            "Progress:[35232/42907]  batch loss:0.216591\n",
            "Progress:[38432/42907]  batch loss:0.090900\n",
            "Progress:[41632/42907]  batch loss:0.109307\n",
            "Train Error: Avg loss: 0.088594\n",
            "Test Error: Accuracy: 95.9%, Avg loss: 0.200581\n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.281132\n",
            "Progress:[ 3232/42907]  batch loss:0.011781\n",
            "Progress:[ 6432/42907]  batch loss:0.024333\n",
            "Progress:[ 9632/42907]  batch loss:0.062227\n",
            "Progress:[12832/42907]  batch loss:0.008453\n",
            "Progress:[16032/42907]  batch loss:0.173065\n",
            "Progress:[19232/42907]  batch loss:0.120251\n",
            "Progress:[22432/42907]  batch loss:0.122973\n",
            "Progress:[25632/42907]  batch loss:0.050592\n",
            "Progress:[28832/42907]  batch loss:0.088139\n",
            "Progress:[32032/42907]  batch loss:0.044798\n",
            "Progress:[35232/42907]  batch loss:0.114203\n",
            "Progress:[38432/42907]  batch loss:0.093059\n",
            "Progress:[41632/42907]  batch loss:0.075384\n",
            "Train Error: Avg loss: 0.085762\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.218590\n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.020933\n",
            "Progress:[ 3232/42907]  batch loss:0.047782\n",
            "Progress:[ 6432/42907]  batch loss:0.056781\n",
            "Progress:[ 9632/42907]  batch loss:0.033763\n",
            "Progress:[12832/42907]  batch loss:0.137585\n",
            "Progress:[16032/42907]  batch loss:0.085162\n",
            "Progress:[19232/42907]  batch loss:0.085324\n",
            "Progress:[22432/42907]  batch loss:0.025450\n",
            "Progress:[25632/42907]  batch loss:0.002633\n",
            "Progress:[28832/42907]  batch loss:0.159351\n",
            "Progress:[32032/42907]  batch loss:0.263600\n",
            "Progress:[35232/42907]  batch loss:0.243813\n",
            "Progress:[38432/42907]  batch loss:0.079672\n",
            "Progress:[41632/42907]  batch loss:0.144145\n",
            "Train Error: Avg loss: 0.086262\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.245832\n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.034491\n",
            "Progress:[ 3232/42907]  batch loss:0.109869\n",
            "Progress:[ 6432/42907]  batch loss:0.053856\n",
            "Progress:[ 9632/42907]  batch loss:0.050296\n",
            "Progress:[12832/42907]  batch loss:0.029486\n",
            "Progress:[16032/42907]  batch loss:0.057348\n",
            "Progress:[19232/42907]  batch loss:0.223338\n",
            "Progress:[22432/42907]  batch loss:0.155533\n",
            "Progress:[25632/42907]  batch loss:0.070610\n",
            "Progress:[28832/42907]  batch loss:0.118078\n",
            "Progress:[32032/42907]  batch loss:0.005972\n",
            "Progress:[35232/42907]  batch loss:0.081516\n",
            "Progress:[38432/42907]  batch loss:0.173289\n",
            "Progress:[41632/42907]  batch loss:0.056400\n",
            "Train Error: Avg loss: 0.080668\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.258293\n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.055980\n",
            "Progress:[ 3232/42907]  batch loss:0.151246\n",
            "Progress:[ 6432/42907]  batch loss:0.057676\n",
            "Progress:[ 9632/42907]  batch loss:0.012949\n",
            "Progress:[12832/42907]  batch loss:0.023359\n",
            "Progress:[16032/42907]  batch loss:0.014209\n",
            "Progress:[19232/42907]  batch loss:0.066182\n",
            "Progress:[22432/42907]  batch loss:0.061457\n",
            "Progress:[25632/42907]  batch loss:0.080920\n",
            "Progress:[28832/42907]  batch loss:0.088681\n",
            "Progress:[32032/42907]  batch loss:0.105476\n",
            "Progress:[35232/42907]  batch loss:0.076892\n",
            "Progress:[38432/42907]  batch loss:0.036861\n",
            "Progress:[41632/42907]  batch loss:0.089886\n",
            "Train Error: Avg loss: 0.082962\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.257123\n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.087154\n",
            "Progress:[ 3232/42907]  batch loss:0.019406\n",
            "Progress:[ 6432/42907]  batch loss:0.216045\n",
            "Progress:[ 9632/42907]  batch loss:0.053843\n",
            "Progress:[12832/42907]  batch loss:0.119648\n",
            "Progress:[16032/42907]  batch loss:0.116615\n",
            "Progress:[19232/42907]  batch loss:0.130389\n",
            "Progress:[22432/42907]  batch loss:0.033175\n",
            "Progress:[25632/42907]  batch loss:0.073395\n",
            "Progress:[28832/42907]  batch loss:0.187387\n",
            "Progress:[32032/42907]  batch loss:0.234167\n",
            "Progress:[35232/42907]  batch loss:0.090930\n",
            "Progress:[38432/42907]  batch loss:0.113506\n",
            "Progress:[41632/42907]  batch loss:0.067097\n",
            "Train Error: Avg loss: 0.082917\n",
            "Test Error: Accuracy: 94.5%, Avg loss: 0.240113\n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.060728\n",
            "Progress:[ 3232/42907]  batch loss:0.060044\n",
            "Progress:[ 6432/42907]  batch loss:0.400511\n",
            "Progress:[ 9632/42907]  batch loss:0.005304\n",
            "Progress:[12832/42907]  batch loss:0.028812\n",
            "Progress:[16032/42907]  batch loss:0.002557\n",
            "Progress:[19232/42907]  batch loss:0.042368\n",
            "Progress:[22432/42907]  batch loss:0.092621\n",
            "Progress:[25632/42907]  batch loss:0.194805\n",
            "Progress:[28832/42907]  batch loss:0.071558\n",
            "Progress:[32032/42907]  batch loss:0.027568\n",
            "Progress:[35232/42907]  batch loss:0.086562\n",
            "Progress:[38432/42907]  batch loss:0.062910\n",
            "Progress:[41632/42907]  batch loss:0.033191\n",
            "Train Error: Avg loss: 0.081365\n",
            "Test Error: Accuracy: 94.5%, Avg loss: 0.236209\n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.031990\n",
            "Progress:[ 3232/42907]  batch loss:0.046838\n",
            "Progress:[ 6432/42907]  batch loss:0.028780\n",
            "Progress:[ 9632/42907]  batch loss:0.081386\n",
            "Progress:[12832/42907]  batch loss:0.038804\n",
            "Progress:[16032/42907]  batch loss:0.084735\n",
            "Progress:[19232/42907]  batch loss:0.014539\n",
            "Progress:[22432/42907]  batch loss:0.150142\n",
            "Progress:[25632/42907]  batch loss:0.058349\n",
            "Progress:[28832/42907]  batch loss:0.073885\n",
            "Progress:[32032/42907]  batch loss:0.023067\n",
            "Progress:[35232/42907]  batch loss:0.109402\n",
            "Progress:[38432/42907]  batch loss:0.035174\n",
            "Progress:[41632/42907]  batch loss:0.044240\n",
            "Train Error: Avg loss: 0.086072\n",
            "Test Error: Accuracy: 95.2%, Avg loss: 0.227734\n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.061095\n",
            "Progress:[ 3232/42907]  batch loss:0.124574\n",
            "Progress:[ 6432/42907]  batch loss:0.112090\n",
            "Progress:[ 9632/42907]  batch loss:0.100947\n",
            "Progress:[12832/42907]  batch loss:0.064768\n",
            "Progress:[16032/42907]  batch loss:0.050208\n",
            "Progress:[19232/42907]  batch loss:0.060279\n",
            "Progress:[22432/42907]  batch loss:0.110367\n",
            "Progress:[25632/42907]  batch loss:0.013667\n",
            "Progress:[28832/42907]  batch loss:0.015969\n",
            "Progress:[32032/42907]  batch loss:0.086426\n",
            "Progress:[35232/42907]  batch loss:0.223411\n",
            "Progress:[38432/42907]  batch loss:0.009202\n",
            "Progress:[41632/42907]  batch loss:0.106064\n",
            "Train Error: Avg loss: 0.081385\n",
            "Test Error: Accuracy: 95.4%, Avg loss: 0.219301\n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.070740\n",
            "Progress:[ 3232/42907]  batch loss:0.013236\n",
            "Progress:[ 6432/42907]  batch loss:0.015383\n",
            "Progress:[ 9632/42907]  batch loss:0.194369\n",
            "Progress:[12832/42907]  batch loss:0.038104\n",
            "Progress:[16032/42907]  batch loss:0.142450\n",
            "Progress:[19232/42907]  batch loss:0.195732\n",
            "Progress:[22432/42907]  batch loss:0.073731\n",
            "Progress:[25632/42907]  batch loss:0.015680\n",
            "Progress:[28832/42907]  batch loss:0.032664\n",
            "Progress:[32032/42907]  batch loss:0.003937\n",
            "Progress:[35232/42907]  batch loss:0.100177\n",
            "Progress:[38432/42907]  batch loss:0.052150\n",
            "Progress:[41632/42907]  batch loss:0.070415\n",
            "Train Error: Avg loss: 0.077023\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.244430\n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.172128\n",
            "Progress:[ 3232/42907]  batch loss:0.097887\n",
            "Progress:[ 6432/42907]  batch loss:0.118064\n",
            "Progress:[ 9632/42907]  batch loss:0.009892\n",
            "Progress:[12832/42907]  batch loss:0.082890\n",
            "Progress:[16032/42907]  batch loss:0.019995\n",
            "Progress:[19232/42907]  batch loss:0.012250\n",
            "Progress:[22432/42907]  batch loss:0.093098\n",
            "Progress:[25632/42907]  batch loss:0.037124\n",
            "Progress:[28832/42907]  batch loss:0.215202\n",
            "Progress:[32032/42907]  batch loss:0.073074\n",
            "Progress:[35232/42907]  batch loss:0.109123\n",
            "Progress:[38432/42907]  batch loss:0.057148\n",
            "Progress:[41632/42907]  batch loss:0.081315\n",
            "Train Error: Avg loss: 0.080910\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.233448\n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.047091\n",
            "Progress:[ 3232/42907]  batch loss:0.008304\n",
            "Progress:[ 6432/42907]  batch loss:0.029500\n",
            "Progress:[ 9632/42907]  batch loss:0.027496\n",
            "Progress:[12832/42907]  batch loss:0.048550\n",
            "Progress:[16032/42907]  batch loss:0.026235\n",
            "Progress:[19232/42907]  batch loss:0.035470\n",
            "Progress:[22432/42907]  batch loss:0.155477\n",
            "Progress:[25632/42907]  batch loss:0.053765\n",
            "Progress:[28832/42907]  batch loss:0.030749\n",
            "Progress:[32032/42907]  batch loss:0.050740\n",
            "Progress:[35232/42907]  batch loss:0.065068\n",
            "Progress:[38432/42907]  batch loss:0.100662\n",
            "Progress:[41632/42907]  batch loss:0.414460\n",
            "Train Error: Avg loss: 0.075501\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.227257\n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.082335\n",
            "Progress:[ 3232/42907]  batch loss:0.038501\n",
            "Progress:[ 6432/42907]  batch loss:0.072519\n",
            "Progress:[ 9632/42907]  batch loss:0.009022\n",
            "Progress:[12832/42907]  batch loss:0.001097\n",
            "Progress:[16032/42907]  batch loss:0.024590\n",
            "Progress:[19232/42907]  batch loss:0.039731\n",
            "Progress:[22432/42907]  batch loss:0.052921\n",
            "Progress:[25632/42907]  batch loss:0.044449\n",
            "Progress:[28832/42907]  batch loss:0.096419\n",
            "Progress:[32032/42907]  batch loss:0.032166\n",
            "Progress:[35232/42907]  batch loss:0.053892\n",
            "Progress:[38432/42907]  batch loss:0.085244\n",
            "Progress:[41632/42907]  batch loss:0.119703\n",
            "Train Error: Avg loss: 0.079680\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.211407\n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.067637\n",
            "Progress:[ 3232/42907]  batch loss:0.025978\n",
            "Progress:[ 6432/42907]  batch loss:0.087591\n",
            "Progress:[ 9632/42907]  batch loss:0.085536\n",
            "Progress:[12832/42907]  batch loss:0.118692\n",
            "Progress:[16032/42907]  batch loss:0.007344\n",
            "Progress:[19232/42907]  batch loss:0.031920\n",
            "Progress:[22432/42907]  batch loss:0.033074\n",
            "Progress:[25632/42907]  batch loss:0.013507\n",
            "Progress:[28832/42907]  batch loss:0.160055\n",
            "Progress:[32032/42907]  batch loss:0.086536\n",
            "Progress:[35232/42907]  batch loss:0.088992\n",
            "Progress:[38432/42907]  batch loss:0.075326\n",
            "Progress:[41632/42907]  batch loss:0.050337\n",
            "Train Error: Avg loss: 0.078171\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.212120\n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.181638\n",
            "Progress:[ 3232/42907]  batch loss:0.083392\n",
            "Progress:[ 6432/42907]  batch loss:0.084593\n",
            "Progress:[ 9632/42907]  batch loss:0.014023\n",
            "Progress:[12832/42907]  batch loss:0.017685\n",
            "Progress:[16032/42907]  batch loss:0.132057\n",
            "Progress:[19232/42907]  batch loss:0.092913\n",
            "Progress:[22432/42907]  batch loss:0.080384\n",
            "Progress:[25632/42907]  batch loss:0.076658\n",
            "Progress:[28832/42907]  batch loss:0.027306\n",
            "Progress:[32032/42907]  batch loss:0.061172\n",
            "Progress:[35232/42907]  batch loss:0.087879\n",
            "Progress:[38432/42907]  batch loss:0.135556\n",
            "Progress:[41632/42907]  batch loss:0.046841\n",
            "Train Error: Avg loss: 0.077507\n",
            "Test Error: Accuracy: 95.4%, Avg loss: 0.248742\n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.044722\n",
            "Progress:[ 3232/42907]  batch loss:0.031021\n",
            "Progress:[ 6432/42907]  batch loss:0.034909\n",
            "Progress:[ 9632/42907]  batch loss:0.005987\n",
            "Progress:[12832/42907]  batch loss:0.145683\n",
            "Progress:[16032/42907]  batch loss:0.058708\n",
            "Progress:[19232/42907]  batch loss:0.071819\n",
            "Progress:[22432/42907]  batch loss:0.107447\n",
            "Progress:[25632/42907]  batch loss:0.025596\n",
            "Progress:[28832/42907]  batch loss:0.045312\n",
            "Progress:[32032/42907]  batch loss:0.047707\n",
            "Progress:[35232/42907]  batch loss:0.063820\n",
            "Progress:[38432/42907]  batch loss:0.126209\n",
            "Progress:[41632/42907]  batch loss:0.083698\n",
            "Train Error: Avg loss: 0.076647\n",
            "Test Error: Accuracy: 94.5%, Avg loss: 0.259330\n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.073685\n",
            "Progress:[ 3232/42907]  batch loss:0.143206\n",
            "Progress:[ 6432/42907]  batch loss:0.022756\n",
            "Progress:[ 9632/42907]  batch loss:0.088946\n",
            "Progress:[12832/42907]  batch loss:0.039791\n",
            "Progress:[16032/42907]  batch loss:0.073650\n",
            "Progress:[19232/42907]  batch loss:0.084790\n",
            "Progress:[22432/42907]  batch loss:0.050011\n",
            "Progress:[25632/42907]  batch loss:0.096685\n",
            "Progress:[28832/42907]  batch loss:0.089489\n",
            "Progress:[32032/42907]  batch loss:0.406344\n",
            "Progress:[35232/42907]  batch loss:0.077720\n",
            "Progress:[38432/42907]  batch loss:0.021575\n",
            "Progress:[41632/42907]  batch loss:0.046589\n",
            "Train Error: Avg loss: 0.077657\n",
            "Test Error: Accuracy: 94.7%, Avg loss: 0.284455\n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.001843\n",
            "Progress:[ 3232/42907]  batch loss:0.055221\n",
            "Progress:[ 6432/42907]  batch loss:0.214038\n",
            "Progress:[ 9632/42907]  batch loss:0.054545\n",
            "Progress:[12832/42907]  batch loss:0.131841\n",
            "Progress:[16032/42907]  batch loss:0.158596\n",
            "Progress:[19232/42907]  batch loss:0.087964\n",
            "Progress:[22432/42907]  batch loss:0.139299\n",
            "Progress:[25632/42907]  batch loss:0.005173\n",
            "Progress:[28832/42907]  batch loss:0.028709\n",
            "Progress:[32032/42907]  batch loss:0.037688\n",
            "Progress:[35232/42907]  batch loss:0.058426\n",
            "Progress:[38432/42907]  batch loss:0.022145\n",
            "Progress:[41632/42907]  batch loss:0.266411\n",
            "Train Error: Avg loss: 0.076388\n",
            "Test Error: Accuracy: 94.8%, Avg loss: 0.249361\n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.184957\n",
            "Progress:[ 3232/42907]  batch loss:0.018824\n",
            "Progress:[ 6432/42907]  batch loss:0.076645\n",
            "Progress:[ 9632/42907]  batch loss:0.063551\n",
            "Progress:[12832/42907]  batch loss:0.118398\n",
            "Progress:[16032/42907]  batch loss:0.049749\n",
            "Progress:[19232/42907]  batch loss:0.160004\n",
            "Progress:[22432/42907]  batch loss:0.143918\n",
            "Progress:[25632/42907]  batch loss:0.071500\n",
            "Progress:[28832/42907]  batch loss:0.028533\n",
            "Progress:[32032/42907]  batch loss:0.050829\n",
            "Progress:[35232/42907]  batch loss:0.097775\n",
            "Progress:[38432/42907]  batch loss:0.019097\n",
            "Progress:[41632/42907]  batch loss:0.023938\n",
            "Train Error: Avg loss: 0.076165\n",
            "Test Error: Accuracy: 94.1%, Avg loss: 0.288425\n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.007013\n",
            "Progress:[ 3232/42907]  batch loss:0.057914\n",
            "Progress:[ 6432/42907]  batch loss:0.051817\n",
            "Progress:[ 9632/42907]  batch loss:0.002919\n",
            "Progress:[12832/42907]  batch loss:0.078808\n",
            "Progress:[16032/42907]  batch loss:0.028606\n",
            "Progress:[19232/42907]  batch loss:0.008263\n",
            "Progress:[22432/42907]  batch loss:0.062787\n",
            "Progress:[25632/42907]  batch loss:0.039739\n",
            "Progress:[28832/42907]  batch loss:0.027203\n",
            "Progress:[32032/42907]  batch loss:0.033058\n",
            "Progress:[35232/42907]  batch loss:0.025065\n",
            "Progress:[38432/42907]  batch loss:0.087406\n",
            "Progress:[41632/42907]  batch loss:0.194563\n",
            "Train Error: Avg loss: 0.078419\n",
            "Test Error: Accuracy: 93.6%, Avg loss: 0.251004\n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.030996\n",
            "Progress:[ 3232/42907]  batch loss:0.033283\n",
            "Progress:[ 6432/42907]  batch loss:0.003518\n",
            "Progress:[ 9632/42907]  batch loss:0.143141\n",
            "Progress:[12832/42907]  batch loss:0.113329\n",
            "Progress:[16032/42907]  batch loss:0.080585\n",
            "Progress:[19232/42907]  batch loss:0.052789\n",
            "Progress:[22432/42907]  batch loss:0.053559\n",
            "Progress:[25632/42907]  batch loss:0.054968\n",
            "Progress:[28832/42907]  batch loss:0.025910\n",
            "Progress:[32032/42907]  batch loss:0.022488\n",
            "Progress:[35232/42907]  batch loss:0.052389\n",
            "Progress:[38432/42907]  batch loss:0.075990\n",
            "Progress:[41632/42907]  batch loss:0.096279\n",
            "Train Error: Avg loss: 0.070590\n",
            "Test Error: Accuracy: 95.4%, Avg loss: 0.211707\n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.230071\n",
            "Progress:[ 3232/42907]  batch loss:0.095306\n",
            "Progress:[ 6432/42907]  batch loss:0.000457\n",
            "Progress:[ 9632/42907]  batch loss:0.123146\n",
            "Progress:[12832/42907]  batch loss:0.030394\n",
            "Progress:[16032/42907]  batch loss:0.124266\n",
            "Progress:[19232/42907]  batch loss:0.026381\n",
            "Progress:[22432/42907]  batch loss:0.031054\n",
            "Progress:[25632/42907]  batch loss:0.032745\n",
            "Progress:[28832/42907]  batch loss:0.149670\n",
            "Progress:[32032/42907]  batch loss:0.269900\n",
            "Progress:[35232/42907]  batch loss:0.121381\n",
            "Progress:[38432/42907]  batch loss:0.060698\n",
            "Progress:[41632/42907]  batch loss:0.011966\n",
            "Train Error: Avg loss: 0.081604\n",
            "Test Error: Accuracy: 93.7%, Avg loss: 0.257618\n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.077260\n",
            "Progress:[ 3232/42907]  batch loss:0.075620\n",
            "Progress:[ 6432/42907]  batch loss:0.084855\n",
            "Progress:[ 9632/42907]  batch loss:0.080834\n",
            "Progress:[12832/42907]  batch loss:0.102945\n",
            "Progress:[16032/42907]  batch loss:0.159600\n",
            "Progress:[19232/42907]  batch loss:0.038845\n",
            "Progress:[22432/42907]  batch loss:0.001352\n",
            "Progress:[25632/42907]  batch loss:0.031356\n",
            "Progress:[28832/42907]  batch loss:0.156390\n",
            "Progress:[32032/42907]  batch loss:0.016813\n",
            "Progress:[35232/42907]  batch loss:0.015362\n",
            "Progress:[38432/42907]  batch loss:0.093435\n",
            "Progress:[41632/42907]  batch loss:0.255400\n",
            "Train Error: Avg loss: 0.070090\n",
            "Test Error: Accuracy: 94.1%, Avg loss: 0.248640\n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.020865\n",
            "Progress:[ 3232/42907]  batch loss:0.116702\n",
            "Progress:[ 6432/42907]  batch loss:0.070692\n",
            "Progress:[ 9632/42907]  batch loss:0.011657\n",
            "Progress:[12832/42907]  batch loss:0.025530\n",
            "Progress:[16032/42907]  batch loss:0.169565\n",
            "Progress:[19232/42907]  batch loss:0.021753\n",
            "Progress:[22432/42907]  batch loss:0.090611\n",
            "Progress:[25632/42907]  batch loss:0.052053\n",
            "Progress:[28832/42907]  batch loss:0.050941\n",
            "Progress:[32032/42907]  batch loss:0.030400\n",
            "Progress:[35232/42907]  batch loss:0.068676\n",
            "Progress:[38432/42907]  batch loss:0.107896\n",
            "Progress:[41632/42907]  batch loss:0.110138\n",
            "Train Error: Avg loss: 0.069987\n",
            "Test Error: Accuracy: 95.0%, Avg loss: 0.258340\n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.022129\n",
            "Progress:[ 3232/42907]  batch loss:0.030172\n",
            "Progress:[ 6432/42907]  batch loss:0.092723\n",
            "Progress:[ 9632/42907]  batch loss:0.027027\n",
            "Progress:[12832/42907]  batch loss:0.042211\n",
            "Progress:[16032/42907]  batch loss:0.348250\n",
            "Progress:[19232/42907]  batch loss:0.177600\n",
            "Progress:[22432/42907]  batch loss:0.054885\n",
            "Progress:[25632/42907]  batch loss:0.014271\n",
            "Progress:[28832/42907]  batch loss:0.027435\n",
            "Progress:[32032/42907]  batch loss:0.025687\n",
            "Progress:[35232/42907]  batch loss:0.056590\n",
            "Progress:[38432/42907]  batch loss:0.087009\n",
            "Progress:[41632/42907]  batch loss:0.213648\n",
            "Train Error: Avg loss: 0.074104\n",
            "Test Error: Accuracy: 95.0%, Avg loss: 0.223746\n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.025846\n",
            "Progress:[ 3232/42907]  batch loss:0.004452\n",
            "Progress:[ 6432/42907]  batch loss:0.015780\n",
            "Progress:[ 9632/42907]  batch loss:0.026105\n",
            "Progress:[12832/42907]  batch loss:0.032357\n",
            "Progress:[16032/42907]  batch loss:0.232110\n",
            "Progress:[19232/42907]  batch loss:0.033603\n",
            "Progress:[22432/42907]  batch loss:0.055831\n",
            "Progress:[25632/42907]  batch loss:0.094350\n",
            "Progress:[28832/42907]  batch loss:0.032638\n",
            "Progress:[32032/42907]  batch loss:0.259104\n",
            "Progress:[35232/42907]  batch loss:0.044565\n",
            "Progress:[38432/42907]  batch loss:0.038838\n",
            "Progress:[41632/42907]  batch loss:0.057534\n",
            "Train Error: Avg loss: 0.073318\n",
            "Test Error: Accuracy: 94.1%, Avg loss: 0.245309\n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.073472\n",
            "Progress:[ 3232/42907]  batch loss:0.027446\n",
            "Progress:[ 6432/42907]  batch loss:0.006446\n",
            "Progress:[ 9632/42907]  batch loss:0.041429\n",
            "Progress:[12832/42907]  batch loss:0.045691\n",
            "Progress:[16032/42907]  batch loss:0.029790\n",
            "Progress:[19232/42907]  batch loss:0.024610\n",
            "Progress:[22432/42907]  batch loss:0.012748\n",
            "Progress:[25632/42907]  batch loss:0.092020\n",
            "Progress:[28832/42907]  batch loss:0.033238\n",
            "Progress:[32032/42907]  batch loss:0.107033\n",
            "Progress:[35232/42907]  batch loss:0.087874\n",
            "Progress:[38432/42907]  batch loss:0.279895\n",
            "Progress:[41632/42907]  batch loss:0.048938\n",
            "Train Error: Avg loss: 0.071768\n",
            "Test Error: Accuracy: 94.5%, Avg loss: 0.280980\n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Progress:[   32/42907]  batch loss:0.002559\n",
            "Progress:[ 3232/42907]  batch loss:0.093291\n",
            "Progress:[ 6432/42907]  batch loss:0.121174\n",
            "Progress:[ 9632/42907]  batch loss:0.112496\n",
            "Progress:[12832/42907]  batch loss:0.039572\n",
            "Progress:[16032/42907]  batch loss:0.023736\n",
            "Progress:[19232/42907]  batch loss:0.069714\n",
            "Progress:[22432/42907]  batch loss:0.127799\n",
            "Progress:[25632/42907]  batch loss:0.199366\n",
            "Progress:[28832/42907]  batch loss:0.082791\n",
            "Progress:[32032/42907]  batch loss:0.019929\n",
            "Progress:[35232/42907]  batch loss:0.010244\n",
            "Progress:[38432/42907]  batch loss:0.129702\n",
            "Progress:[41632/42907]  batch loss:0.042770\n",
            "Train Error: Avg loss: 0.070879\n",
            "Test Error: Accuracy: 95.8%, Avg loss: 0.240935\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training and test loss\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs'), plt.ylabel('Loss'), plt.title('Training and Test Loss Over Epochs')\n",
        "plt.legend(), plt.show()"
      ],
      "metadata": {
        "id": "YEpdfFgeW_Fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "df16b878-688d-4e9d-d139-18f757ddadcd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.legend.Legend at 0x782d04f6ee30>, None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}
